["if i were being pithy, i find that when you're doing this type of thing it's more a feeling of \"working fun\" rather than \"working hard\".(of course this means that one is probably not always going to do \"production ready\" things, but it's for fun, so it doesn't really matter. sometimes it's fun to just go nuts and sprinkle \"undefined\"[1] all over the code base and just go from types to implementation as fast as humanly possible.)[1] this is a haskellism, but basically means any of:code_removed", "translationschinese:", "my personal guess is that most people need \"warm up\" time to make progress on their projects, the time needed to build up the mental model of the whole domain. this can go from hours to days to weeks depending on the person and the type of mental model. but some people have certain domains where they can just instantly build up that model in their head and immediately begin making serious progress. you sound like you're one of the rare ones that can do this for a large number of domains (3d algorithms, project architecture, database structure, feature interaction). i'm only like that with a few very specific domains and i suspect most other devs are like me in that sense, so we stand in awe when someone has that natural in-built capability. (i think this not only goes for making progress but also learning new concepts, as i have seen other graduate students who can blaze through certain things like haskell where i struggle as through molasses.) if this theory is true, then you probably aren't spending more than 3-5 hours on projects like this per week, but you're making the same progress most of us would need 2-5 weeks for.", "this was my #1 turnoff for haskell as well. all these operators and functions, each with possibly varying precedence as well as different fixities. i was constantly having to lookup how the function was actually being called -- which of its surrounding entities were a part of the function call, and in which order did the calls take place? in addition to this complexity, the functions are often cryptic little characters (operators) that just make the readability worse. programming languages should make our lives as developers easier, right?", "[ed: where i say ml, read sml - standard meta language]one of the reasons i'm interested in fb's reasonml dialect of ocaml is that i stumbled a bit going from plan ml (meta-language) to ocaml. that said, i think ocaml too is less complex than haskell. but more so ml.", "i think there's definitely a haskel trend to prefer \"accurate\" nomenclature vs merely \"serviceable correct\". that is to prefer \"joint rod and spherical cap digging implement\" vs \"shovel\".", "i have fond recollections of learning to program in caml (this was in 1997). without ever being \u201cindoctrinated\u201d to fp (i only recently made the connection to fp), we learned recursion, list manipulation, pattern-matching and currying before loops. tail-recursion was the standard way to write a function. i don\u2019t think teaching the same concept to first year students would be as easy in haskell (although i only know the language from lyah)", "do blocks don't allow side effects, they are just syntactic sugar that makes composing monadic operations easier.haskell does have escape hatches with unsafeperformio and ioref/stref", "haskell is a much more complicated language than ocaml:- laziness can be hard to reason about for newcomers who have really only had experience with strictness- you have to learn a lot of concepts from category theory right off the bat, because it uses io and monads. you need to know what a monad is, and almost all monad tutorials are notoriously bad at explaining what a monad is. you also don't know when to stop, when you've learned 'enough' category theory- the community is full of clever tricks and idioms that aren't really necessary to write haskell code, but a beginner might think they need to know it. examples: monad transformers, free monads, comonads, lenses, coroutines- the type system is substantially more complex. haskell has higher kinded polymorphism, rank-n-types, and a neverending set of extensions that a lot of haskellers use that'll keep you busy learning the rest of your life. haskell code can also be very polymoprhic, and the type errors can be really confusing sometimes. ocaml doesn't have these, but you can simulate the most important features: higher kinded polymorphism with functors, and rank-n-types with recordsthat's why ocaml is easier to learn and use", "^ what yodsanklai said ^ocaml has declarative oo programming via it's module system. typeclasses and ocaml modules have equivalent expressive power, so you'd achieve that with typeclasses in haskell. but ocaml's type system is much simpler and more explicit, which makes it much easier to learn and use", "turns out haskell is great for \u201cbuilding something useful\u201d though.at least that\u2019s been my experience in my years of writing professional, money-making software in it.", "i know of this list:", "ocaml and reason are beautiful languages. i actually applied to jane street hoping for a chance to use them more, but they weren\u2019t interested in my resume. is there a list of ocaml/haskell/etc companies out there for us functional programming enthusiasts?", "in (ghc) haskell you also have opt-in strictness (per module or per variable)", "i personally found the syntax in the ml series languages to be clearer when learning. i found standard ml/nj to be even easier (and potentially nicer) than ocaml for what it's worth.i think it comes down to visual cues. haskell eschews syntactic sugar and i personally find it hard to read the structure of expression. i found ml to be more explicit.that and the community around haskell really loves... clever... constructions. and its type system is more expressive but also complex from a mental model pov.", "i think a big problem is that it's hard to slowly develop \"taste\" in haskell. that is, it's hard to navigate the path from not knowing what you do and don't need to use to accomplish your task, to being able to tastefully choose the right tools. like you say, things like lenses are just useful libraries that you may or may not need, but how do you know? people on message boards and blogs may suggest that they are the right way to solve your problem, and you have to grok a bunch of stuff to determine whether or not you agree.i find this harder in haskell than other languages, because i find it harder to progress slowly. in most languages, step one for a beginner is to just hack something together, maybe even using direct for or while loops, switch statements, and the like. then you can go back and figure out what the language gives you to express what you've done in a better way. then you can iterate on that basic process, moving up the levels of abstraction, often finding at various points that you didn't need to write any of the code you wrote because a library exists that does the same thing if you call it in the right way. by the time you're reading about the library, you understand the contours of the problem it solves, because you've already done a worse job of solving those problems yourself. i've always had trouble injecting myself into the right point of this step-wise procedure in haskell, and instead feeling like i need to do a bunch of research on the right ways to do things in order to make any forward progress.", "ocaml's syntax is way more verbose and noisy than haskell's or elm's. it tends to have longer keywords, more sigils, \u2026 and some of the defaults are inconvenient (non-recursive lets) has some trivial examples", "sorry to hijack the thread:i recently was trying to decide which language to pick up next: lisp, ocaml, f# or haskell (i know a bit of lisp and haskell already, as well as some standard ml).it came down to two: ocaml and f#. the former has poor support in windows (work machine), and the latter has less poor support in linux (home machine). so i decided i'll probably go with f#. i've been told the syntax is quite similar, so how difficult is it to translate an f# program to ocaml. are all the patterns the same that one can do a more or less 1:1 translation while still being canonical?", "this is true to some extent (imo elm and haskell) but i think at least being exposed to one functional language will make anyone a better developer in all languages.i started programming in clojure, clojurescript, and now messing around with ocaml. the primary language i use at work is ruby.the aspect of fp that really helped me even be a better ruby developer was just having way less shared state. when you have less shared state, and small functions doing one thing with as little side effects as possible it really makes code cleaner and it makes your software behave in much more predictable ways.i know what some are saying \"well that seems like what you should be doing anyway...\" that is true but at least working with a fp language really drives this home and for me did more for code quality improvement than anything else. in fact now when i look at most ruby code even in big high quality projects i am like why??? ruby gives you so many ways to do things without shared state (blocks) yet so many choose to set instance variables all over, or store stuff in variables in memory.i still am not sold on strong static typing such as in haskell, and yes i get the opinion of what you said about that community. i am not sure though if it is because i am bad at it, or it truly takes more work than it saves you in the future. i just find with fp as in clojure and ocaml it gives me a lot of gain without ever getting in my way. so it is worth trying, and even if you keep working in a large imperative language, fp experience will help you not fall into the holes of large shared state.", "in haskell, you have to opt-in to side-effects (monadic do-blocks).in ocaml, you have to opt-in to lazy evaluation.", "for my personal computing needs i recently upgraded from the combination of an ancient i7 920 quad core desktop and a quad core haswell laptop to a ryzen 2700x desktop and a pile of lovely disposable x220 thinkpads.on the one hand, for software that's not complete garbage in terms of optimization (scientific software, video/audio software, games, my own code) the difference is staggering, i hadn't felt a change this drastic since i moved from pentium 1 to pentium 3. on the other hand, i now know that there is no amount of resources that will make a modern web browser or electron app run well.the good news is that now that i feel i deserve good performance i've made an effort to get rid of most of the crap. apart from disabling js etc. by default and blocking everything i possibly can i have no solution for the browsers, sadly, but everything else is gone. the thinkpads all run minimalistic arch linux setups and mostly work as thin clients, so overall every system i use is snappy and responsive, for the first time in a decade. i shouldn't have needed a hardware upgrade to return to common sense in computing, but it is good to know that with some discipline and a low tolerance for garbage it is still (mostly) possible to have a reasonable computing experience. now, if only there was a usable browser out there...", "seconding this. i got discouraged trying haskell. came back and tried it with racket and things made more sense. i certainly wouldn't give haskell as someone's first functional language.", "i don't get it. i work day to day with algol-syntax languages like javascript and java, but have dabbled in ml languages like elm and haskell. one of the things i really like about those languages is the syntax -- succinct and clear. what takes time and is hard for me is grasping the semantics and patterns.", "i did as well. i tried haskell on my own in the aughts before giving up. i had some fond exposure to ocaml and sml but never got into it until i heard the jane street talks, heard about mirageos, and decided to take the ocaml course in 2016.i've since gone back to haskell and am finally enjoying it... but i credit ocaml with getting me to a place where i could enjoy haskell the second time around.", "same, i had bad experiences with the early athlons and bought intels after that, never had any stability problems. but now i'm seeing douchey behaviour from both intel and nvidia. i've been a big fanboy because of the performance, but the business practises are becoming polarising, and amd seems to have caught up or surpassed in performance terms. plus, they handled the vulnerabilities disclosure much better (even a smug 'amd processors are not affected' on more than one).i always used to root for intel because amd made their entire business model off copying (later licensing) intel's x86 designs (including the model numbers), but that's becoming a lot less relevant now.i upgraded my desktop's geforce 550ti with a radeon hd 7850, and though it's gotten off to a slightly rocky start (windows logins are noticeably slower, seems to be a known issue), performance is great, benchmarks showing it on par with the 970m in my laptop. when the haswell i7 needs to be upgraded, i may start looking at a ryzen. never thought i'd see the day.", "there are two major differences between ocaml and haskell.first: haskell is a pure functional language, meaning that side effects, io, keeping state, all that must be dealt with inside the type system, which while undoubtly clean and powerful, it makes it often cumbersome to do things that should be quick and simple. ocaml, on the other hand, is pragmatic. it promotes and facilitates functional programming but it also let's you easily \"drop down\" (so to speak) to an imperative way to write code. you have mutable variables, imperative loops, you can perform side effects anywhere, etc. as a rule of thumb, you can write fully functional code, yet sometimes when the best way to write a certain thing is imperatively, you can do so with no hassle.second: haskell is lazy, and ocaml is strict. this makes it much easier to reason about performance and makes for much more predictable code. at the same time, it has first-class support for laziness when you do need it, but you have to explicitly \"opt in\", so to speak. haskell also lets you force strict evaluation, but you will find it's much easier to build laziness in a strict language than the other way around.there are also other important differences (like typeclasses vs functors) but i feel these two are the biggest ones.", "i had the feeling haskell would use much more fp jargon than ocaml, i think.people where talking about profunctor optics, monads and lenses, stuff i never heard of.", "yes, i did try it after haskell.i had the impression the fp hype started with haskell and so i tried it, alter people started talking about ocaml, so i gave fp another try and liked it.", "did you try ocaml and reason after your attempts to learn haskell? that might have something to do with it. sometimes we don't get the idea the first time we are exposed to it and we need time to let it sink in. it's when we are exposed to the same ideas a few times in different formats that it starts to trigger our tendency to notice patterns.i have observed a similar effect that it seems like plenty of people come from an imperative language to ocaml and stay in ocaml longer than say, haskell. although i'm not sure why that is but maybe they are much like you and tried haskell first?", "haskell forces you to manage effects explicitly, even for e.g. input/output. in a production system this is probably a good idea (most of your functions shouldn't be doing i/o and you probably do want to flag up a function that is), but when you're just trying to get started with \"hello world\" it's a confusing extra complication.if that was your problem, it might be easiest to start by doing things in the repl (ghci) where you don't need to be doing i/o, and only start writing standalone haskell programs once you're a bit more comfortable with the language. but i'm just guessing - maybe you found some other aspect to be a barrier?", "can anyone explain why ocaml seems easier for people from non-fp backgrounds than haskell?i tried haskell and purescript and didn't understand a thing.i tried ocaml and reason and it felt rather easy to learn.", "> but coming from a background with c/javascript, the syntax is definitely hard to understand.i work with haskell fairly regularly, and have experience with a few other languages (python, racket, c/c++, java, etc.), but i definitely agree with this sentiment. i am not a fan of ocaml's syntax at all.i haven't had a chance to check out reason yet though, so maybe i'll spend some time playing with that soon!", "best part of this is the very pragmatic set of problems. i loved the meijer haskell mooc too, a lot, but it's more about mind bending rather than more day to day programs.", "for others that run into problems with the link: it does not work with (at least for me)change it to", "haswell massively improved the branch predictor, which gave a significant ipc boost to many real-world workloads (especially emulation and interpreters).", "there are some interesting ideas about programmability, like automagically offloading some computation parts to fpga.", "game programming rating: immature> haskell is a garbage collected language, so haskell is more appropriate for the scripting / logic layer of a game but not suitable manipulating a large object graph or for implementing a high-performance game engine due to the risk of introducing perceptible pauses due to gc pauses. also, for simple games you can realistically use haskell for the entire stack.", "is also didactic but goes into more details, and is not haskell-specific (iirc functors, map and so forth are all defined in javascript)", "sounds like the haskell pyramid", "you can use haskell to do the things elm does (and more, like deploying to mobile). checkout reflex and obelisk:", "cabal newbuild is quite nice.for newbs stack is fine. but i genuinely question any serious code base that needs stack. genuine cabal hell hasn\u2019t existed since around 2010. and the mini purgatory that some people call hell is impossivle with cabal new build.my perspective is perhaps biased, but i also am comaintainer of widely used libraries used literally everywhere plus i\u2019ve done commercial and recreation and research flavors haskell dev for over a decade, currently at a fortune 10ish sized company.though zooming out: these days i tell learners they should try everything out, and revisit various tools as their mastery grows.for industrial / large prjects that want pinned deps, i\u2019ve seen folks happy with the mafia build tool or even going full nix for end to end os level reproducible build and config.my main issue with workflows like those centered around stack is that i\u2019ve seen a lot of folks just not think about library versions and deps as part of their library/application foot print. and this has various consequences in how they engineer and upgrade their own libraries and applications.", "the guy has serious issues, i was shocked at how toxic he gets at the drop of a hat. i was browsing a discussion on the haskell subreddit and he was incredibly nasty, literally zero good faith given or assumed of others. technical opinions aside, i would never want him involved with a project i'm participating in. he fails the only rule i care about: don't be an asshole.", "to be clear, i'm not aiming to build the next call of duty; these days you can get pretty far building a medium-sized 3d game out of unoptimized javascript running on a web page. the gc optimization you mention is interesting to learn of, but probably irrelevant for the kinds of things i would be doing. does that change your assessment of haskell for this purpose?", "right.one technique used for writing games to run on gc'd runtimes is to avoid allocations entirely in the game loop. with a lot of work, you can preallocate everything you're going to need and just modify it as you run.this technique is not a good match for haskell's primary design principle of avoiding mutable state.", "> have you been able to reduce the `side-effects` significantly or have just become more aware of it?yes, sorry, i think i didn't explain myself very well.prior to learning haskell and embracing the way, my code was fairly covered in side-effects. i was a relatively junior programmer at this point (many years of experience because i started young, but few years of real education). side-effects were just, you know, a thing that happened because they were \"the easy way\".after learning haskell, i became much more conscious of side-effects. i realized that a lot of things i used to do could be done without side-effects, mostly by writing better functions and thinking more deliberately about how to eschew the side-effects.that said, it's not like they're gone. it's just that i'm much more careful about them. i \"avoid\" them in that i do my best not to include them, but if there's a genuine use for them then that's fine. however, i have taken to naming my functions better to reflect their side-effecting nature, and i try to move the side-effecting functions to places that make more logical sense (instead of just wherever).", "right, and this is what i actually meant. it's not that side-effects disappear, but rather that i try not to litter my code with them. i avoid them in the sense that i don't embrace a side-effect-heavy style of coding, as i did with my imperative code prior to learning haskell.perhaps i could have worded that better. sorry for the confusion.", "i think functional programming in general is part of it, for sure.that said, my first success with functional programming was actually with racket. racket is great for learning (in my opinion), but the \"lessons\" racket had to offer weren't really solidified for me until i moved to haskell. at that point, things really started to click.that could be due to any number of things, though. however, certain concepts (e.g., laziness, typeclasses) are more haskell-specific (or at least are not common among all functional languages).", "haskell state keeping is either fast or convenient, not both. timing has several issues, not only gc pauses, but the entire functional paradigm was not created for real time. lazyness adds up fast if you keep passing stuff through clock ticks.none of that is a showstopper. but i'd rather use a language that doesn't suffer from fundamental drawbacks on the domain i will work.that said, haskell is very promising for ai. if i ever get to that game again, i'm writing the main loop in rust with an asynchronous ai in haskell.", "these kinds of comments are why i was very careful to pick who i was mentioning. bodil is a very public figure and more than capable of taking care of herself. hopefully, i (and more importantly she) won't regret that decision.but anytime you make a list of \"here are people who are helpful and won't demand much but courtesy in return\" in the haskell community folks like you pop up demanding i mention your favorite guy like he's relevant or necessary. go write your own list if you want your gab.ai fp follow list.", "my thinking was to have a top game loop that \"ticks\", and then passes the current game state + the time delta to a pure function which returns the new game state, which gets stored. is the concern that haskell's lazy-evaluation might lead to a higher level of variance in frame-rate than another language?", "> while i have not achieved any sort of nirvana, i do believe that learning haskell has \"enlightened\" me insofar as i now look at programming in a fundamentally different waycan i ask whether haskell in particular led to this enlightenment, or if functional programming is the underlying concept responsible? i've been considering learning julia for fun and am wondering if it would impart some of the same benefits.", "my conclusion about using haskell to make games and device drivers\u00b9 is: don't.even if the ecosystem changed and some great libraries appeared since i last tried, the language itself is a bad match for those domains. lazyness is great everywhere, except when it works against you, and the garbage collector will assure you notice it.1 - on my case, userspace drivers. i'm still open to userspace filesystems (i have on on my todo list, if i ever get there), but device controlling implies on some harder real time requirements.", "avoiding side effects sounds like something someone new to haskell would say. haskell in no way avoids side effects. actually i'd say it embraces them by introducing special semantics just for them! what it does do is encourage you to move side effects to the \"edge\" of your code base and produce a more clean separation between pure & non-pure code. this is incredibly valuable for testing and overall correctness.", "i'll check it out. mainly what i'm interested in is doing world simulation in haskell; it seems like it would be a really interesting language for that. but that kind of thing isn't very useful without a decent way to visualize and interact with it.", "not exactly games, but the haskell school of expression by paul hudak is targeted at multimedia work in haskell. i haven't read it, but if that's what you want to work on, it might be worth checking out.", "with regard to yesterday's exhumation of lyah i'd like to point out typeclasses.com which i just discovered on r/haskell through this announcement:", "> addenda (relevant to community musings today): [...] awful and abusive people exist in the communityare you referring to people saying negative things about learn you a haskell?", "> haskell is not an achievement to unlock or a trophy to be won because learning is a never-ending process and not a finish line.haskell aside, i think this is a fantastic point regardless of whatever it is you're learning. there's always so much more to learn and having this mindset makes it a lot easier to do so.", "can second all these suggestions. also, from my experience all the haskell events i've been to have been incredibly welcoming and positive, whilst i'm aware there are a tiny subset of abusive people out there, i've never met them nor met anyone who would tolerate them.shoutout if you're in the sf area, bayhac ( a yearly unconference/hackathon is incredibly fun, and also there are (roughly) bi-monthly haskell meetups ( in sf which are great fun (disclaimer: i co-organise the meetups - find me @nick_engb).", "my advice for haskell(\"monad\") beginners would be to try to re-implement the(\"a\") state monad by yourself without using any libraries. it helped me understand that monads are nothing more than just function composition.", "i have skimmed all the famous books so far on haskell. but the best learning resource to me so far has been the upenn course [0] because of the quick coding and feedback loop in the browser. also, the beginning assignments involve visualizations, which is always good to check if you are doing things right or wrong.0.", "addenda (relevant to community musings today):be aware that as a small and very distributed community, the haskell world has less power to eject bad actors than more centrally managed and resourced projects have (e.g., golang and rust have much more structural power to moderate). awful and abusive people exist in the community, and it's best to just start blocking and ignoring folks who disrespect you.the amazing thing about the haskell community is that knowledge is very well distributed throughout the community these days. the culture, influenced by academia, strongly values writing and publishing ideas rather than sharing them orally or in the workplace. this means that if you're interested in learning, there are a ton of places and ways to do it.if you're looking for good initial connections to folks who are respectful, well informed, and unlikely to expose you to some of the frustrating cabals in the community, i've got a few recommendations1. gabriel gonzales (this is his blog, and he's @gabrielg439 on twitter)2. chris martin of typeclasses. i'd also list his partner in crime julie moronuki, but her social media interaction is reduced these days. these two focus on helping programmers get up to speed with haskell from a variety of starting points, and they care more about functional programming than haskell specifics.3. patrick thompson of github (@importantshock on twitter). a fantastically skilled person who will link you to a network of amazing haskell folks who do stuff in a positively next-generational way.two people who are adjacent to the haskell community and incredibly interesting, but probably can't answer direct questions for you. worth a follow.1. dr. edwin brady, creator of the idris language. he's widely respected, humble, and has a beautiful vision for how humans and computers should interact to write programs.2. dr. bodil stokke (@bodil on twitter). bodil is not so much a haskell person these days, but she's got a phenomenal breadth of knowledge and always has interesting things to talk about in the fp space. worth a follow if you're on that platform.i suppose you can ask me for help too, but i'm certainly not as competent as these folks.", "i read through part of the \"learn you a haskell\" book that was posted here yesterday, and started getting really excited to use this beautiful language.and then i started looking into ways to use it for making games and was... disappointed. maybe i've been spoiled by the vibrancy of javascript's ecosystem, but i hoped to find a library for simply rendering existing meshes with existing materials and the closest i found was a library of base opengl hooks. add onto that the lack of half-decent ui libraries (on the web you can use elm, which is similar but different) and it feels like the only thing haskell is practical for is headless data-processing, which is a shame.", "if you're not on a purely intellctual trip, my advice is to first get a feeling for the language before trying to understand everything. every widely used concept arises out a necessity and not out of thin air. don't read all the monad-tutorial first. it's hard to understand not only why this abstract nonesense is useful, but even what it \"is\" (assuming you have no serious math background)! the interesting thing is that the concept arise naturally if you spend some time tinkering with haskell. the functor arises almost instantly!", "i think this (short) article had a lot of good points, though i do take minor issue with one bit:> some people learn haskell with the expectation that they will achieve some sort of programming enlightenment or nirvana. you will be disappointed if you bring these unrealistic expectations to the language.while i have not achieved any sort of nirvana, i do believe that learning haskell has \"enlightened\" me insofar as i now look at programming in a fundamentally different way. i put a much greater emphasis on writing many small functions, i use types wherever possible (and type hints too, since python is my primary language), and i avoid side-effects when i can. all of these things i do because haskell taught me just how powerful simplicity can be.i also learned about different ways to conceptualize the relationships between data, and i learned about laziness (something i'd never heard of before then). haskell has a lot to offer for people who come from an imperative background.> haskell is not an achievement to unlock or a trophy to be won because learning is a never-ending process and not a finish line.while you can never \"finish\" learning, you can set milestones to mark your achievement. comprehending some of haskell's features (both the basics and the advanced ones) are perfectly acceptable milestones by which to track progress. i don't think that's a bad thing.---that said, overall the article is very good. i agree that newcomers should write small programs, get their hands dirty, and learn to really use the basic features of the language firsthand before moving on to more advanced things. (and especially i agree that new users should avoid typeclasses at first, or even at second.)", "\"which allowed the use of special characters on the home row\"unless you're programming in something very symbol-heavy, even by programming language standards, i suspect you'll find that it's hard for any symbol (other than space) to break into the top-10 non-space symbols; not impossible, but hard. i just did a 200kb perl file here, and the top 12 symbols are space, e, a, r, s, i, t, o, n, newline, l, and d. the first symbol, underscore, shows up in position 13, then it's u, then finally, $. underscore is less than half as popular as the e. as you may guess, the naming convention of this code is mostly underscore_based. if this code was camelcase instead, you'd have to go down to position 14 with $.the other problem is that languages will significant differ, so you can't really create \"a programming layout\". if you did nothing but type perl, that list of symbols may suggest that perhaps $ should be on the u or i key or something valuable like that, but if you run the same process over your c# you're not going to see $ popping up nearly as high and now you've got a huge wasted key. parentheses are in the 22nd and 23rd slot on this count, the only thing that i would be comfortable saying is really generic. (and then there's still haskell, where they are used, but much, much less often.)", "i started learning haskell by working on a proof of concept for a relational language. the big advantage, i think, was i _didn't_ try to do anything fancy with monads or typeclasses. i was just interesting in expressing functions, and that got me fairly fluent in that subset of haskell.it definitely helped later when i started working on a language myself, and now needed to write a parser and do a lot of transformations using uniplate.my biggest piece of advice for beginners trying to do anything more complicated that requires dependencies is to use stack[1] and set up a skeleton project.set up your stack.yml file with the latest nightly (hack on nightlies, release on lts) and then visit stackage[2] to see docs _completely in sync with the versions you're using_. you should just be able to add dependencies you need to package.yml.that gets you a fairly stable environment where things will actually do what you expect, which eliminates a big source of confusion and frustration.[1]: [2]:", "right. long ago a group of oxford physicists with no computing experience were baffled by \"let x=x+1\", which the demonstrator failed to explain in terms of a storage model.orwell (haskell predecessor) was used later at oxford, and i think ml at the other university. \"preparing to study computer science at cambridge\" once said \"teaching yourself to program can lead to your picking up bad habits that will hinder your progress later. in particular, you should avoid languages like c++.\"", "i agree re: marketing -- something i had easily fell for. one of the authors has moved onto writing another haskell book (a \"work of art\" apparently), but this time my interest, for an intermediate level book, is elsewhere: (which would be more informative--thus pedagogically sound--than a work of art).lesson learned: don't fall for the marketing of art.generally the best way to learn is by actually doing projects:", "i've never had to resort to mathematics (like category theory) when learning to use haskell in real-world projects. and i don't think hutton's or bird's rely on mathematics for teaching haskell.", "hutton's book was my favourite too when i was learning haskell. my only gripe was it used a proper typeface for it's code samples, making mapping to keyboard strokes an unnecessary cognitive effort.", "people have different styles of learning. i loved lyahfgg, but hated haskell programming from first principles. as is evident from this thread, many others feel the opposite way. both books deserve to exist and be shared frequently.", "i would start with haskell programming from first principles, as it is recommended by many and it looks good (i have to admit i started with lyah but content-wise, hpffp is much better).i also recommend reading these web documents as a supplement: am now reading haskell high performance programming ( and while the book is more intermediate (it assumes that you can find the documentation and read the haskell code yourself), i think it is a good overview of how to use modern haskell in real projects.", "well, if you are reading the chapter, it's because you want to understand it. since everything in this book is verbose, you can't just skip the verbose parts.half the examples contain jokes or cutesy animal sounds (onomatopoeia). i like jokes, but it is distracting me. especially when i don't understand the cultural reference.my biggest gripe with the book is that the examples can feel quite contrived. its probably super hard to make a book featuring all concepts without having contrived examples. but i remember reading a chapter and some arbitrary abstraction is introduced. problem is, based on that example, i don't realize when the abstraction is useful.it might be impossible to write a haskell book that is neither terse not unnecessarily verbose.since you can get some chapters for free, i'd recommend you just download them and see if you like the style.", "> but my real wish: because i'm like many people and have experience with dozens of languages. i want books that leverage that knowledge and experience. e.g., to explain monads, just say it's an interface specification, and give the api. it'll make sense to me.i understand the wish but i personally believe it is a bad idea. i think haskell is just too different due to purity and laziness and trying to adapt your intuitions from imperative programming is going to mostly fail, badly. i suggest it's better to approach haskell with a completely blank mind and learn the correct intuitions through just being very rigorous at the beginning.i have written a bit of haskell myself but i still get surprised by evaluation order, for example. but it has paid off, i think, it's a lot more understandable and modular and beautiful code that i write in haskell than elsewhere.", "> all high-level programming languages are on board with abstractions, pretty much by definition!they all provide abstractions, but they're not necessarily on board with letting users build new abstractions. go is famously absolutely not on board with it for instance. elm significantly less so \u2014 and i think the more restricted use-case also makes the issue significantly less problematic, at least it was in my (admittedly limited) experience \u2014 but it's still way downslope from the likes of haskell or ocaml.", "i wouldn't really consider stack to be a great tool. there is stackage which may be useful but the tool itself falls apart quickly when used to compile more than a single package executable.that being said, one should have looked at these:code_removed", "i will quote (what i think is) an important part of the learning process: \"much of the difficulty in learning a new language is simply setting up the environment and getting comfortable with the tools to start programming.\" having a kind of ide to play around was immenselly useful in my case. i then could try to solve small problem i invented. and used the various haskell resources in a non-linear way (how to do this? cf so, books, articles, etc. and then some theory articles to tell you why it is done this way. and that again for another topic required to solve my problem, and again, and again). problem solving was my way to go to discover the haskell way. not just reading a book linearly.", "lyah also didn't do much for me.i got started with haskell data analysis cookbook. as an experienced programmer, i love the \"cookbook\" format. e.g., \"keeping and representing data from a csv file\" or \"examining a json file with the aeson package\". if you need to actually use the language, this is a great way to get started. complete programs are shown.unfortunately, most books dive into the language _implementation_ instead of teaching its _interface_. (this probably points to a haskell design weakness: deep learning of the impl. is nec. for success.)but my real wish: because i'm like many people and have experience with dozens of languages. i want books that leverage that knowledge and experience. e.g., to explain monads, just say it's an interface specification, and give the api. it'll make sense to me.", "i concur. lyah may be seen as an intuitive and easy read for getting started but i felt i was incapable of understanding real haskell code with just that background. i finally got my hands dirty by hacking around on existing haskell code which is when things started making sense.", "it seems obvious to me that lyah is an imitation of why's poignant guide to ruby, and that neither is actually a good learning resource. i don't mean to disparage these as works of art, but _why did it first, _why did it better, and if you actually want to learn either ruby or haskell neither should be your first stop.", "the haskell book was better for me at least.", "let me try to make hexane360's point more explicitly:imagine a hypothetical universe where all haskell books are equally good, but some are more popular than others (maybe they have well known authors, or catchy titles, or are available for free online, or something). in particular, imagine haskell book number 7 (hb#7 for short) gets 99% \"market share\".then if someone says \"most people who gave up on haskell used this book\", you should not conclude that it reflects badly on the book. it's just a consequence of the book being popular, so it's the one people tend to try to use, so it's \"the one that didn't work for them\".if you want to learn whether the book is better or worse than average, you need to split people into two groups: one group used this book, the other group used some other book, and compare which group does better. (ideally, you should assign people to a group based on a coin flip, but even just looking at what happens \"naturally\" without your interference is better than nothing.)back to our non-hypothetical universe: lyah does not have 99% market share, but it's pretty popular. i heard of it, and i've never looked for a book on haskell. so to some extent the same logic applies.", "can you give a little more info? does it offer alot over haskell?", "i learned haskell from the \"gentle introduction\" (which isn't so gentle), then writing programs, reading documentation, and reading online discussions and threads.", "it is something that is marketed very well. from the sample content, it didn't look interesting to me at all.lyah may not be the greatest haskell tutorial. but it makes an easy read. that means, you are not afraid to go back to it again and again, which is the crucial aspect of learning anything sufficiently complex or new or both..", "i personally favor thin books that present what really matters after having digested it first. not that there's no place for thick books on my shelves (clrs among others). i find haskellwiki/hoogle better serve the use case that the haskell book seems to target.", "html is by definition intrinsic to web development.lyah is not intrinsic to haskell programming.", "this is my all-time favorite haskell resource: jump to the bottom and go through as many pages as possible. going through functors, applicatives, and only then monads puts everything in a broader context and makes monads easier to understand.", "it was valuable to me as pretty much the only haskell resource i read that addressed more complex concepts without hitting a point where they needed to resort to mathematics.", "haskell programming from first principles is costly but extremely good: beginner material in the haskell wikibook is pretty solid:", "easily the best one imo: unlike lyah it covers stuff that is actually important to writing real haskell programs like testing code, managing effects via monad transformers, etc.also this is one of the best references while you're learning (not good as a tutorial, but chock full of invaluable resources): tbh i wish every language had an equivalent of this guide.", "in the mid 90s, first year computer science at the australian national university used miranda, the proprietary language from which haskell was forking at the time. it was great. when i read sicp later, the first half seemed like a long-winded demonstration of obvious ways to use recursion. didn't everyone know this stuff?much of the language seemed like magic, but anu had a culture of throwing students in the deep end to keep us humble about what we knew.", ">majority of people i anecdotally hear gave up on haskell seem to mention lyahthis is a bad statistic to use on its own. imagine if i said \"majority of people i anecdotally hear gave up on web development seem to mention html\". see the problem?", "haskell was the first programming language taught at our college when i was a student, where some of the students hadn't even used a computer before. it went fine. (i think it was actually better than other languages would have been, as many of the students had a background in mathematics and might have been confused by things like \"x = x + 1\", while they were comfortable with the idea of a function, at least as used in mathematics.)if you'd like to see for yourself what that course was like, here are lecture notes (and assignments, and mid-term exam):", "honestly, this is not a good book for beginner.here are some free functional programming (haskell,purescript)learning resources from 101 to building product: over 20 free fp books:", "i don't recommend learn you a haskell or real world haskell. check out haskell programming from first principles", "i don't think haskell is hard, but that's once you know it. it takes a lot of insights until you can see that it is really simple. a lot of code can look unreadable but that's just until you become familiar with the idioms.", "i won't comment the book. but my personal feeling is that you need a working environment first. and for that, you need to follow the advice at this resource: with my comment (cf olivier rossel). if you are under ubuntu, forget about the brew paragraph. just curl -ssl | shafter all that, you will have an editor that can run/debug some haskell.", "haskell is a great language to learn as an introductory language with the right teacher and text. read hutton's book and come back here and tell me you found it to be too difficult for a beginner.", "actually haskell is excellent for an introduction. the problem with haskell is that it may be hard hard to get \"real stuff done\" so to say, i.e. in an industry setting where you have to interact with many external services or libraries (and then miss those specific libraries).if you're learning the basics of computer science you usually don't have to do this so haskell is a great language then.", "first programming book i've ever read. i love it. i haven't done haskell since.", "i have never heard of haskell being a language used for teaching introductory computer science courses. that sounds like a nightmare. i'd imagine mid-to-upper div classes.", "> terrible book.definitely overstated and not good advice for beginners.my advice to beginners would be:- read all the haskell books available at your disposal. (in addition to lyah and the hutton book, i would say learning haskell from first principles and get programming with haskell are great, when you hit something that doesn't make sense in one source, try referencing it in another source.- when you have some experience writing programs in haskell, refer to some older books like real world haskell. there may be a few issues compiling the examples, but nearly all the techniques in the book are still widely used and you learn about the language has progressed in the last few years. this gives you a compass to read and maintain older haskell source code).- read as much haskell code as you can from popular libraries (pandoc, xmonad, and smaller libs as well).", "what do people think of real word haskell (", "i used this book to get introduced to haskell and think it worked great, it\u2019s also used as the course material in the first programming course for the cs-program at chalmers university of technology (cth) and have worked as a introduction to programming for hundreds of students every year.", "personally, i found lyah to be a great book. if there are places where the book is incorrect, i didn't have the background knowledge to notice. i felt the book did a good job explaining applicatives and monads by starting at the very basics and very slowly ramping up the complexity to a complete understanding. i know with many math books i have had a problem where some transformation morphs equation a into equation b and the reader is left wondering how exactly b was obtained. i never felt that way reading lyah. i could see where somebody already knowledgeable with haskell would find the micro steps overkill, but it went at the pacing i needed.", "the haskell wikibook[1] is a better free resource.[1]:", "may be this book isn't ideal, but it explain the most important and complicated things in haskell such as functors, monads, applicatives, etc.", "not to start a flame war, but imho this is my definition of a \"terrible book\". of the everything and the kitchen sink variety. by contrast, i very much enjoyed lyah, not least for its self-effacing humor. hutton was too dry for me. there's a less well-known \"thinking functionally with haskell\" book by richard bird that is concise and targets the mathematically inclined crowd.", "it's very easy to give up in other languages. haskell forces you to find a pure way by giving you no other alternative - and most of the time, a pure way is actually easy once you try.", "haskellbook is also highly recommended", "i read lyah and enjoyed it. but i did play around with haskell a lot at the same time.in addition, the irc channel was immensely helpful along the way.nowadays i just use haskell for a few things at work or for toy projects, and the initial steps were taken with lyah. (beginner level though and i think i learned more from irc than the book in the end)", "what about \"get programming with haskell\"[0] from manning. is it any good?code_removed", "yes, this book is one i recommend to anyone who wants to really understand functional programming. admittedly it's not haskell, but it's the book i wished i'd had back when i first learn fp (and scala).", "> instead of just taking haskell features and porting them > into already adopted languages, i'd really like to see > more companies just go directly with haskell, [...]unfortunately there are some places where aspects of the standard infrastructure around haskell block production application.in particular, we have applications with very hard latency requirements and also with complex type/binding requirements (where a direct structural type system is needed):", "haskell is hard, mainly because it's normally not a first language, and the first language people learn probably has algol-like syntax (e.g. c, java). i think erlang is a bit easier to learn due to having fewer features, and for me was the gateway drug to haskell. it let me learn to program with recursion instead of loops, and pattern matching instead of `if`s. the type system is the best part of haskell, but unfortunately it makes it very easy to get stuck when starting out (\"io string\" vs \"string\", \"bytestring\" vs \"text\"). it's well worth the investment, though, to get a tool that lets you develop concise code like python/ruby but gives you strong guarantees of correctness. also worth noting the incredible ecosystem of libraries and tooling, like stack and intero:-", "i wish this was shared less, it does a really bad job at teaching practical haskell skills. for a long time this book left me with the feeling that i was unable to learn the language.", "lyah was my first taste of functional programming. before that i only had 2-3 years of experience using php and ruby. i read this book and quickly fell in love with fp and category theory, for the first time really started to enjoy programming to the fullest. this book is also the reason i was able to land a job as an erlang developer, and teach a little bit of haskell to others. now, 5 years later, i continue my studies with languages such as emacs lisp, guile, clojure, elixir, elm, hy.i know this book isn't really popular (reading these comments) but to me it holds a lot of emotional value and i felt obligated to share my experience. i'll always be grateful for what this book taught me, and thankful to miran for writing it.", "> terrible book.while lyah may not be ideal, isn't calling it \"terrible\" a tad too harsh?fwiw i learned haskell using lyah and enjoyed it thoroughly. it was my first time learning a language with such a high focus on functional programming, but i think this book did a good job of teaching it.", "yeah but you don't have to learn haskell to understand that", "agreed. now that i found i like org-mode plus org-babel-tangle i'm planning to re-read it solving the exercises.lyah however is a few days read. it lets you to get closer to start learning haskell, but not even in the same league.", "another entry in the not haskell category, functional programming in scala is outstanding.", "it probably won't be for you. i was picking up rust in 2015 and my prior haskell knowledge (just past beginner at the time), helped immensely. there's a good deal of crossover for the broad concepts.", "wouldn't be my first recommendation for a good haskell book. i really enjoyed haskell: first principles. i'm sure that will get mentioned a lot here.still, as a free resource it does cover some fun things. i just felt the book wasn't practical.", "http version is up and running. maybe it's just a certificate thing:", "i got lyah in a humble bundle and didn't make it very far before getting bored and dropping it.i've used rust, sml, and a bit of scala so i don't feel like it should be that difficult to pick up haskell. next time i get the urge, i'll try hutton's book.", "currently:>this site can\u2019t be reached >haskellbook.com refused to connect.hn readers hitting the site?", "i can't recommend this book highly enough. very practical, and the way the chapters are organized really feels right. the excercises and examples really help drive the concepts home.in my opinion, learn you a haskell is a poor resource to learn the language and for some readers seems to be actually counterproductive (i have two friends who got through lyah and then tried actually using haskell, realized they have no idea how to actually use the language, and give up on haskell altogether:( if only they'd used the haskell book...)", "as unfortunate as that may be, i'm glad to hear that maybe it's not that i can't learn haskell, maybe it's just that i chose the wrong book. so here's to trying again with hutton's book!", "yes and there is a newer 2016 version (2007 one came up for me first) referral link)", "another good (imho better) option is the haskell book", "i really enjoyed programming in elm as a starting point. elm avoids type-classes, which tend to be the biggest hurdle when starting to learn haskell. plus, you can design a nice web app in the process (versus, say, process csv files). after i became comfortable with elm, learning haskell, type-classes, lazy evaluation, etc., made significantly more sense to me. for instance, `do` syntax is great, but it's not obvious what it really is doing, at first, unless you've programmed pure functional languages without using `do`.also, learning idris is another great learning exercise if you want to stretch the ways to think about programming.", "i agree, it's really disjointed. it spends a long time on relatively easy stuff and not much time on the hard things, imo. i also have trouble with the style and i think it goes too far with the sort of informal, conversational tone. ultimately haskell is a language with a lot of formality at its core. you don't have to present it as all abstract category theory theorems and such, but that doesn't mean you should avoid formality entirely.", "i think the enthusiasm for lyah should also be seen in context.real world haskell was the first book that made it to a wider audience. and while was is full of useful information, it is a very uneven book that works badly as an introduction to haskell. we once had a reading group where we read rwh, most colleagues dropped out after the first 3-4 chapters.in comparison, lyah was a book that was far more straightforward as an introduction. and i know a few people that have gone through it cover to cover.although it's been a while since i read it, i really liked graham hutton's 'programming in haskell'. it was short & clear.", "many years after my first exposure to this book and having learned more heavy-fp in scala, i would not recommend this as a resource for learning either fp or haskell.but let that not be a pock on the overall great mission to make fp more accessible.", "i always think that this attitude is a little bit off. obviously learning a new paradigm or a new language is great and expanding your horizon is very rarely bad, but i feel a little bit sad about shoehorning haskell, or functional languages in general, still into this education category.haskell is a very solid production language and you can put industrial grade software in haskell out there, and it is in fact used by a fairly serious amount of companies at this point.instead of just taking haskell features and porting them into already adopted languages, i'd really like to see more companies just go directly with haskell, or clojure, or ocaml and f#. it does work.", "i'm not op and it's not haskell, but fsharpforfunandprofit.com really clicked for me, personally.", "are there any similar resources with practical examples (other than the book real world haskell)?", "terrible book. please, please read graham hutton's programming in haskell. lyah is full of incorrect definitions and broken analogies. hutton on the other hand is up there with k&r for clear and concise definitions.", "still recall the advice form a classmate asking if i should learn haskell -- he said \"just learn it because it'll change how you think about programming\".i think people should learn it for this exact reason -- it really does change how you program as well as thinking about programming even if on a daily basis you're not writing pure haskell or clean or scheme or whatnot.common programming concepts like \"iteration\", \"state\", \"formal methods\", \"parrallellism\" are concepts that functional programming makes you reconsider from a new perspective.", "> i'm not sure why lyah wasn't good for me, when it's touted as being a great starting placeit's not. it's a terrible starting resource. majority of people i anecdotally hear gave up on haskell seem to mention lyah. yes the material is there, but it's not presented in a way that generally sticks and fits pieces together. i guarantee someone will reply to this thread and say it worked for them, but in general people seem to be unsuccessful with it.there are better options out there.", "i tried lyah before i had any real functional experience, and it went poorly. i think i wasn't dedicated enough.i took a programming languages class taught in racket, and by the end of that semester i felt like i had finally \"gotten\" what functional programming was all about.tried lyah again and... it still didn't quite stick. not sure why. but i was determined, because i'd heard about haskell so much on the internet.so i took a follow-up \"class\" where we just implemented projects in the functional languages of our choice, and i chose to do everything in haskell. i asked my research advisor (i work in a pl research lab) for guidance, and that's when haskell really started to make sense for me. i'm not sure why lyah wasn't good for me, when it's touted as being a great starting place for so many people, but now haskell is one of my favorite languages by far.", "> both elm and standard ml have additional type constraints for numbers and comparable types that aren't implemented in terms of a user-definable type constraint like haskell's typeclasses.that's not really true. standard ml has overloaded operators for int/real, but you cannot write a polymorphic function over any kind of number without using the module system. this is a key distinction. standard ml does have a notion of 'equivalence type variables', which is frequently seen as a wart (since you often get an equality definition you might not be interested in). standard ml has nothing for 'comparable' types (except, again, through the module system).offhand, i can't really think of any other language that uses builtin type classes in the style of elm.", "> use of dictionary passing as a substitute for typeclassesno, i mean that neither elm nor standard ml has nor needs typeclasses. no language needs typeclasses.both elm and standard ml have additional type constraints for numbers and comparable types that aren't implemented in terms of a user-definable type constraint like haskell's typeclasses.another example of their being different is that haskell offers custom user-defined operators, whereas elm intentionally does not allow user-defined operators. there are a fixed list of them, and that's it. a great many languages have that policy too, and i would not call them wrong to do it that way.again, there are sound design reasons to make either choice! there are costs and benefits to making things user-definable. if you prefer the way haskell did it, great! that's why we have different programming languages.:)", "> elm handles those things the way standard ml does, not the way haskell does.that's the thing, though: it doesn't. sure, elm is expressive enough to allow use of dictionary passing as a substitute for typeclasses, and as you noted, this approach has some resemblance to how ml modules work \u2013 albeit with less sugar. however, elm's standard library does not seem to think this is the best approach, since it instead uses the aforementioned special-cased typeclasses.", "i agree with you.elm is not going to change, however fortunately there are alternatives. pick something like purescript or ghcjs and move on like i did.i now write haskell professionally[1] both for frontend and backend, something that you'd be hard-pressed to achieve with the likes of elm.[1]", "it's more accurate to say purescript has haskell-like (or category-theoretic, if you prefer) abstractions.all high-level programming languages are on board with abstractions, pretty much by definition!", "elm handles those things the way standard ml does, not the way haskell does.it's cool if you prefer the way haskell does it, though! you should check out purescript, which chose to do it the way haskell did it.", "> once people start using elm the way it was designed to be used, things become simple and start to flow.but how will anyone ever get anything done, when they can't make everything in their code exceptionally clear by wrapping it all up in a 15 monad thick monad-combinator? /sbut yes, i totally agree. elm is a simpler, safer and easier haskell for the front-end. i just love it:)", "> perhaps this is more of an issue of expecting elm to be more like haskell than it is.some people have a hard time in elm because they expect elm to behave like a language that they are already familiar with. the most frequent impedance mismatch issues i've seen are reaching for `type-classes` or attempting to implement various polymorphic behaviors and people who are too hungover on imperative constructs (elm is declarative).once people start using elm the way it was designed to be used, things become simple and start to flow.", "> this is more of an issue of expecting elm to be more like haskell than it is.yep, that's it right there.i wonder if there's some way we could make it clearer that elm is not haskell, and trying to use it like it's haskell won't likely to lead to a good experience.at any rate, thank you for the feedback! it's definitely an ongoing communication challenge since the two languages have so much syntax in common.", "i love elm and i recommend it to everyone who wants to get into functional programming, especially haskell.additionally i'm glad.19 finally came out. but 18 months was really long.i'm guessing this was a good release point to show some major benefits, and i'm assuming that past 18 months was spent on more stuff that will come out later which is not ready yet.the main change seems to be a smaller codebase. which is great. this is done by dead code elimination and not including unused modules in addition of some incremental size reduction by record field renaming (replacing somereallylong.name with s.n). however some of the other concepts that supposedly was going to improve spas etc. are not released yet.", "congrats on the release! i have very high hopes for elm in the future, and i think it truly shifts the paradigm of frontend development.on an attempt to use elm in production i ended up switching back to javascript. the biggest issue i faced was lack of type-classes, which made certain parts of the code feel like i was pulling teeth to get elm's type system to be happy. perhaps this is more of an issue of expecting elm to be more like haskell than it is.i hope elm is able to get more adoption, and with it more examples of idiomatic approaches to problems in elm's style. however this somewhat feels like a chicken-and-egg problem.regardless, this release looks great for people using it in production already!", "for http resources, this is addressed in rfc7231 - essentially, servers may implement non-idempotent behavior such as logging for methods otherwise considered idempotent.", "i should've been better with the tone. my view still holds.i know programmers who've written large swaths of haskell and ocaml, who however reach for the eminently dynamic racket for its metaprogramming. they know the relative strengths of each paradigm better than most of us and have fine judgement. however junior programmers (<10 years) who haven't spent the effort required to learn other paradigms and are religious about whatever language they chose to learn as an accident of history are missing out tremendously.most of the static vs dynamic type research has always been about c++ based static types (which combines simula-67's object system with pascal's types - more history here: contrasted first against lisp and later with languages like python, ruby, and javascript. statically typed fp is totally different, and there are papers on either side of the bias to point to. i will recommend the elm language as a good starting point for anyone interested in seeing what typed fp truly can be.", "imo docker is a dead end, it essentially ended up being a glorified zip file, the real solution what docker was trying to do (reproducibility) is what nix does, and if nix is not a solution then something in that direction.in nix, you're basically describing the whole dependency tree of your application all the way to libc. when you build your application it builds everything necessary to run it.the great thing about it is that your cde essentially is identical to your build system, and the builds are fully reproducible, it takes over being a build system, package manager and as mentioned cde.they went even further with that (i have not explored that myself yet) and used the language to describe the entire system (called nixos) which looks like cms is no longer necessary and also nix is used for deployment (nixops, also did not tried it)if you are into containers you can still deploy into systemd lxc containers, or even create a minimalistic docker image.the disadvantage is that there is a significant learning curve, it's a new language, and it is a functional, lazily evaluated language. the language is not really that hard, but many people are not used to functional programming. it is especially popular for deployment of haskell code, since the language is also functional and lazily evaluated.", "cron works great when you don\u2019t need to guarantee execution, e.g., if a server goes down. unfortunately, all the alternatives are pretty heavyweight, e.g., jenkins, azkaban, airflow. i\u2019ve been working a job scheduler that strives to work like a distributed cron. it works with very little code, because it leans heavily on postgres (for distributed locking, parsing time interval expressions, configuration storage, log storage) and postgrest (for the http api). the application binary (~100 lines of haskell), polls for new jobs, then checks out and execute tasks. the code is here if you\u2019re interested: compiles to machine code, so deploying the binary is easy. that said, i\u2019d like to add some tooling to simplify deploying and configuring postgres and postgrest.", "i am 53 and i started to learn basic at the age of 15. i started writing assembly code about 2 years later to speed up the games i wrote in basic. i write a small amount of code almost every day (maybe 30 or so lines of mathematica code), but only rarely do i write 1000 lines a week. when i do have a busy programming week, it is rather fun. i really enjoy writing code in haskell. it reawakened my love for coding. i still don't understand it well, but i know it well enough to be able to convert almost any of my c++ code to haskell.", ">the underlying paradigms aren't that terribly different, but the actual terminology for expressing ideas idiomatically is wildly different, and represents an unusual obstacle.haskell uses a lot of terminology that's familiar to mathematicians, but unfamiliar to everyone else.cl uses a lot of strange terminology, because it incorporated concepts before their names were standardized and used in other languages. you're left spending a lot of time trying to figure out that a wheel is called a frob or you just end up re-inventing the wheel even though the frob was already in the standard.", "by the way, there is a project to \"implement a front-end for cakeml that accepts ocaml or haskell syntax\"> an involved version of this project would be to write a new verified parser for an alternative syntax. a simpler version would be to re-target the parser in the ocaml compiler to produce cakeml abstract syntax, and treat this as an executable specification. similarly for any haskell compiler that is amenable to such treatment.", "the main problem i had when learning cl was its standard library that at felt both enormous and strangely deficient in utilities for day-to-day work. clhs is fine but the definitions can be obtuse, navigation isn't all that easy, and it's just a generally daunting approach to learning a language. there's a big gap between the code you learn in practical common lisp and what you see if you open the source for any popular cl library.it's like haskell, without the hype. the underlying paradigms aren't that terribly different, but the actual terminology for expressing ideas idiomatically is wildly different, and represents an unusual obstacle.", "that's doubtful that high-assurance haskell is in much demand actually. people usually prefer much more strict (in both senses) languages for that, cakeml in particular comes to mind.", "for information about ghc's internals, i recommend reading the rts documentation is at", "that runtime system is huge. i remember it was an obstacle to high-assurance in haskell. is there a detailed write-up on what those 80,000loc do? maybe someone could redo it in one of the verifying, imperative languages like spark or ats to increase its assurance without full verification.", "there are many languages that make it explicitly difficult to pull directly from master. nodejs packages are near impossible to install directly from a repository, you always have to go through npmjs.com. haskell too (before stack became widespread), but even now most people install packages from hackage/stackage, where packages are strongly versioned.", "there are many things you say here that i can totally agree with. when speed of development is a concern and costs of runtime errors are moderate enough that one can absorb them, it would be a bad idea to use haskell (haven't used scala so not qualified enough to comment).somewhere along the spectrum of increasing cost to business of runtime errors the needle switches in favor of static tyoes. this is more true when you ship applications to folks who dont necessarily know or care about the internals. throwing runtime errors is just a bad form in those cases.when the code is going to be deployed on infrastructure you control, there is a lot more leeway to absorb runtime errors. the choice depends on how costly the runtime errors are and how costly are the fixes. time being part of the cost.", "i don\u2019t know. my primary corporate experiences with this are all in scala and haskell (with teams that have very veteran programmers in each), and the results were terrible.i liken it to david deutsch\u2019s comments on good systems of government in his book the beginning of infinity where he advised that the trait you should use to evaluate a system of government is not whether it produces good policies, but rather how easy it is to remove bad policies.languages don\u2019t cause people to invent better designs for mapping between the real world and software abstractions. they can provide tools to help, but they don\u2019t cause the design.but statically typed languages do create boilerplate and sunk cost fallacies leading to living with bad designs and accepting limitations that have to be coded around.dynamic typing compares favorably in this regard: it is very easy to rip things out or treat a function as if it implicitly handles multiple dispatch (because you can specialize on runtime types with no overhead and no enforcement on type signatures or type bounds), and quickly get feedback on whether a design will be a good idea, or what things would look like ripping out some bad design.i think exactly what you describe is the hyped up promise that static typing, especially in functional languages, fails to actually deliver in practice. you can still write production code that way, just incurring costs of maintenance of more code & boilerplate without the supposed offsetting benefits of catching more bugs, reducing runtime errors, or communicating design more smoothly in the type system, except in isolated, small parochial cases.", "> can someone explain why you'd want uninhabited types?uninhabited types are useful for expressing units.i'm writing an app that makes heavy use of a haskell library[1] that implements currency units and exchange rates using uninhabited types (type-level strings).so, one dollar will have the type `amount \"usd\"`, whereas one euro will have the type `amount \"eur\"` (both will have a value of `1`).an exchange rate from euros to dollars will have the type `exchangerate \"eur\" \"usd\"` (the first type parameter being 'source' and the second 'destination'), and its value will be `1.14` (the current exchange rate from eur to usd).a function for converting an amount in one currency into another currency unit will take two arguments: `amount src` and `exchangerate src dst` and return an `amount dst`.also, in general, it can be useful to:1. remove an argument from a function2. create an uninhabited type that, at the type level, represents the values of this argument3. tag the function's return type with this uninhabited \"phantom\" typebecause now you no longer have to remember from which argument some return value was calculated/derived: it's right there in the value's type.[1]", "i've wanted something like this for quite a long time. i've spent quite a bit of time trying to grok ocaml, haskell, and lisp syntaxes, and i've never gotten to the point where i \"see past the syntax\". even if you like these languages and their syntaxes, you should be excited about projects like these which help to bridge the cognitive gap between mainstream imperative languages and functional languages--more people getting exposure to functional ideas is a good thing for you--learning syntax and functional concepts in tandem is more difficult than the sum of the constituent parts.edit: sadly, this project hasn't been touched in 2 months.", "i\u2019ve used a lot of functional programming unit test tools, and i\u2019ve never seen any of them live up to the hype of checking corner cases in an automated yet comprehensive way.the marketing pitch for that is always something like quickcheck in haskell, where e.g. reversing an array should be its own inverse function and you can auto-verify this like it is a law across a bunch of cases.the problem is in real life unit tests, nothing has any laws like this, and it\u2019s just a bunch of bizarre case-specific business logic and reporting code. the concept of a corner cass is a semantic one, and the definition of what inputs are possible to a given function will change and have constraints from the outside world that not even the most expressive statically typed language will easily let you encode into the type system.combine it with the fact that your colleagues have variability in their skills too, and often won\u2019t make good choices with type system abstractions to represent business logic, and then all that costly extra boilerplate code for specifying types, creating your own business-logic-specific adts, adding privacy modifiers, templated or type classes implementations......it just becomes a big pile of garbage liabilities for what turns out to seriously be no benefits over dynamic typing.even in the static typing case, you\u2019ll end up with tons of runtime errors causing you to frequently revisit assumptions in the unit tests. you\u2019ll just have a harder time refactoring large pieces of code that are wedded to particular type designs and you\u2019ll have to sit and wait on the compiler to try every change (this can be hugely bad when the system has components needed for rapid prototyping, interactive data analysis, or other real-time uses).i\u2019ve really seen a lot of corners of this debate play out in practice, and static typing beyond extremely simple native types and structs (basically c style), really offers nothing while being a huge productivity drain. the claims that it actually helps productivity because the compiler catches errors and forces more correctness just turns out to be false in real code bases. you get just as many weird runtime errors and just have a harder time debugging or rapidly experimenting with changes.", "i don\u2019t use julia for speed but because it is so easy to use and powerful.haskell e.g. is very powerful and elegant but time consuming and hard to learn. lisp is easy to learn and powerful but has kind of clunky syntax.ruby has quite nice syntax and is quite powerful but also kind of messy. python is quite clean and easy to use but not as powerful.julia i would say has hit a sweet spot between all these languages. it is quick to learn and understand while also allowing you to write clean easy to read code. that may describe python. but with macros and multiple dispatch i would say it is a much more powerful language.i also find it much nicer than python to use as a script language as you got way more functionality out of the box.i am a c++ developer professionally, and write little julia script to help me with various boilerplate coding inn c++, processing assets etc. julia is really quick to drop into when you need it.with python i always forget which module some functionality is in. the name of a function etc. julia has much better naming most useful stuff is already invluded in the automatically loaded base module.", "i've only been learning for about a week, but i think if you're a nerd for language design, you will appreciate it on an aesthetic level as a very tight design around a powerful concept. common lisp also has multiple dispatch, but i feel the integration of it into all the nooks and crannies of julia really pays off. julia's performance doesn't appear as a side effect of building on the llvm or because they over-optimized the core, as it does in many young performance-oriented languages. instead, it appears as a tangible benefit of a multiple-dispatch oriented design that makes it easy to add information to the system to improve performance without compromising the clarity of a sketch.i have often felt that there are many discontinuities between \"pretty\" haskell as it is taught and pragmatic haskell. i haven't used julia enough in anger to say it for sure, but i see in the way it works great potential for the pragmatic code to be as beautiful as the high-level and abstract code.for a long time i have felt that haskell represented the most mathematical language. julia really shows that there are other ways of building a mathematical language with taste and style. it's oriented to practitioners and applied math folks rather than computer scientists and pure mathematicians. i have enjoyed seeing the differences between these systems quite a bit, and i think julia has a bright future as a practical, daily-use system for science.", "these examples don't really do dynamic scoping justice, and there are a few inaccuracies here.> a dynamically scoped variable can propagate downward, upward, or sideways (ie sibling methods in the call graph can access the values that you placed into the dynamically scoped variable).the binding only propagates downwards, never sideways or upwards.you can send values through bindings upwards, downwards, or sideways, but all you're doing is assigning a value to a memory location. this isn't particularly novel, because you can do the same thing with any other type of variable, or with fields in a structure, etc.> a dynamically scoped variable is basically just a global variable that isn't quite 100% global. so you can get into all the same problems that a global can get you into with the added benefit (or sometimes problem) that any two instances of a dynamically scoped variable might actually be different because they are coming from a different caller.this is no more a problem than it's a problem that when you call f(x), you might get a different value for x each time you call it, because x comes from the caller.the common use cases for dynamic variables are certain seldom-changed parameters for functions and maintaining context. the basic reason for using them is to avoid having to pass a potentially large set of variables through a potentially large number of intermediate functions. dynamic variables are most similar to thread-local variables.for seldom-changed parameters, consider standard-output (asterisks and hn don't mix). it's common to want to redirect the output of some block of code to a different location, in a shell script you could do this very simply:code_removed in lisp, you can do this by binding the standard-output variable:code_removed you can see that this isn't really some mysterious or dangerous phenomenon, it's a way to pass things down to functions without having to pass them as arguments. it's also commonly used for tracking the context of things like requests in a web server. in haskell you'd do this by using a reader monad, and in go you'd do this by adding entries a dictionary attached to your context.context object.", "look for functional programming data engineering jobs e.g. haskell, they might be what you're looking for, since most people don't run their algorithms in haskell (some do!) and use it as a duct tape/pipe.", "> single letter var namesthey are also a haskellers favorite.there's a non-sarcastic paper running on the internet named something like \"descriptive variable names considered harmful\". most of the community agrees with it, including me.", "isn\u2019t this just like a type system?i suspect that other languages seem even better as subjects for this kind of formal verification. haskell and rust come to mind. for the same reasons, go and smalltalk strike me as less suitable. (for those people who think i'm just a go and smalltalk partisan.)", "once you get past all the complicated math (honestly being into haskell has helped with this), crdts are actually very easy to understand, at least their semantics are.here's are some decent primer talks:john mumm - a crdt primer: defanging order theory -> illustrated\" by arnout engelen -> you want to see it in action:\"practical data synchronization with crdts\" by dmitry ivanov -> discovery using crdts by mushtaq ahmed and umesh joshi at fnconf17 -> also a talk with a guy sitting in a field which is the best i think i've ever seen, but i can't find it... but i can't find it in my youtube history:(as people reason more and more about distributed systems i think crdts will become (if they're not already) almost required knowledge, like paxos/raft.", "> a caveat to #2 is that depending on the language, it may be possible to override safety, for example haskell's fromjust can throw an exception if used on a missing value. but this tends to require conscious effort, and can easily be checked for automatically, since it involves the use of unsafe function calls.a much scarier example there is c++, where std::optional can be deref'd (literally `*opt`, the easiest and shortest thing you can do with it)\u2026 and just ubs on an empty optional. because c++ hates both type-safety and memory-safety.", "php is very much like java, only being dynamically interpreted. symfony is a very high quality framework, with which can build serious applications.python is surely nice looking, but as it allows redefinition of everything at runtime, it is impossible to optimize at compile time. i think php, with the recent type strictness functionality, is better positioned for making way to new developments like meaningfull code analysis, (compile time) optimizations and performant jit compilers. python is too dynamic for that, unfortunately. the same holds for javascript.i don't know ruby well, but i know it is also slow.the biggest problem with php is that it standards library has inconsistent naming. the syntax is very much java-like. if php would shove the standard library into `legacyprelude` (and have it automatically loaded like haskell) it could improve on that as well. this problem is not as fundamental as the other problems in my opinion, although still requiring a major effort to slowly turn to a new `prelude`.", "there has to be a way to represent a missing value, but the key point in languages that don't have null is that you can only represent missing values using a type that supports missing values - e.g. option types such as haskell's maybe.this achieves two things:1. it allows you to define functions that cannot return null, and the compiler guarantees this. this is a huge win - you no longer have null as a possible return value for many functions.2. values belonging to the option type have to be unwrapped to access their contents, so it's not possible to unknowingly dereference a missing value. this is an even bigger win than #1, because it can literally eliminate null pointer errors.a caveat to #2 is that depending on the language, it may be possible to override safety, for example haskell's fromjust can throw an exception if used on a missing value. but this tends to require conscious effort, and can easily be checked for automatically, since it involves the use of unsafe function calls.", "\"the flipside of easy-to-learn is there's no payoff for getting better with the language. your code will always be exactly as tedious as novices' code because they'd rather conserve compiler cycles than spend them to amplify programmers' work.\"in my years of experience with the language, this is, bluntly, untrue. go, used properly, is slightly more verbose than most comparable code in python or perl. if someone is writing code that is shot through with boilerplate in go, then i would say that they may be using \"oh, go just needs lots of boilerplate\" as an excuse.the problem isn't that go lacks abstraction mechanisms; the problem is that you need to learn how to use the ones that are there and not sit there pining for the ones that are not. i find this to be almost exactly like learning haskell; you need to learn to use what is there, not sit there pining for what you don't have. also like haskell, there are some particular points that it all comes together at once and hurts you, but, then again, there's some places in go where i've had big wins using the language features too. it does cut both ways. (i've done some fun things with interfaces, and the pervasive io.reader/writer support, while not necessarily a feature of the language, can make certain things amazingly easy to do while still retaining incredible flexibility.)as one example i went through personally, while by the time i learned go i had a lot of non-oo experience, so i wasn't as stuck on inheritance as someone who only did oo-languages for the last 10 years would be, i still had to adjust to using a generally-oo language (by my standard of the term) that did not support inheritance. it has now been literally plural years since i missed inheritance in go. (in fact, quite the opposite; i miss easy composition in my other oo languages! yes, virginia, it is possible to miss features go has when using other languages, despite what it may seem like if you only read the criticisms.) but my first couple of months were a bit rougher before i internalized how the composition works and affects the design of your code.complaining that go code is all boilerplate is like someone who tried haskell but complains that it's just an especially inconvenient imperative language and you end up doing everything in io anyhow. nope... you have not yet gotten past your \"writing x in y\" phase. that's fine; there's a ton of languages and platforms and libraries in the world. if you didn't get a short-term payoff from using it, go ahead and move on. but you haven't attained enough mastery to go around slagging on the language/platform/library yet.(and, again, let me say that, yes, it is somewhat more verbose that python or something. if you've shrunk your go down to that level, you probably went too far and are doing something ill-advised. but i find that in practice, for most tasks, it is not that much more verbose. there are exceptions, like heavy duty gui code or (imho) scientific code; the solution is not to use go for those.)", "i just made this choice (learn fsharp or oval). initially i was leaning ocaml for the same reason as gp but then i tried a simple scraper (make a get request and parse the html) and couldn't get it to compile because of cabal hell. well obviously not cabal hell but dependency hell where i had to keep changing installing and uninstalling versions of cohttp and the compiler. in the end i said screw it and installed all the.net/mono/f# stuff and it worked flawlessly the first time. i don't understand how language developers don't prioritize package management in 2018 - it's simply a deal breaker when other languages get it right. yes i realize ocaml and haksell have a different perspective on dependency resolution than other languages but then they should ensure that it works (and yes i also realize dependency resolution is np complete).", "most languages, sure, but not all; haskell doesn\u2019t have null. you can express the absense of a value with a maybe:code_removed if your function returns a \u201cmaybe string\u201d, it can either be just a value, or nothing. however, if a function returns a \u201cstring\u201d, you can\u2019t return nothing, only an actual string.there\u2019s no null in haskell.", "i feel that way when people write anything in a functional programming language.\"here's this lovely new functional language!... written in haskell, using haskell's entire runtime as a basis.\"", "> as for vt-d, i believe the unlocked \"k\" processors from intel all have vt-d disabled for some reason.this was only the case up to haswell cpus. they stopped crippling iommu capabilities since haswell refresh (i7-4790k).", "thank you for taking the time to explain the background.i totally agree that consultants working from quantitative data about past projects are much better than the usual cargo cults.however, there are a lot of dangers in the process:- if you are a consultant in automotive embedded software, you will be contracted for these projects, so your data will be quite useless to guide startup web application development (for example, loc can make sense for embedded c, but not for languages like scala or haskell, where you can implement the same feature elegantly in 100 lines or clumsily in 1000).- as consultant, you want to generate revenue. so there is a strong incentive to oversell how solid your insights are. there is no counter-force in place to balance that bias out.- while scientific publication is somewhat broken, it is (in cs) a quite good quality control with respect to scientific method. the book did not undergo any quality control by other experts. so now it becomes a matter of personal trust towards the author.summarized, i think that practitioner's data collections and their personal reports about them are useful in some cases, but cannot replace scientific empiric research.", "a bit off topic, but would be great to use sqlite in the browser instead of indexeddb.i love relational databases, but you're almost forced into a nosql approach when developing a spa since the client (browser) only supports simple key -> value storage. it would be a dream to use linq-to-sql, or similar type safe query dsls like slick or quill (scala), or esqueleto (haskell) in the browser.combine that with a single language driving the backend and frontend and voila, no duplication of model, validation, etc. layers on server and client.one can dream i guess, but the reality is nosql fits the modern web app like a glove, for better or worse.", "this book review has a few economic fallacies and was probably not written by gates. but, these points are interesting--\"it\" refers to \"intangible investment\" here--1. it\u2019s a sunk cost. if your investment doesn\u2019t pan out, you don\u2019t have physical assets like machinery that you can sell off to recoup some of your money.2. it tends to create spillovers that can be taken advantage of by rival companies. uber\u2019s biggest strength is its network of drivers, but it\u2019s not uncommon to meet an uber driver who also picks up rides for lyft.3. it\u2019s more scalable than a physical asset. after the initial expense of the first unit, products can be replicated ad infinitum for next to nothing.4. it\u2019s more likely to have valuable synergies with other intangible assets. haskel and westlake use the ipod as an example: it combined apple\u2019s mp3 protocol, miniaturized hard disk design, design skills, and licensing agreements with record labels.", "thanks, that looks very good. unfortunately clojure and i don\u2019t really click. i have about two years professional experience with clojure but except for my site i don\u2019t much use clojure for personal projects. i prefer common lisp. for functional programming, i would substitute haskell for clojure except my haskell skills are so-so.", "steps to understanding call/cc (for c programmers):code_removed presto, you have call/cc.shorter: allocate function frames on the stack, reify the return function argument closure and call it the continuation. to \"reify\" means to give reality to something that was previously hidden / implied.call/cc looks really awesome until you realize that it has / causes problems. one problem is that if you hold on to a reference to a continuation then you're actually preventing gc of all the stack frames captured by that continuation. then there are thread safety issues... any language that has variables (as opposed to lexical, immutable bindings) will have thread safety problems. imagine using closures as callbacks, and having said closures change variables they close over, and now imagine them racing against each other to modify the same variables. well, in a scheme continuations are strung-up closures, so now imagine multiple threads trying to call the same continuation. these thread-safety problems run deep, and will tend to push one towards haskell or rust.really, call/cc is a bit of a parlor trick:) -- a fascinating parlor trick, but still a parlor trick.if you want much much more detail, i recommend two great books that deal with this subject:code_removed in on lisp, paul graham has a chapter where he builds a set of macros that give you scheme-style continuations with minimal compromises in how you write lisp code.lisp in small pieces is all about writing lisp/scheme interpreters and compilers, so it touches on all of this depth and great detail.", "i wonder what new language bindings they will support. i have experimented with saving keras models, converting to racket scheme, and writing a runtime. it would be way better to have it officially supported.haskell support has worked ok for a while. the languages i would most like to see supported are common implementations of common lisp like sbcl and clozure. i think there is some future for hybrid connectionist and symbolic ai and it would thrill me to have common lisp support for tensorflow.", "location: new york, nyremote: yeswilling to relocate: notechnologies: haskell, rust, scala, gor\u00e9sum\u00e9/cv: hello@alexeyzabelin.comi like haskell, rust, and contributing to open source projects. i've been doing web dev in haskell for the past year, would like to keep working on something that involves fp.", "nope.i look on the job boards and trusted recruiters emails to see where there is a balance between the number of openings and the pay. i don\u2019t see any openings for rust or haskell locally.ughhh did i just say \u201chire salary\u201d instead of \u201chigher salary\u201d.", "what if the stack is a niche, like haskell or rust?haskell devs claim to have plenty of work because there are few of them, and rust might be very marketable in a few years.would you work on either of those?", "lennart augustsson implemented a jit for basic as an edsl in haskell using llvm.a blog post he wrote about it: jit itself:", "people are working on making haskell compile to web assembly.[0] [1]", "> so proofs and programs are isomorphic. we know there are programs which never halt and we know there are programs for which we can not algorithmically decide whether they halt or not. what is the equivalent thing in proofs? are there proofs which never halt?yes; a \"proof which never halts\" is an invalid attempt at a proof (so not really a proof).to a first approximation, the curry\u2013howard correspondence says that programming and proving are the same. this is literally true if \"programming\" and \"proving\" are restricted to mean more specific things. (there are many variants of the curry\u2013howard correspondence. the simplest one relates \"simply-typed lambda calculus\" with \"propositional intuitionistic logic\". simply-typed lambda calculus is basically what you get when you take python, strip everything away except for the keyword \"lambda\", and add types. intuitionistic propositional logic is basically what you get when you take ordinary logical reasoning, strip away quantifiers (\"for all\", \"there exists\") and force yourself to never use proof by contradiction. there are also variants for more powerful programming languages and more powerful logics. the case of classical logic, where we can use proof by contradiction, is particularly interesting, since the translations of such proofs make use of continuations. see but in a wider sense it's false: invalid proves aren't very much worthwhile, while non-terminating programs can be. thus a better approximation is \"programming strictly encompasses proving\".> is a proof really isomorphic with a program as written in source-code, or is it isomorphic with the execution of a program with a given input?the former.> a program and its execution are not the same thing are they?correct. a program is a piece of a text. its execution is (for me, in this context) the final value computed by the program. (the curry\u2013howard correspondence is easiest to understand when we restrict to programs in a purely-functional programming language like haskell.)> but with proofs i find it hard to think about the difference between the \"source-code\" of a proof and the \"execution\" of a proof. is there such a thing as distinction between the execution of a proof and the \"source-code\" of it?i'm with you; the reason the difference is hard to see is because while we run programs all the time, we almost never run proofs. however, yes, indeed, you can run proofs. the result will be a \"proof certificate\", something like a proof with all intermediate definitions unrolled and then maximally simplified.quite different-looking proofs (texts) can yield the same \"proof certificate\" when ran, exactly as different-looking source codes can yield the same final value when ran.here is an example. consider the following proof (due to euclid) of the fact that there is a prime number greater than 6: \"like any positive natural number, the number n = 1\u22c52\u22c53\u22c54\u22c55\u22c56 + 1 is a product of prime numbers. however, no number between 2 and 6 is a factor of n, since dividing n by any such number will always leave a remainder of one. hence all the prime factors of n, for definiteness pick the smallest one, are prime numbers greater than 6.\" the proof certificate obtained by running this proof will be the pair (7,...), where \"...\" is a certificate that the number 7 is indeed prime. the reason the number 7 appears here is because 1\u22c52\u22c53\u22c54\u22c55\u22c56 + 1 = 721 = 7 * 103. if the proof picked the largest factor instead of the smallest, the result of the proof would be the pair (103,...) (with a different primality certificate).running proofs is becoming a more important thing nowadays, thanks to the development of good proof assistants and homotopy type theory. (while in principle it's possible run proofs manually, like in the previous paragraph, it's only fun when a computer does it for you.) for instance, a mathematician might prove that some particular structure of interest only contains finitely many elements, without having a clue how many values there are. if she runs the proof, the computer will tell her the answer. the catch is that with current (mathematical) technology, she might have to wait quite a bit for the answer. (the in my circles famous \"brunerie two\" comes to mind: this is a proof where we know the answer to be the number 2, and made much progress in pimping the curry\u2013howard correspondence, but aren't quite there yet. see", "i was left wondering \u201cisn\u2019t what he calls effect really similar a haskell monad?\u201d for a large part of the article. i was really glad to see my novice fp insticts were right!", "i'm not against the repl (perhaps i should even describe its usage in more detail). in fact, i use it all the time. i'm against books like learn you a haskell that leave the reader wondering how to make and distribute executable programs. or, worse, create an impression that it is not even possible, if the reader is not motivated enough to read another book or blog posts.", "yup, and code formatting:", "what i see is a typical mat crunching code, just like you would see in c++ or fortran, nothing haskell specific.haskell examples you've attached are better commented than, say, eigen to mention openblas", "no real minuses discussed here so i thought i'd share some from my fp journey, which was sml -> ocaml -> haskell -> clojure. each had its own sort of enlightenment, both in strengths and weaknesses.imo an under-appreciated weakness of haskell is its culture of poor code quality and engineering practices, e.g. in how code is structured, (not) commented, or named.example, inspecting a graph in haskell via fgl, we encounter the foundational decomp type [1]:code_removed `a` and `b` are types, and in languages geared towards engineering, we would give them actual names: a is a nodetag and b is an edgetag. but in haskell it is customary to not provide this information, instead falling back on the type checker to ensure the code is consistent. there is not much effort put into useful naming: map vs mapm vs mapm_...second example, the simplex algorithm [2]:code_removed this code is astonishingly compact, but totally impenetrable. it has no comments, useful names, etc. this write-only code is typicalhaskell and its culture have significant weaknesses from an engineering perspective.1:", "i regret not listening to people\u2019s advice about this sooner and spending a lot of time looking for the best haskell ide / development tools. in the end, everybody else was right and unfortunately, the current state of the available tools is not good enough. the process that most people seem to use, and the one i also adopted is using my favorite text editor with syntax highlighting.wonderful. that's like driving a lamborghini with a school bus steering wheel.", "a issue with today's programmers is that they require instant gratification from their programming languages. remember that it takes a large investment to learn a foreign language. the more you learn, the more you can express. haskell and fp takes times to master because they are powerful tools that allow you to express complex ideas succinctly.that's not a selling point unless the roi on that time investment is good. it's a problem with the language and not programmers if there isn't a more gentle learning curve.", "i would recommend programming in haskell by graham over other introductory texts. not only is it a small read, graham does a great job of avoiding the mire and excells at teaching critical concepts with simple examples. you're better off reading programming in haskell three or four times than reading some of these more intricate or simplified texts once. it will give you a groundwork of the fundamentals, and you will not have incorrect definitions of important concepts.the key to haskell is to think like a functional programmer. most of us are trained to think in ways other than functional programming. this is a skill that takes time to build, and a book can't necessarily impart upon you.a issue with today's programmers is that they require instant gratification from their programming languages. remember that it takes a large investment to learn a foreign language. the more you learn, the more you can express. haskell and fp takes times to master because they are powerful tools that allow you to express complex ideas succinctly.so don't get discouraged if it seems foreign, it is. with haskell you can say a lot with a little, and it will pay dividends for years to come.", "good writeup, short but some interesting comments and links.i have also had a journey with haskell. i really enjoy haskell and have worked hard on developing skills. that said, there often seems to be other languages that seem better for me, for individual projects. machine learning? usually need to use python. web development? hard to beat rails for productivity. enterprise systems? it is usually written in java. doing \u2018research programming\u2019 to explore data and ideas? i usually favor common lisp, but sometimes use haskell.for me, i think haskell will always just be a language i very much like but only occasionally use.", "reading python involves a lot less mental translation than reading haskell. i wonder why...", "some other type features that ocaml has that haskell doesn't are polymorphic variants and structural polymorphism (row types).", "this was really interesting and helpful. thank you for taking the time to type it all out.you inspired me to learn ocaml because i've never thought of it as a language that's capable of expressing things that haskell just can't.", "> i think the best answer is \"the one you're interested in\" or maybe if you have a goal then use that?ding ding ding, this is the correct answer. something you have a vested interest in will always be infinitely easier to learn than some random thing someone else (who likely _is_ interested in it) suggests because they said it was easy.for example, while not exactly a \u201csuper simple\u201d topic, at work part of my responsibilities include maintaining/developing etl jobs for copying data from a few data warehouses to local app dbs. i absolutely dread anytime i have to spend any amount of time working on these, i find it boring, the software terrible, the problems tedious. and, i\u2019m certain if i spent a fair amount of time really learning the technologies/patterns/etc, it wouldn\u2019t be nearly as much of a chore. and, given i\u2019m not working with google level terabytes of data, only a few 100 or so gigs, the scope of what i\u2019d have to learn likely isn\u2019t terribly difficult. the problem is though, i have absolutely no interest in doing so, i only work on them because i inherited them, and if i were to need to do the same thing from scratch, i\u2019d likely try something other than \u201centerprise\u201d etl frameworks, or more realistically try my damndest to find someone that actually likes doing this kind of thing so then i don\u2019t have to worry about it.contrasted to about a little over a year ago, i got super interested in ci/cd and containerization technologies. i started having no experience with ci, docker, and really only having deployed things to heroku. however, i was fairly quickly able to get up to speed with the basics of the technologies, and then a short time after that i became the \u201cdocker & ci\u201d guy at work, i found that i was able to quickly and (hopefully) competently answer almost any question/issue coworkers were encountering. i now spend a fair amount of time configuring ci and containerizing older apps in our portfolio just because i thought it was fun/interesting to do, which provided me with even more opportunities to learn and find gaps in my knowledge. but, to some others, spending any amount of time configuring ci, fighting with a legacy codebase to get it\u2019s test suite to run in a containerized/ci environment, and building security scanning practices likely sounds absolutely dreadful, tedious, or a waste of time.so, whatever you have an actual interest in learning completely will be the easiest, whether that be machine learning, full blown functional programming in haskell, enterprise java oop, application architecture, compiler/language development, or even something as deceptively \u201csimple\u201d as building cli tooling. anything someone advertises to you as \u201ceasiest to learn\u201d is something that person themselves are interested in, which is why to them it was easy, but if you don\u2019t give a shit about it, it likely will be a chore and far from the \u201ceasiest\u201d.", "basically no. the closest thing in rust is traits. but then this is like saying that haskell basically has ocaml functors (functions from modules to modules) as typeclasses which isn\u2019t true.some of what functors do can be done with typeclasses/traits. eg a functor might take a module with a type and compare function and produce a type of maps fron that type. meanwhile in haskell/rust you get the compare function from a typeclass/trait.on the other hand you can only have one trait/typeclass implementation per type which requires newtype wrapper awkwardness if you want an alternative. another problem is that traits tend to be basically small but functors can be big. eg let\u2019s say you want to write an application for transferring files over various protocols. you might implement a module per protocol which would include things like the type for the configuration, how to read the config, how to make a connection, how to pool connections, how to request a file, how to get chunks of it and so on. these things may not fit so well into a nice typeclass and some haskell people certainly don\u2019t like typeclasses that don\u2019t correspond to mathematical things. in ocaml the file transferring program might be based on a fuynctor applied to each protocol.a second thing rust/haskell don\u2019t have is a way to make a typeclass at runtime whereas one can do that in ocaml, e.g. it\u2019s basically impossible to make a safe type for arithmetic mod n in haskell/rust if n must be known at runtime. it is actually possible with reflect in haskell but that is horrific. it would be nice if one could do something like:code_removed but you can\u2019t. on the other hand not having any way to implicitly know how to serialise or compare things in ocaml is sad.", "i think saying that \u201cf x\u201d is in any sense more mathematical than \u201cf(x)\u201d is stupid. ask a mathematician and you may find they prefer \u201cfx\u201d, \u201cf(x)\u201d, \u201cf[x]\u201d, \u201cxf\u201d, \u201cf.x\u201d, \u201cx.f\u201d (does this make oop mathematical then?), or something else entirely. perhaps they just write f and never mention x.using lots of operators is certainly something that could be seen as more mathematical but then i guess that makes apl much more mathematical than haskell and ocaml and c++ and perl combined. i don\u2019t think that counts as mathematical but it is a difference of style.for specifying signatures this is surely a style thing. in type theory, types are normally put right next to the values and so in this respect haskell and ocaml are not mathematical. i say this is a style thing as one can write types separately from variables, next to them, or not at all.for \u201ctypes not being a namespace\u201d i\u2019ll give you that criticism for haskell (but also for c) and maybe for ocaml but recall the common idiom of calling all types \u201ct\u201d and putting them in their own modules with relevant functions. i don\u2019t see how this is more mathematical.my general complaint is that these aren\u2019t differences on a more/less \u201cmathematical\u201d spectrum. the only mathematical things are that ocaml/haskell are closer to lots of the fashionable plt research than c and that research is certainly mathematical. also haskell people tend to fetishise category theory and abstract algebra so lots of the code that\u2019s written is sort-of mathematical. haskell also suffers from readability problems mainly due to the people who write haskell and what they like rather than the language itself.", "it's always been funny to me as a functional programmer that python took off. people always talk about how much quicker it is to write code in python, and 99% of the time i find the python code to be more complex than the ocaml/scheme/haskell/common lisp equivalents (minus, of course, the library support).", "1. it's definitely been slower than i would have liked. a lot of developments have been hyped up a lot, when in fact they are years away. modular implicits (which approximates haskell's type classes) and multicore have been in the works since only a little bit after i started using the language. at the time, they were kind of described to me as being \"right around the corner\" but failed to appear. there have certainly been lots of good additions to the language apart from this (e.g. we got a great inliner called flambda), but it seems like it's still gonna be >=6 months before multicore lands and possibly a year or more before modular implicits makes its way into the mainline compiler.2. i think it's kind of a bittersweet future. i think growth is decelerating for ocaml because of reasonml/bucklescript making it really easy to get started with ocaml and use web libraries. this is great because it brings exposure to the language, but i think it's caused a number of people to switch over from native to web, which means abandoning some of the ocaml libraries for their web versions. ocaml has a great native backend and it's really a shame for me to see it fade away, but i think in the long-run that's probably going to happen. still, i think popularity of reason will continue to go up and that will bring ocaml into the mainstream for hopefully long enough to garner some attention and get people to take the native backend seriously.3. i'm currently working for equity at a very small startup i co-founded but we're using reasonml for the web side of things. previously, i was at an internship where i had a lot of freedom to use whatever i wanted and was paid to write some software in ocaml. i think finding a job writing ocaml is rather difficult, but introducing it in a job (especially for internal tools or web development with reason) is much, much easier. the \"big\" ocaml jobs seem to all be at companies where it's really hard to find employment (jane street, facebook, bloomberg), but occasionally you'll see some smaller ones pop up online.", "> want to elaborate that? afaik, neither of them tries to imitate mathematics.generally speaking, \"f x\" instead of \"f(x)\" meaning function application, types not being able to serve as namespaces for functions, arguments' types in signatures being specified separately from their names, and most importantly the preference of first-class operator symbols over function- or method-calls.* * * * *for example, i find this much more difficult to read (from hakyll):code_removed... than if it looked like this:code_removed (insert grating reminder here that rust still doesn't have monads. haskell's notation may be poor, but its semantics are anything but.)", "i'd argue that the typecasting in that last paragraph may not be realistic.> but more importantly... to business's eyes, rust is too immature, scala and f# inherit all the billion-dollar mistakes from their parent vms, julia is a data-scientist's tinker-tool and haskell is too great a paradigm-shift for most programmers. so ocaml is far from being \"dead\", let alone meriting death.in my previous business, we used perl, c/c++, julia, a little python, and others. we aimed specifically for the best tool for the job. rarely, if ever, did one language fit the bill, covering everything we need.i've not used ocaml, so i can't talk to this. i can state, emphatically, that julia is far more than you indicate. i am rust-curious, though haven't found a good reason to spend time with it at $dayjob. similar for perl6, and other more modern languages.if you advocate a language for the sake of the language, rather than the set of problems you can efficiently express solutions to in that language, i'd argue you might be missing the point of the language. paraphrasing iverson on this, language and notation are tools for expressing thoughts. no single notation/language is perfect for all thoughts.", "> that tries to be a pale imitation of mathematics but gets it even wronger than haskellwant to elaborate that? afaik, neither of them tries to imitate mathematics.> namely a good combination of footgun protection and expressivenessnone of those languages have parameterised modules, ocaml is far more expressive in some fronts.", "i'll grant that ocaml has a ghastly syntax that tries to be a pale imitation of mathematics but gets it even wronger than haskell; that it has a lot of runtime overhead compared to c; and that what you gain for these sacrifices - namely a good combination of footgun protection and expressiveness - is also available elsewhere (rust, julia, haskell, and to a lesser extent scala and f#).but i wouldn't call it \"dead\" per se. at worst, the knowledge easily transfers over to haskell, scala or f#. (sadly these languages all abstract-away most of the knowledge needed to write good, fast rust code.)but more importantly... to business's eyes, rust is too immature, scala and f# inherit all the billion-dollar mistakes from their parent vms, julia is a data-scientist's tinker-tool and haskell is too great a paradigm-shift for most programmers. so ocaml is far from being \"dead\", let alone meriting death.", "my comment from when this came up on reddit, slightly edited for context:`/`-by-0 is just an operation and it tautologically has the semantics assigned to it. the question is whether the specific behaviour will cause bugs, and on glance that doesn't sound like it would be the case.principally, division is normally (best guess) used in cases where the divisor obviously cannot be zero; cases like division by constants are very common, for example. the second most common usage (also best guess) is to extract a property from an aggregate, like `average = sum / count` or `elem_size = total_size / count`. in these cases the result is either a seemingly sane default (`average = 0` with no elements, `matrix_width = 0` when zero-height) or a value that is never used (eg. `elem_size` only ever used inside a loop iterated zero times).it seems unlikely to me that `/` being a natural extension of division that includes division by zero would be nontrivially error-prone. even when it does go wrong, pony is strongly actor-based, has no shared mutability and permits no unhandled cascading failures, so such an event would very likely be gracefully handled anyway, since even mere indexing requires visible error paths. this nothing-ever-fails aspect to pony is fairly unique (haskell and rust are well known for harsh compilers, but by no means avoid throwing entirely), but it gives a lot more passive safety here. this honestly doesn't seem like a bad choice to me.", "there is no golden path here. checked exceptions for division would make a lot of pony code objectively worse. unchecked exceptions are great for php, haskell, rust or go, but pony is trying to do something different - to literally make it impossible to panic in an operation without describing that in the type system. the ergonomics of divide by zero in this context are absolutely debatable, not an issue to dismiss out-of-hand.", "this kind of type becomes really tedious to use unless there is some sort of viable \"subtyping\"\u2014you certainly want to be able to use a non-zero number where any number works and, ideally, you want to be able to recover a non-zero number when you write a function that takes in a normal number and always returns a positive value. if you're forced to use a bunch of explicit conversion functions to achieve this you add a lot of noise to your code and, generally, the most common function is going to be along the lines of \"i know this is positive, so throw an error if it's 0\"\u2014which is exactly what we get anyway.explicit might be better than implicit most of the times, but it is possible to be too explicit.that said, we can achieve this, although it's probably a bit trickier than you'd think at first. the best option i know is called \"refinement typing\", which basically allows you to specify types as subsets (ie \"the set of integers which are not 0\") and automatically verifies whether your functions actually return a value in the subset.liquid haskell[1] is an example of a system you can use today to play with the idea. it uses an automatic logic solver (z3) under the hood to automatically prove that your refinements hold. (for example, i believe it should be able to automatically verify that the function f x = abs x + 1 will never be 0.)[1]:", "for those considering learning ocaml, i thought i'd share my (admittedly biased) thoughts about the language as a long-time user (well... roughly 4.5 years).out of all the languages i've learned, ocaml is one of the few that i would consider to be a \"sweet spot\" language. a lot of people seem to have one language that they tend to fall back to when they're not sure what else to use because they find it most practical, whether or not they enjoy using it as a language. out of the languages i know, it's pretty much between java and ocaml for me, with ocaml being much more ergonomic. writing ocaml code is much more relaxing than most other languages i've encountered because everything is quite predictable once you know the core language, but it features a multitude of tools that you can use to approach any task (oop, modules, functional programming, imperative, low-level, high-level, metaprogramming, etc.). i also think that opam is one of the best language package managers around (for example, it comes with native support for having multiple copies of the ocaml toolchain installed in parallel). finally, reason+bucklescript have become really nice and for web programming i think they offer one of the best options.there's still a few things that are far from perfect, though. ocaml still lacks an equivalent to haskell's typeclasses and that makes designing good generic libraries a pain (it's still possible using modules+functors, but it takes a little boilerplate because it's not implicit). as a side effect of this, the standard library is pretty fragmented between the official one (aka \"things we used to write the compiler so you can keep them if you want\"), the batteries library (which is essentially what the standard library would be if the official one was \"finished\"), and jane street's core library (which replaces the standard library altogether). the problem is that this extends into basically all of ocaml. for such a small language, there's little room for all the competition and that means that a lot of libraries either don't exist or aren't actively maintained. that said, most libraries are a breeze to implement and for the real-world code that i do write, they are hardly a distraction 99% of the time. the only other downside is that opam isn't compatible with npm, which means that bucklescript (the ocaml->js compiler) has a totally separate ecosystem from the native compiler.tl;dr, if you're looking for a very general language to learn and don't care about having to implement your own libraries, ocaml is one of the best choices out there. if you're doing js programming, it's worth taking a look into reasonml/bucklescript.if you're interested, feel free to ask me any questions about the language/ecosystem/learning.", "a repl is an incredibly useful tool for all sorts of development, \"real\" or not. but i share the author's frustration with intros to functional programming that take advantage of a repl to provide small, context-less examples. it makes it hard to see how i could use the language in for a complex project with significant side effects (e.g. file/network io).real world haskell[1] is a great example of an introduction that provides small examples and situates them in the context of programs that i could see myself actually using.[1]", "i sort of lost interest in what else the author had to say at this early point, despite having been interested in ocaml for many years. (referring, for context, to the \"do not make it repl-centric\" comment in the article.)in common lisp, clojure, scheme/racket and haskell, i constantly develop with the repl. i also use it in other languages such as ruby which are not necessarily repl-centric.i find that i write much better (less buggy) code, faster, in a language with great support for a repl.", "not sure about this specific paper, but i've been following john tromp's work on this for a while. its current homepage seems to be on github paper assumes knowledge of combinatory logic and lambda calculus, which you could probably find videos about. this paper uses pretty standard notation, so almost any video/course/book/blog/etc. should be ok. the main thing this paper does is to define a way to encode such programs as a string of bits.note that combinatory logic is one of the simplest turing-complete programming languages, but it's so simple that it's basically unusable for anything more elaborate than toy examples (the paper actually has a quote from chaitin saying this!). once you're comfortable playing with little examples containing a handful of symbols, that's basically all you really need.there's a nice book of mathematical puzzles which is actually based on combinatory logic. this is why combinatory logic terms are sometimes referred to as \"birds\", e.g. in this haskell library: you're familiar with other programming languages, it's usually pretty easy to implement combinatory logic and play with it. for example, here are 's' and 'k' in javascript:code_removed this isn't quite right, due to most languages using strict evaluation, but the following haskell is essentially correct:code_removed there's also the esoteric language \"unlambda\" which implements these directly, including the \"monadic io\" that the paper mentions calculus is more tricky than combinatory logic, since it contains variables. it's also more widely used (e.g. as the basis for many functional programming languages, like haskell and scheme), so there should be more material available. in essence, when you see something like:code_removed you can think of it as acting like this javascript:code_removed when it comes to kolmogorov complexity, maybe the wikipedia page and its citations will help ( )? notice that all of the definitions, etc. on that page assume that we're talking about some particular programming language or machine, but the examples use pseudocode rather than a \"real\" programming language. this paper is basically saying that we should use lambda calculus as that language, and we can measure the size/length of a program by encoding it as binary according to the method given.", "unfortunately the arbitrary \"leave everything un-optimized\" also misses the point because in practice we don't.> (d)evolves into a lookup tablewe can make the arbitrary decision not to accept that, and instead try to use our best judgement on what optimizations to accept.\"one can, with sufficient effort, essentially write c code in haskell using various unsafe primitives. we would argue that this is not true to the spirit and goals of haskell, and we have attempted in this paper to remain within the space of \"reasonably idiomatic\" haskell. however, we have made abundant use of strictness annotations, explicit strictness, and unboxed vectors. we have, more controversially perhaps, used unsafe array subscripting in places. are our choices reasonable?\"", "depends on the language too, i suppose. i'd be more shocked if they said they had never used recursion, but were using haskell at work.", "as a layman, it is a personal aspiration to be able to understand this precise paper. it's very appealing to be able to express and reason about the related problems of complexity and edit distances using a generative(?) notation like lambda calculus that you can hack on in accessible languages like haskell.i also like that the citations include emperor's new mind; godel, escher, bach; the brainfuck homepage, and haskell. the effects of these ideas on a couple generations of young minds is bearing fruit.it feels like we're on the brink of gamifying a lot of important math.", "if you like this see also [1], and joy as well as iota and jot[2] (programming languages). and maybe \"algorithmically probable mutations reproduce aspects of evolution such as convergence rate, genetic memory, and modularity\": in the context of his metabiology programme, gregory chaitin, a founder of the theory of algorithmic information, introduced a theoretical computational model that evolves \u2018organisms\u2019 relative to their environment considerably faster than classical random mutation. while theoretically sound, the ideas had not been tested and further advancements were needed for their actual implementation. here we follow an experimental approach heavily based on the theory that chaitin himself helped found. we apply his ideas on evolution operating in software space on synthetic and biological examples and even if further investigation is needed this work represents the first step towards testing and advancing a sound algorithmic framework for biological evolution.[1]", "the original ml language (the one produced as part of the lcf theorem prover), did have a `where` clause that works like the one in haskell. see here for example: brief skim over the revised definition of standard ml indicates that it was abandoned at some point. i've no idea if caml or ocaml kept it.that said, i'm reasonably sure that the syntactic construct (insofar is it is used in programming languages) originated with the iswim introduced in this paper, which was rather influential in its day, perhaps especially in the functional programming community.", "french software engineer working at startups in paris since 2010 here.> what's the startup scene in paris like?booming. a bit too much, if you ask me.the ecosystem started growing fast when i arrived, basically. in 2011, the first real startup accelerator (le camping) opened. at that time, there was a very interesting meetup for the parisian hn community called paris hackers, with very interesting people including founders of docker (then dotcloud), capitaine train (acquired by trainline), etc.today i would say there are at least 10x more startups and 20x more people working in them, which resulted in the average level of people in the ecosystem going down. there are accelerators and incubators everywhere, as well as very interesting things like efounders ( meeetups have grown unwieldy large (e.g. the machine learning meetup is often having a hard time finding rooms large enough to fit its 200 - 300 people per session).as for companies, some startups have become large (criteo, leboncoin, blablacar,...); some are obviously growing fast (algolia, aircall, platform.sh,...); some (like moodstocks where i used to work) have been acquired by us companies which have set up offices in paris, among other things to tap into the well known talent at french research labs in cs and ai (google and facebook in particular). to accompany all this, more vc funds are opening and rounds become larger and larger.there is a lot of good to all this, but personally i feel like this is kind of a bubble and i miss the time, not so long ago, when we were all a bit more reasonable.> how good does my french need to be?it depends on the company. i would say most tech startups do most of their written work (including chat etc) in english. people might still speak french, but will switch to english when non-french speakers are around if they want to.> are there any languages/platforms/etc. that are popular there more than in silicon valley/fairfax county (the places i'm used to working)?i would say the obvious one is python for web backend. the french (and european in general) tech community has adopted python a lot more while the us was going with ruby. some of the larger and older startups use a lot of scala as well. newer companies tend to use go.there are interesting startups using less popular stacks, especially functional programming. what is propably the largest french startup, vente priv\u00e9e, is using some haskell, and so is (whose cto is a former capitaine train cto). is building a bank from scratch with elixir and scala (the ceo is the former ceo of capitaine train). there are a lot of erlang people around too.as you may see i mentioned capitaine train a lot because this is how the ecosystem is growing: thanks to disaporas of people from acquired startups (\u00e0 la paypal mafia). a few years earlier it was exalead ( you need more information feel free to get in touch. my email address is on my home page, which is linked in my hn profile.", "i really didn't enjoy the book when i read it in ~2014 i think. it's a pain to get set up with emacs and then it walks you through functional programs without introducing anything first. and it is indeed difficult to grok, especially because they are toy programs with zero real world value. in that sense, i'd compare it to learn you a haskell for great good, but with less context.this[0] is a better way to learn, in my opinion.then after that, maybe check out brian will's videos[1].then definitely check out this helpful video on web dev[2]. there's a better video somewhere but i can't find it anymore. it's just a guy walking his friend through how to make an isomorphic clojure web app. very nice pair programming walkthrough guide. but i guess it's forever gone.[0]:", "i don't think ml has the `where` clause. haskell got it from miranda, which got it from sasl, which got it from iswim.", "haskell's one language i know which has a `where` similar to the one described in the article.", "ocaml and haskell do have exceptions, though.", "go and rust have very different mechanisms, due to very different world visions.1 - exceptions do suck. it's obvious in haskell where there are better tools but sometimes you aren't allowed to use them.2 - rust thus goes into: well, let's take those better mechanisms and allow them everywhere. go goes into: well, let's create some alternative mechanism like the ones most people are used to.3 - rust then goes into: oops, our error handling does not stack well so people are just panicking everywhere (what actually requires more code than proper handling). go goes into: oops our error handling requires 2 times as much code as the actual program, so people are just panicking everywhere.4 - rust will eventually solve its crisis by creating something equivalent to \"do\" notation. i don't really think there's any solution for go, but i do expect them to create some low level exception system so they can keep the language simple - maybe this time they'll copy vb instead of c.by the subject of your point #6, rust's mechanism is strictly more powerful than exceptions. it can do anything exceptions do, and more. go's evidently is not.", "that's because she's already went through all that stress and bullshit and skills testing in med school and residency. if any clown could call themselves a nurse, and would apply to er nurse jobs, it would take all of ten seconds before nurses would have to do whiteboard triage interviews.i have no idea what the candidate did in their cs undergrad. maybe they cribbed all their work from their roommate. maybe they went to a party school. maybe they spent the last 4 years as a 'senior developer' at foocorp copying files from hard drives to floppy disks, and posting a few paragraphs a day on the company's wordpress install. maybe they are an architecture astronaut who can talk for six hours about how great haskell is at doing multi-manifold monadic trivariable entaglement, but has no idea how to do any real work.or maybe they spent the last decade building bigtable and mapreduce, and spanner, and tensorflow at google. i'm not an expert on bigtable, or mapreduce, or spanner, or tensorflow, though - and i can't definitively, in 60 minutes, tell if the person i'm talking to is bullshitting me. i can't tell if they actually did any of that work, or they coasted. i can't tell if the complicated problem they are describing to me is actually hard, or if they are embellishing it. even if i felt confident that i could make that conclusion, my opinion would be incredibly colored by personal biases.oh, i should check their github, you say? well, guess what - jeff dean - the guy who did spend the last decade building bigtable and mapreduce, and spanner, and tensorflow - doesn't have a github account. presumably because he has better things to do with his free time, then work on oss.oh, i should hire fast and fire fast? don't get me started on why that doesn't work...", "well, it does not have the exact same syntax of your example. even more because your example was pure. haskell does that automatically for pure code too (`y = x + 1` would do exactly what you described) but it's not really relevant.io code always returns a promise, and the next statement on a `do` block may await the previous promise and yield the execution to whatever other piece of code can run, based on some rules on the compiler, based in large part on data dependency. if i'm reading your comment correctly, that is what you are asking for.", "go seems like a bad venue to compare the value- and jump- based approaches to error handling, because its value-based error handling is so poor that it ends up pushing people towards jump-based handling. i'd be more interested in reading about this in haskell or rust or whatever.i also don't think anyone should be allowed to write, or read, about error handling unless they've read and digested 'the error model': if they have, they should be required to say so at the start of their article, so i know i'm not wasting my time reading it!:)i would say that one of the lessons from the evolutions of errors in rust is a sort of negative-space analogue of animats' story - that with sufficient syntactic sugar, value-based error handling behaves pretty much the same as jump-based error handling, and that we shouldn't think of them as alternatives, but as directions on a continuum. a bit like how we realised that garbage collection and reference counting are on a continuum: most interesting thing i've read on this recently is the proposal for \"herbceptions\" in c++: defines a do-over of exceptions in c++ in such a way that they can be implemented as return values, and lose the usual disadvantages of exceptions. particularly with the optional bit in section 4.5, where you have to explicitly (but tersely) mark calls to functions which can throw, so you never have exceptions unexpectedly appearing out of nowhere.", "\"c is a language that is turing-complete. so is objective-c. so shouldn\u2019t it be possible to recreate an objective-c program in straight c?\"major misunderstanding about turing completeness.a language is so much richer than simply enabling you to write a map from inputs to outputs. sure you could probably rewrite my haskell program in fortran in the sense that the fortran program produces the exact same outputs for any given inputs...but it's hardly convincing to me that you \"recreated\" my program in fortran after dropping my monad transformers and lenses.regardless, you wouldn't even be able to generally prove (assuming you lack dependent typing) that your program is functionally equivalent to mine (since this is undecidable).", "yes, a fix to the mess error handling in go is is long overdue, and i find rust and haskell approach one of the most effective ones, clear to understand and not too verbose, and yet powerful and relatively free of the mess exceptions are in other languages. i sincerely hope the go authors will give sum types a shot in future releases of the languages, because they are so comically powerful that implementing them just feels like the right thing to do.", "i guess you haven't used rust, or ocaml, or haskell.in those cases, errors are even more like normal values because they're returned using generic types (optional/maybe, result/either), not using hacky multiple return stuff.for example, in go you might have a function that returns (string, error), but you can't define a method on that type that was returned, so e.g. you can't have:code_removed this would let you right such code as:code_removed on the other hand, in rust or haskell you'd return a generic sum type which is either an error or a value and which can be treated as an actually normal value.this leads to the languages i mentioned above having the ability to have much cleaner and more concise error handling than go.the fact that go has multiple returns, not tuples or sum types, results in its errors being really awkward to use values, among their other flaws.", "there's a reason why julia doesn't have a strong static type system.in julia, you can write a custom type, and immediately have access to all of the builtin libraries.for example, i wrote a drop-in replacement for floating points, and immediately had complex numbers, matrix math, gaussian elimination, fourier transform, etc... and could rapidly compare the numerical performance of that with fp.for a more exotic example, i wrote a galois field gf256 type and was immediately able to reed-solomon encoding and decoding using the matrix multiplication and matrix solving libraries.for an even more exotic example, i wrote a \"lexical gf256\" type (basically passing strings) and had the system generate optimized c code for reed-solomon decoding, using the builtin julia matrix solver without having to manually do matrix solving for every possible (n,k) reed-solomon system.it was also relatively easy to write a verilog generator (~3 days of work), so you could pass bit-arrays representing wires, run you unit and property tests on the binary representation, then redispatch the function passing lexical types and get verilog code out the other end, then transpile the verilog to c using verilator, dynamically load the verilog into the julia runtime, and then unit and property tests on the transpiled verilog.i'm sure it's possible to do this in haskell, but i imagine it would be harder.", "in principle julia is a general purpose language, although so far the ecosystem is heavily biased towards scientific computing.so while you might find the language itself pleasant, you'll probably find a lack of libraries.(personally i'm a fan of strong static type systems (e.g. haskell), and i think it is a shame the designers didn't go down that path. but hey, they did all the work and not me, so who am i to complain. kudos to the 1.0 milestone!)", "i am happy to see i am not the only person in the world that feels like this about signal.the interesting fact is that i \"ctrl+f\" this page for wire and i have seen nothing, even though this comment is about something that made me switch over wire from signal: to date, that's the unique instant messaging that has foss'ed both the server and the clients. (ok, the article also says about matrix.)i admire wire for a number of reasons, but certainly foss'ing all their code is one the main reasons. (the other is... haskell! and also rust.)and just to point out, not only wire bug-fixed the library implementation of the signal protocol, as they use the signal protocol. and their web interface is very good!oh, yes... and they are not based in usa.edit: i am not affiliated with wire, but just a happy customer.:)", "i think the problem is that we assign too much importance to the last 5% of type safety. go\u2019s typing guarantees are somewhere between haskell and python, and it ends up being a very practical place on the spectrum. further, have a great type system is just one of many competing factors; tooling has to be good, deployment has to be good, runtime has to be good, testing has to be good, libraries have to be good, code has to be readable, etc etc. most languages drive hard at one of these; go gets 90% of the way on all of them.", "g-research | london, uk | full - time | onsite | www.gresearch.co.uk g-research is a leading quantitative research and technology company. by using the latest scientific techniques, we produce world-beating predictive research and build advanced technology to analyse the world's data. we have vacancies in information security, software engineering, information technology, and quantitative research. we work with c#,.net, c++, haskell, javascript, aws, docker, f#, hadoop, kafka, scala, spark, python, mongodb, tensorflow, kubernetes, jvm, cyberark, cassandra and ansible. we offer an exceptional employee package which includes top private healthcare and an annual discretionary bonus. our other perks include: bike to work scheme childcare vouchers company weekend away expert guest speaker give as you earn pension scheme season ticket loan apply at www.gresearch.co.uk/vacancies", "from my understanding, this is not haskells io - though my time with haskell is limited.1. haskell uses special notation 'do' to handle access to io wrapped values, e.g. (contrieved example, one would not use do for such simple cases)code_removed instead ofcode_removed 2. haskell method signatures do include io, e.g.code_removed instead ofcode_removed 3. because io is usually not the only effect managaging monad, as i've said in another comment, the type signature usually uses a type alias that does alias a monad transformer stack likecode_removed or concurrency mixed in4. this the same as my scala code, where i have cats futuret monad transformers with scalactic errors ort every stacks showing up all over my apis as a type alias of 'witherrors'.5. 'also, parallelism is \"free\" on pure code.' not sure what's that got to do with it, but yes if you have no concurrency problems (concurrent writes to shared data) you don't need to think about concurrency and parallelism is free.but if my understanding is wrong, i'm happy to learn something about concurrency in haskell without it showing in code and type signatures.", "architects and mechanical engineers not only know about blueprints and design procedure, they also have a solid understanding of the physics that make their designs work. programmers, by and large, just know how to code.there exists a formidable body of study describing the practices and theory required to write knowably-correct software, but the software engineering industry treats these ideas with utter derision. even lighter-weight methods for knowably preventing broad classes of errors(e.g. haskell-like type systems) are considered niche and pretentious. these opinions are mirrored by many cs programs, so most engineers wouldn\u2019t have the slightest clue how to apply these methods, or even know that they exist, should they decide they were necessary.with that kind of culture, what can we expect?", "i'm a c# + javascripter too. i learn a few languages on the side, plus some exposure in jobs. java, haskell, ruby, elm being the main ones.i think it is worth dabbling to see how things are done on the other side. learning haskell makes dealing with rx / linq a bit easier - not directly but by flexing that functional-thinking brain muscle.having said that i still think of c# as my go-to language and enjoy programming in it, i think it is a great general purpose language and i am glad i am doing my production code in that. it's a nice mix of type safety (so prefer that to ruby) but with plenty of escape hatches and meta-programming options (prefer that to the strictness of haskell).as a c#/js-er the most useful languages might be powershell and typescript, and the most eye opening might be lisp and haskell.", "functional programming!functional programming languages have several classic features that are now gradually adopted by none fp languages.lambda expressions [1] is one such feature originating from fp languages such as standard ml (1984) or haskell (1990) that is now implemented in c#3.0 (2007), c++11 (2011), java8 (2014) and even javascript (ecmascript 6, 2015).pattern matching [2] is another feature that is now^2015 implemented in c#7.0. my bet is that java and other will follow in the next versions.here is a list of fp features. some of which are already adopted by none fp languages: lambda expressions, higher order functions, pattern matching, currying, list comprehension, lazy evaluation, type classes, monads, no side effects, tail recursion, generalized algebraic datatypes, type polymorphism, higher kinded types, first class citicens, immutable variables.[1]", "i suppose something close might be ocaml or haskell, since they have similar type safety to rust (whose syntax is loosely based on ocaml from what i understand) but have some nice features that python and nim use like list comprehensions and generators, lazy evaluating, etc. but also with rust macros you can sort of make your own sub-dsl's which add some of those features.", "just to post it as an answer instead of a question. that's haskell's io.it is just one of the lots of concurrency behaviors available in libraries. also, parallelism is \"free\" on pure code.", "in haskell you'd have the type signature everywhere i think, mostly as a monad transformer.", "> such like socket programmingthat's one of my biggest pet peeves (and if you see my other comments, you'll notice i have quite a few).to do socket programming in asyncio, you can either use:- protocols, with a nice reusable api and an interface that clearly tells you where to do what. but you can't use \"await\". you are back to creating futures and attaching callback like 10 years ago.- streams, where you can use async / await, you but get to write the entire life cycle by yourself all over again.i get that protocols are faster, and match twisted model, and i get that streams are pure and functional, but none of this is easy. i use python to make my life easier. if i wanted extreme perfs i'd use c. if i wanted extreme pureness i'd use haskell.> wrapping non-async-compatible libraries and separating cpu-intensive blocking tasks to awaitable threadsthat's the one of the things asyncio did right. executors are incredibly simple to use, robust and well integrated.problem is: they are badly documented and the api is awkward.i won't write a tutorial in hn, but as a starting point:you can use:code_removed if you pass \"none\" as an executor, it will get the default one, which will run your callback in a thread pool. very useful for stuff like database calls.but if you want cpu intensive task, you need to create an instance of processpoolexecutor, and pass it to run_in_executor().i say it's one of the things asyncio did right because the pools not only distribute automatically the callbacks among the workers of the pool (which you can control the number), but you also get a future back which you can await transparently.", "i also initially thought the same thing. page two of \"parallel and concurrent programming in haskell\" maybe says it in a nicer way:>a parallel program is one that uses a multiplicity of computational hardware....>concurrency is a program-structuring technique in which there are multiple threads of control...(a pdf can readily be found with your favorite search engine for the full extract:) ).i would much prefer to see a precise, rigorous definition and then examples (or eg and then defn is also acceptable), instead of just a list of examples. examples help you understand a rigorous statement. but, if you only give a hand waving explanation for something, i think it just creates more confusion in the end, as you never know exactly what is correct. it's leaving it open for ambiguity.", "isn't haskell somewhat like that, due to being lazy by default?", "this isn't my area per se but have you considered lisp/haskell (even ruby) or one of the other languages with good metaprogramming/dsl creation facilities?or perhaps making a small extension to one of the above, i know many languages have the ability to be extended through modules added at compile (meaning when you compile the interpreter/compiler/runtime itself, not the program) time, or used as a target for a preprocessor. that makes it so it's at least a little easier to get a userbase going, maybe some existing libraries can work with your language.if that's not possible, i'd be curious to learn what makes it not feasible. fresh approaches to data processing are really desirable right now, since so many of us are working with data that is different from what language designers intended.", "there are some other lessons too, especially regarding haskell. basically the sad truth is that if you do not benchmark literally every single line, you can suddenly get much worse performance than expected. sometimes ghc's strictness analysis does not discover that it can unbox some things and you land in a boxing-unboxing loop or you hit some of optimization bugs (during the work on performance we've reported over 10 ghc bugs and even implemented our custom graph memory manager). so one of the biggest problems that we encountered earlier was that actually the ghc performance is much harder to predict than you think and you have to take extra care of it while building your software. of course using haskell pays off in other areas, but performance is tricky.", "i think dart started internal development around the same time coffeescript gained major popularity and brought attention to js's desperate need to evolve, but they released at a bad time: when js finally did start to evolve (as harmony) which was a reaction to coffeescript in the first place. so coffeescript served its purpose of pushing js forward, and most other compile-to-js languages had no more purpose. i say most because some serve a different purpose than just being a slightly nicer js, like how elm piggy-backs on the familiarity of haskell and provides a niche no-mutation environment, and typescript adds type-checking for those of us who can't write code as confidently without it. but the rest served their purpose, and dart's dream of having its own vm inside chrome was probably what killed it so quickly.", "> also if you make hardware absolutely optomised for lisp then all the c, fortran, and cobol (this was the 1970's!) programmers aren't particularly interested because it does nothing for their code.yes, but it's different now. now our programming languages are closer to lisp than c. we use javascript, python, ruby, haskell and throw functions all over the place and they come with a cost of frames etc. even \"low level\" languages like c++ and java recently gained powerful capabilities to express lambdas, and c++ programmers use lambdas and std::function pretty often. why not experiment with a machine that can handle function passing better turing machines. it seems like if you use enough high-level structures in your code, even a \"slower\" lisp machine can run your faster than \"fast\" classical turing-machine-like-cpu.this is not even for general purpose cpus. there are embedded devices people write python or javascript code on. why not make those cpus lisp machines?", "i'm under the impression that lc is closer to how humans think of computation, and it seems that even though it's easier to implement tm as a bare-metal machine, isn't it a trade-off? if humans mostly produce lc-like high-level code, then compile them to tm-like machine code, wouldn't it be better at some point to produce lc-like machines? because even though they're slower at face value, wouldn't it be faster on \"human software\".this comment assumes 'humans mostly produce lc-like high-level code', but i think this is valid; other than c, i cannot think of a language in which programmers don't use lambdas, higher-order functions ubiquitously. it seems like our cpus are optimized for c, but i'm curious how would it change if we optimize them for javascript, python or haskell...", "as a fan of both visual programming and haskell, i definitely think this is the future of programming, and i can see it going two ways - a general purpose tool like with a huge library of plugins or included in a host program as a vm/embedded dsl. or perhaps both;) what are the developers plans/thoughts on this?", "this seems to me like the eternal tech discussion about the beauty of, say, haskell vs. what it produces in the real world. for some people, the intrinsic elegance of the language is enough, while for others the language is just a means to an end.while i can perhaps appreciate the perspective that a game of football could be beautiful to someone when there are no shots, to me the movement and positioning and passing are all means to an end: setting up scoring opportunities. in general, i get sort of annoyed by things divorced from reality: math and science need their engineering, programming languages need their killer apps, and football strategies need their goals!", "code_removed the term \"message passing\" is a bit confusing in this case, because it applies to both objects and actors, but both use a different approach.when you send a message to a regular object, usually a method with the same name is called. for example, when using `process.send` the \"send\" method in the \"process\" module is called. this however can change, as objects can implement the method \"unknown_message\" to handle messages for which no method is explicitly defined.in case of processes, sending a message is just that: you send a message, this gets put into a special queue, and then it's up to the receiving process to do something with it (whatever that might be). if you want to implement some kind of rpc system you'll need to see what kind of message you have, then dispatch accordingly. inko's test suite does this using polymorphing: every message the test runner receives implements the \"command\" trait, which defines a \"run\" method. the test runner then simply sends \"run\" to these command objects, letting them figure things out from there.code_removed i'm not sure if i fully understand this question. a channel in inko consists out of two objects: a sender and a receiver. the sender just wraps the pid of the receiving process, the receiver is just used for storing the type of the message at compile time, and providing some methods.as to what you can send: everything that is compatible with the type of the channel. for example:code_removed this will fail, because our channel only allows `integer` values, whereas \"foo\" is of type `string`.code_removed it is worth mentioning that despite the name \"channel\" being used for the method, it's not an actual channel data structure (e.g. like in go). the messages are still stored in the mailbox of the receiver, just like when using `process.send`. instead, the sender/receiver api is just a simple trick that allows the compiler to know what types of messages are being sent and received. i called this \"channel\", because after several hours of thinking i still couldn't come up with a better name.", "i don't quite get how messages and method calls interact. could the process intercept the method call by explicitly receiving or somehow influence the process module to do something else?channels are a great idea! what capabilities (send on channel/receive on channel) can you forward to other processes? as cloud haskell explain, in distributed systems we must not allow send on channel to be forwarded.regarding channels, both linear channels and mailbox types for unordered interactions are interesting ideas worth looking into.great project!", "g-research | london, uk | full - time | onsite | www.gresearch.co.ukg-research is a leading quantitative research and technology company. by using the latest scientific techniques, we produce world-beating predictive research and build advanced technology to analyse the world's data.we have vacancies in information security, software engineering, information technology, and quantitative research.we work with c#,.net, c++, haskell, javascript, aws, docker, f#, hadoop, kafka, scala, spark, python, mongodb, tensorflow, kubernetes, jvm, cyberark, cassandra and ansible.we offer an exceptional employee package which includes top private healthcare and an annual discretionary bonus.our other perks include:bike to work scheme childcare vouchers company weekend away expert guest speaker give as you earn pension scheme season ticket loanapply at www.gresearch.co.uk/vacancies", "worth mentioning a haswell system with qdr i helped build. i discovered that it was needed to use an older version of libpsm to avoid a bandwidth boost tweak that increased latency which isn't the competitive advantage of ib qdr. also highly disappointing they down clocked haswell as soon as avx2 was touched. given no temperature increase, there isn't a thermal argument for it just for using more of the micro instructions on the die. was an early system, and needed to use end-of-life centos for the correct library versions.", "sounds reasonable, but am i missing something deeply important, like say lisp or haskell, if i don't learn julia. what i've seen it's a nicer fortrant.", "cibo technologies | senior software engineer | onsite | cambridge, ma or st. louis, mo | full-timecibo is a startup simulating agricultural ecosystems for any crop, any location, and any scenario in order to meet challenges related to food security, sustainability, profitability, waste, and quality of both food and the environment. you\u2019ll be part of a collaborative team of developers, data scientists, agronomists, and remote sensing experts. as engineers we believe in type tests, functional programming and automation. our major platform is built on scala in aws, with sprinklings of r. cibo is a science-based company, so prepare to learn and invent with us!qualifications: * solid cs foundation * 5+ years of professional experience * skilled in at least one of each of an object-oriented {scala, java, c++, python, etc.}, functional {scala, haskell, ocaml/sml, erlang, clojure, etc.} and a strongly-typed language {scala, java, c++, haskell, etc.}. multi-counting allowed. * significant experience with multithreading or distributed/eventually consistent systems * excellent collaboration skillsto apply for this position please visit website: other career opportunities:", "> there is also a performance overhead with iterablesthough, for the sake of pedantry, it's not something that can't be handled by an optimizing compiler that understands them. haskell, for example, is good at this.", "java gives me a rash, so writing that last comment took every last bit of restraint i had.but, i still can't come up with a static language that i'd want to teach someone as a first language. c# would be a good choice, but i don't know how much success a beginner would have with.net. typescript is hard to debug unless you know javascript. i wouldn't wish c++ as a first languge upon anyone. haskell seems like it would be very frustrating for a beginner. swift might be okay if they really badly wanted to go mobile, but that's not the case here. rust is the best i can come up with, though it seems like a tough first language.do you have any ideas? i see the value of learning static first, but can't come up with a good language!", "the most common thing i can think of is putting everything in io/st, also known as \"c++ in haskell\".", "the thing i remember from that era was most of what i read about in byte being out of reach financially. the open source movement has made software much more accessible. if i want to learn to program in go or haskell i don't need to start by reaching for my wallet.", "we're definitely moving in the direction. someone already mentioned rust, and typescript is gaining traction in web dev. banks like barclays and standard chartered already have haskell teams, and i've noticed more and more haskell jobs popping up over the years (in london). scala is already realtively popular.formal verification is used in some niche areas (bae, galois). proof engineer is a real role some companies are looking to fill.", "i can also recommend: (js, py) (go) (haskell)", "what does crappy haskell code loook like?", "wouldn't have worked back when i was ta...first, i'd have been able to run it (or grade it even without running it). and yes. i've seen a lot of crappy haskell code. i've written a good amount of that myself when i was learning haskell back then.second, assuming i didn't know haskell, i'd have stopped your babbling in the presentation at some point and asked you to run it.third, any student that does unusual things is either very good or very cheeky, so those students deserve special attention. so 10 minutes at your and my convenience to run the demo in my office would always have been an option.(but then, teaching at my university probably was quite different from teaching at your university).", "i am actually quite happy with sympy, it sometimes needs a helping hand but: - it can solve the equations that i need solved - it is open source and free - it is a python library (i alreaddy know the syntax and it can be plugged in a python codebase) - i can export the results in latex, c++, haskell,... (nice bonus)", "being such a concise language, haskell could be a good option here. you can do quick scripting while still having a powerful type system (especially compared to go's) backing you up. i somewhat quickly typed this code up and haven't tested it, but it should replicate that bash script pretty closely:code_removed i didn't make use of it, but there's also the turtle library which aims to provide a fairly solid shell scripting experience, providing a lot of coreutils as simple haskell functions. you also get a repl in the form of ghci, which comes default in haskell installations.", "came here to post this. i've been lurking (and occasionally, although rarely, posting) on that site since i was a teenager. it got me into low-level programming to the point where i even bought some arm boards and a sunblade workstation just to play around with different architectures\u2014i have got to refurbish that sunblade at some point; openbsd ran fantastically on it, and being able to code bootsectors in forth was pretty cool.haven't been on there as much since i started university though, my interests shifted towards physics/maths. i'm trying to get back into it because it's a fun hobby and i need a distraction from work/college; i started a kernel towards the end of spring, but unfortunately got distracted by exams. i want to try get in running userspace programs as soon as possible, but i'd like to get the syscall api nailed down first as i don't want to have to rewrite drivers (it's a microkernel) if i decide at some point to rewrite the kernel in rust (currently in c, but i like rust's type-system\u2014the combo of a rust kernel + haskell userspace is also something i've been contemplating, but will probably have to wait a few years)", "haskell has no problem with this(though its default num hierarchy is sorely lacking)code_removed", "seeking work - san diego, ca or remoteemail: hey@workwithgosha.comi\u2019ve been doing a lot of mobile and front-end work past couple of years, but i know my way around back-ends, architecture, deployment as well.most of my experience comes from consulting. you can see my some of past works & references here: keep a blog about react native & react ( and have self-published a book about forms in react (\u2028\u2028a bunch of buzzwords because apparently everyone needs them: react native, react, javascript, flow, redux, ruby, rails, postgresql, haskell, type systems.note: my handle has nothing to do with the kkk.", "i built my computer graphics final project in haskell so that the ta wouldn't be able to run it and grade it. then for our presentation, i babbled on and on about the math and went over time so we wouldn't have to give a really crappy demo.", "nilenso | engineer | bangalore, india | is an employee-owned software cooperative. we're looking for people we'd really like to work with.we work on problems that are technically deep, large scale, in domains with high impact, and we have an affinity to work with functional languages: clojure, elixir, haskell et.al.you can read more about working at nilenso here: write to us (moshimoshi@nilenso.com) if you're interested.", "do you know haskell or c++?", "this sounds pretty cool. my own workflow is so pandoc-dependent though that i don't think i could use it unless someone who is much better at haskell than i am works the markdeep extensions into pandoc:-(", "i have been following this project closely for a while as it is simular to an imaginary language i've always wanted (and have been slowly working on myself). whereas kitten comes from a haskell heritage (thus functionally pure), mine comes from a forth hertiage (it is a true forth). kitten, as it seems to me, is a potentially awesome hybrid of haskell, c (more under the hood) and forth and i am very much looking forward to seeing its fruition. it's about time concatinative languages got their modern, mainstream turn in the sun.", "the idea at work here is alan kay's, to bring the spec into the language as code somehow. prolog is better suited to this than many other languages, simply because it is so easy to reuse existing operators and structures but overlay them with new semantics, as well as adding your own operators. but i think you can do that same fundamental idea in any language. the roi will often be lower though, if you tried to do what i did in java, for instance. in this case the core is very procedural. that was kind of fun to do, just as a reminder that prolog can do that without it being onerous. but the roi would have been even higher if the core problem involved nondeterminism, constraints or deduction in some unavoidable way.a lot of the code i write in prolog is written to demonstrate you can do practical things in prolog without it turning into c or pascal. i feel that lisp managed to shed the \"this is only for ai\" stigma, thanks to books like practical common lisp and partly thanks to emacs itself. but prolog is still sort of thought of as this freak language only really useful for solving einstein puzzles and sudoku.prolog is not my strongest language, and i am far from an expert in it. but, i don't think you have to be an expert in it to use it productively and enjoy it. if i had tried to do this problem in haskell or python or java, i would probably have solved it in a completely different way.i don't know if this addresses your questions or not, but i'm glad to talk more.", "it's a bit verbose, but this kind of thing is far less prevalent in haskell anyway; most of the time you destructure a list through pattern matching, not explicit head/tail functions.", "for those who lack the generics, i just wanted to remind that you can \"script\" in haskell by adding this to your header:code_removed and run it as an executable if your machine has stack installed. if not -- compile it with a `stack ghc --resolver=lts-12.2./file.hs` and you'll have a `./file` executable. no project creation, no need to list the dependencies.", "the spj book is from 1987, so more than 3 decades old. there has been quite a bit of progress in compilers since. while i'm not up to scratch on the latest version of the ghc compiler, it's quite a bit different. i recommend looking at peyton jones and marlow's overview article [1]. the scala compiler(s) are also interesting. i'm not aware of an overview article, but i found last year's [2] worth reading. a big breakthrough in the compilation of functional languages was xavier leroy's on (o)caml. i am not aware of any recent descriptions, but maybe [3, 4] are better than nothing. note that languages like javascript have full functional sublanguages, so all recent progress in jit compilation for javascript could/should be considered here too.historically, the main issue in the compilation of fp languages has been laziness. in a statically-scoped call-by-value language, compilation is not that different from compilation of 'normal' languages.[1] s. marlow, s. peyton-jones, the glasgow haskell compiler. d. petrashko, o. lhotak, m. odersky, miniphases: compilation using modular and efficient tree transformations. x. leroy, functional programming languages part ii: abstract machines.[4] x. leroy, the zinc experiment: an economical implementation of the ml language.", "legalstart | full-stack software engineer | paris, france | full-time, onsite, visa, python/django rest framework, react, postgresql, rabbitmq, docker, awsbased in paris, legalstart is a leader in the european legal-tech space that aims at profoundly simplifying legal services, starting with making access to justice greatly easier, especially for businesses creators.since the launch of the site at the beginning of 2014, legalstart has experienced a very strong growth. in this context, we are looking for highly motivated developers to help us extend our product base and grow internationally.at legalstart, we strive to improve our technical skills, that means challenging the status quo (we shipped a small blockchain-based product in production), continuously improving our practices (we introduced haskell and reasonml in our codebase), staying close to the local community (hosting meetups, conferences)\u2026 also, legalstart engineers develop a strong ownership of the product itself, and we really value their personal growth.apply there if you feel up to the experience!* front-end developer: python developer:", "if you want to sprinkle some type safety onto your r, check out this lovely piece of kit:", "haskell is pretty common for this. see purescript, elm, agda, idris. there are more here:", "> underneath the hood, logitext interfaces with coq in order to check the validity of your proof steps. the frontend is written in haskell and ur/webi wonder why not agda? or if coq then why not ocaml? in both cases it would be easier to upstream parts of logitext in these projects, benefitting everyone.", "yes sorry, elm is indeed implemented in haskell.", "> partial borrowyeah, that's the annoying part of rust:(> i can't use my non-thread-safe classes in a lazy_staticwell, you can, if you wrap them in fragile/sticky from phantomdata is awkward, it absolutely sounds like something the compiler should handle, not the programmerthis is quite common in haskell (called proxy there), for different reasons (not for lifetimes since there are none \u2014 but for passing type-level stuff around calls), but because of that, it feels completely natural to me.", "elm is still implemented in haskell. self-hosting isn't a goal.", "> underneath the hood, logitext interfaces with coq in order to check the validity of your proof steps. the frontend is written in haskell and ur/webi wonder why not agda? or if coq then why not ocaml? in both cases it would be easier to upstream parts of logitext in these projects, benefitting everyone.", "yes sorry, elm is indeed implemented in haskell.", "> partial borrowyeah, that's the annoying part of rust:(> i can't use my non-thread-safe classes in a lazy_staticwell, you can, if you wrap them in fragile/sticky from phantomdata is awkward, it absolutely sounds like something the compiler should handle, not the programmerthis is quite common in haskell (called proxy there), for different reasons (not for lifetimes since there are none \u2014 but for passing type-level stuff around calls), but because of that, it feels completely natural to me.", "elm is still implemented in haskell. self-hosting isn't a goal.", "having some experience with both languages (though not professionally), i personally much prefer prolog to haskell. there's an initial hurdle with prolog because it uses such an unfamiliar paradigm, but once you get good with it, programming in prolog is pure pleasure for me.i like haskell just fine, it's an excellent language, but my heart belongs to prolog.", "was elm originally implemented in ocaml? i thought it was haskell.another two relatively popular languages implemented in haskell are idris and agda.", "probably because they predate haskell. in the case of java, thats not true, but haskell would have only been 5 years old at the time, and was largely academic.", "i'm always surprised and delighted to see so many \"first implementations\" of languages in prolog. it was described to me in college as \"just a novelty\" but in fact it's used extensively in the jvm internals [1] and apparently is the starting-point impl for other languages.but prolog still seems so..awkward. i wonder why langs like haskell or ocaml aren't more de-facto for these purposes; they seem to have similar expressive power for parser/grammar things and with less inside-out paradigms (imho).[1]", "seeking work - remote, short to medium term projects - zak.wilson@gmail.com i make software - mostly full-stack web development and http apis, but i'm adaptable. i have some interest in artificial intelligence and machine learning. i have a little experience making android apps, and my open-source android app ceilingbounce has happy users.i can do stuff that's harder than basic crud apps. stuff i know well: clojure, ruby (with or without rails), python, django, javascript, lua, postgresql, mysql, sass, responsive css.other stuff i've used for something non-trivial at least once: common lisp, scheme, java, sass, c, php, haskell, bash, perl, mongodb, mirah, android development with clojure. yes, i can probably pick up that language or tool you're using that nobody has ever heard of.github: public facing things i've worked on:", "channable - | utrecht, the netherlands | onsitechannable is a data feed management company that connects ecommerce companies to all big online marketing channels (marketplaces, price comparison sites etc.) we also optimize and synchronize product data, offers, and orders on various platforms.we currently have four open positions:- frontend developer [1]- devops automation engineer [2]- api integrations specialist [3]our stack includes: python (flask), haskell, scala (apache spark), postgresql, redis, hdfs, ansible, terraform, ember.jswe process hundreds of millions of products per day and offer technically interesting and challenging work. we are looking for a highly motivated and skilled engineers to join our team in the center of utrecht.see for a detailed job description.[1]", "energotest | gliwice (poland) | full time | onsite | senior software engineer | is a modern and well organized engineering company with a team of distinguished specialists. many of them have managed or co-managed: design, assembly supervision, post-assembly tests, start-up of devices and electrical power engineering systems, practically in all newly erected or modernized power plants, combined heat and power plants, substations and industrial plants in poland and abroad.the energotest r&d department team is looking for a senior developer who would be willing to take part in setting new directions in the development of systems for the broader \"industry 4.0\". the person will help us change the world of automation systems, face the task of creating tools for engineers and firmware for devices manufactured by energotest. working together in the r&d department, we are happy to share our knowledge, but the ability to independently solve problems and look for information will be a desirable skill. if you have skills that do not meet all of the following requirements, but enter other areas of programming and feel that they will help develop our project or make it a unique product, we will gladly talk to you.essential skills: gnu/linux, git, bash, c++, boost, qtnice to have:* python (and boost.python)* experience with embedded linux (yocto)* modern c++ (c++11, c++14, c++17)* functional programming (haskell)* web technologies (html, css, js)extra notes:* it doesn't harm if you also know mfc, c#, delphi and windows in general* official language in energotest is polish* remote work is partially possible (1 day/week)if you want to avoid the recruitment path, take on the challenge available here:", "i'm right there with you guys.i made my desktop in 2014 with a haswell i5-4670k @ 3.4ghz. overclocked it to 4.3ghz, and i still don't have a reason to upgrade. i really want a ryzen 2700x also but staying patient. newer and better hardware will keep coming out so i'm in no rush. (but my next cpu will definitely be amd)my current thing right now is compiling the linux kernel exactly catered to my haswell machine, and using the latest gcc with \"-march=native -o2\" optimizations. it might seem minor, but man if she ain't screaming right now. i should mention i have an amd rx 480 graphics card also. so i'm up-to-date in that world and enjoying the best of team red and blue right now. new drivers, software, kernels, and optimizations keep coming out that make my current hardware faster. but then came spectre and meltdown lol.", "brex (brex.com) | san francisco, ca | on-site only | full-time | visawhat we bring:- an environment where it matters to make the right design decisions the first time. \"move fast and break things\" doesn't really work for the type of system that we build. we take less technical debt than other companies.- at brex, engineers make the product decisions with input from business people, instead of business / product people making decisions with input from engineers- we'd rather have one strong, well-compensated engineer instead of having 5 mediocre engineers. our customers are fine with fewer features, but are not ok with broken features.- small, accountable and autonomous teams of amazing people, eager to learn, teach and constantly improve our way of working.- we believe that great individual contributors generate as much (or more!) value as engineering managers, and we compensate them accordingly.what you'll bring:- exceptional technical background.- strong sense of ownership and accountability for what you're building. what you build today will be the foundation for dozens of other systems in the future.- frankness on discussing technical matters. if you disagree with how things are being done, we encourage you to speak up. you can attack an idea without attacking the person behind it.- passion for code. we love people that take pride in and love programming, especially if they've done so since a very young age.- experience in haskell, scala, functional programming, elixir or f# is a plusdoes brex sound like home? we'd love to meet you:", "location: bloomington, indianaremote: remote onlywilling to relocate: nocore technologies: android, python, javascript, java, node.js, html/css, aws, sql, mongodbother experience: haskell, purescript, elixir, architect/serverless, dart/flutter, react/reduxgithub: jcieslik@whiteboarddynamics.co", "monadic | software engineer, haskell | berlin | onsite | full-timewe're looking to hire our fourth software engineer to work in haskell on distributed systems, version control and tuis to build a platform for open-source collaboration and funding. our salary is a flat eur 100k. we're well funded and based in berlin.more information on the job and how to apply here: you are experienced with react, elm, purescript or vue and interested in product development, we would also like to talk.thanks!", "location: san diego, caremote: yeswilling to relocate: notechnologies: react native, react, javascript, flow, redux, ruby, rails, postgresql, haskell, type systemsr\u00e9sum\u00e9/cv: hey@workwithgosha.comhey, i\u2019m gosha.i see how programming is just connecting business objectives with reality, not a craft unto itself. languages are all the same to me. (i also wrote toy languages and primitive type systems.)\u2028\u2028i\u2019ve been doing a lot of mobile and front-end work past couple of years, but i know my way around back-ends, architecture, deployment too. most of my experience comes from consulting. you can see my some of past works & references here: also keep a blog about react native & react ( and have self-published a book about forms in react ( my handle has nothing to do with the kkk.", "cyient | full time | onsite (remote for the right candidate) | melbourne, fl; bangalore, india; or hyderabad, india | is a software suite developed by cyient for the design, development, simulation, verification, and validation of safety-critical systems. certsafe features a graphical development environment for a visual modeling language based on dataflow/circuit diagram notation, a simulation engine and interactive testing interface, an automatic test generator based on satisfiability modulo theories (smt) solving, and more.as a member of the certsafe team, you will get to apply your software engineering and computer science knowledge in diverse areas, including programming language theory, graph theory, user interface design, concurrent and parallel software design, and software test automation. you will get to interact on a day-to-day basis with real-world users and customers working on safety-critical applications in aerospace, defense, transportation, medical devices, and other fields.certsafe is developed by a small team with a lean kanban development process. we use a variety of technologies including java, maven, jenkins, python, and aws, and also especially appreciate experience with functional languages such as haskell, f#, ocaml, lisp, etc.positions available include software engineer, software quality assurance engineer, application engineer, and devops engineer. visit for full position descriptions.if you plan on working outside of melbourne, fl, these roles require travel to melbourne, fl for 90-180 days to undergo necessary training. visa assistance is available.interested? email your resume to careers@certsafe.com.", "having recently finished university, we needed to use c, xc, c++, javascript, java, python and haskell. nothing microsoft there at all.", "engine ml | software engineer | san francisco | full-time, interns | engineml.comengine ml is hiring a first engineer to work on democratizing fast training of deep neural nets. stack includes:haskell, java, kubernetes, python, tensorflow, pytorchas a first engineer you will work on everything. the ideal candidate will be focused on full stack web dev, devops, or backend, but must be able to wear many hats.will@engineml.com", "lumi (yc w15) | | los angeles, ca | senior product manager, database administrator, front-end and full-stack engineers | remote (within usa) | full-timelumi is making packaging simpler for e-commerce brands. we're solving complex supply chain problems involving everything from creating production-ready artwork, to bringing elegance to the complex systems of pricing, manufacturing, shipping and freight in the packaging industry. our engineering team is fully remote and oriented towards functional programming.our stack: react, haskell, postgres. as an engineer at lumi, you'll become an important part of our diverse and dynamic team. you will be leading projects building the architecture of our customer-facing site and backend tools. because of our small team and rapid development cycle you'll have the opportunity to work on a wide variety of projects and interact closely with the design and strategy of lumi. you can apply by going here: about lumi:*", "onai | | silicon valley | full time, contractors, graduate interns, postdoctoral fellows, onsite, visawe're tackling exciting technical challenges and building offerings relevant to interesting real-world problems in a variety of fields. we have particular strengths in dispersed computation, protocol design, and deep learning.we're currently most interested in engineers with solid experience in haskell/idris or rust. we're also open to enthusiastic developers who might lack this precise experience but are eager and able to learn. we also welcome internship/fellowship interest from postdoctoral researchers or senior graduate students.we do not presently have openings for anyone still working on their undergraduate degree or for fresh graduates.send your resume to info@onai.com and we'll let you know if there's a potential fit.", "yes, the evolution of lisp was guided by brilliant people. i regret throwing out so many of my old computer science related books over the years (e.g. the interlisp reference manual) because the few that remain remind me of the history of programming that has occupied so much of my life.while being nostalgic about the early days of programming languages, i am not as pessimistic about the current state of the art. there were plenty of old programming languages that have faded away despite being important in their day (ibm's pl/1) and lots of work on new languages is pushing in interesting directions (haskell, idris).common lisp has hung on and perhaps survivor bias has made it seem special, but to me, it is special. while working with it i feel that i am working with a language of the future from the past.the landscape of calculation is much bigger than it was half a century ago, when i started programming. it is populated by an enormous ecosystem of processing units from tiny to enormous, embedded to networked across the planet, with single processors to high performance multiprocessors. all of this is controlled by programming and the programmers that wrestle the world of computing into submission. in this hobbesian ecosystem some languages have prevailed for many years, like java and c, others have survived even longer like fortran and lisp, and some have simply proliferated rapidly, like python, all for reasons that are complex and involve human abilities and computer architectures. not all of them are beautiful, lisp is, but all of them have a place even if only to reveal what does and doesn't work.", "gambit research ltd ( | london, uk | onsite | \u00a340-80k + bonusgambit research specialises in creating and managing an automated betting service, via research, statistical analysis and the use of complex algorithms. we ingest and organise terabytes of market and event data from more than fifty sources and make the data available to our strategy teams in real time. we care deeply about speed, accuracy and availability.our flagship product, mollybet.com, presents the odds offered by many of the world's largest bookmakers and betting exchanges, and enables clients to bet with multiple operators with a single mouse-click or api request. molly is generally regarded as the best product in its class.we're always looking for clever, pragmatic, and autonomous individuals to join our team. we have a unique culture, where hierarchy and fancy job titles don't matter. instead our team is given the freedom to choose their own tools, work on projects they actually find interesting, and have totally flexible working hours. the technologies our team typically works with includes: linux, docker, kubernetes, ansible, c, c++, java, haskell, julia, go, javascript, angularjs, reactjs, django, postgresql, redis, apache spark, apache kafka, rabbitmq, celery, elasticsearch, logstash, kibana, graphite, sentry, git, and gitlab.we're currently recruiting for:- python developers- erlang developers- javascript (reactjs) developers- linux infrastructure engineers / sresvisit or send your cv over to careers@gambitresearch.com for more information.", "> so it's a wrapper that implements a particular interface? then why, oh why, do we have so many people who spout...its because its actually a mathematical concept. and that's the mathematical definition.so haskell decided to use the same name. now some people feel, should i explain the math concept, or its concrete representation in haskell.also, its a bit more involved as an interface. in that its not enough to implement the common methods for the interface. you also have to prove that your implementation for each exhibit certain properties, specifically there needs to be an identity value which act as a neutral element, and they must be associative.those laws are where things get more mathematical. because its rare in comp-sci to talk about laws and properties of functions.", "> \"who needs mindshare, when you can have in-jokes instead?\"it's a joke, but more importantly, it's a joke by and for people who are already familiar enough with haskell. it's not a serious attempt at communicating something useful about the language; these attempts exist, but this joke is not one of them. absolutely no-one makes this joke to beginners. you only make this joke to someone who already has an understanding of haskell. it's not a common joke, either.it's like those obfuscated c examples. nobody uses them to teach beginners anything, and it'd be a mistake to ask \"why do all these c programmers keep writing purposefully obfuscated code to scare beginners!?\". purposefully obfuscated c code, much like the haskell joke, is not aimed at beginners.", "> i've said about structs of ints alreadyyeah, but you were wrong (you said other kinds of structs would escape to the heap). the innermost struct could have a string member and a `*heapdata` member; it wouldn't matter. the difference in number of allocations between go and others would remain the same. the difference isn't driven by the leaves, it's driven by number of nodes in the object graph; the deeper or wider the tree, the better go performs relative to other gc languages.> in haskell you could have unboxed array with unboxed records. check vector.unboxed.for sure, but in go \"unboxed\" is the default (i.e., common, idiomatic); in haskell it's an optimization.", "> i am talking about the concrete type of io has and how using it, without the monads as abstraction would be so cumbersome that haskell \"needed\" monads.it would be comparable to working with e.g. lwt in ocaml, which is very much a practical way of programming.", "yes. on my eyes java was always the clear choice for enterprise code, because people come and go, and one bad apple does not destroy the entire code base on java.after i learned haskell i had a \"i knew nothing!\" moment. anybody writing enterprise code on anything that is not as safe as haskell (that is, basically everybody) is letting a lot of money on the table.", ">consider `[]struct{nested []struct{i int}}`.a typical example, yeah. i've said about structs of ints already, it's not a common type unfortunately anywhere beyond number crunching, in which go sucks anyway.in haskell you could have unboxed array with unboxed records. check vector.unboxed.", "we're talking past each other. my claim was that go doesn't need compaction as badly as other languages because it generates less garbage. you're refuting that with \"yeah, well it still generates some garbage!\". yes, strings and arrays will often be dynamic in practice, but an array of structs in go is 1 allocation (at most); in other many other languages it would be n allocations.> consider also that allocations in go are much more expensive than in java or haskell.this is true, but unrelated to cache performance, and it's also not a big deal for the same reason--allocations are rarer in go.edit:consider `[]struct{nested []struct{i int}}`. in go, this is at most 1 allocation for the outer array and one allocation for each nested array. in python, c#, haskell, etc, that's something like one allocation for the outer array, one allocation for each object in the array, one allocation for each nested array in each object, and one allocation for each object in each nested array. this is what i mean when i say go generates less garbage.", ">it doesn't matter whether they're stack allocated or statically allocatedit does. any language could do static allocation, go is not different from java here, the problem is that in any real code nearly all your strings and arrays would be dynamic, thus heap allocated, as well as interfaces. consider also that allocations in go are much more expensive than in java or haskell.", "a significant number of interesting haskell libraries i found are thin abstractions over some c api. it makes sense that these would be readable. is there something for haskell which serve a similar role as boost to c++? if that is readable, i will be convinced.", "> a harder problem is errors that cannot be handled by a simpler type system. for example, consider haskell's head functionhaskell's head function is often pointed to as a wart even given haskell's type system; the signature really ought to be:code_removed with a definition (equivalent to):code_removed it's absolutely not a good example of a source of errors that can't be dealt with in a type system like haskell's.> in order to express constraints such as \"list must not be empty\" or \"number must be higher than 1\" or \"file must be open, the type system needs to understand the semantics of the values expressed by a type system.sure, but you don't have to express those as type constraints to avoid runtime errors when they occur; if you can express the distinction in normal code you can use distinctions of return type.", "they did. the elm-style version is in the standard libraries as:code_removed (", ">so it is implemented accordingly, and any hoops that need to be jumped through in the implementation to make it work aren't magic\u2014they are just necessary to express a long-established pattern.the hoops are magic in the sense that they can't be expressed in haskell 98 or haskell 2010. a haskell compiler is perfectly entitled to optimize out any dummy values which aren't used. that includes dummy world variables.more generally, it simply isn't possible to use data dependencies -- even real data dependencies -- to control the order of side effects. the haskell standards just don't provide the guarantees necessary to make that workable, for the reasons that millstone gave.", "pretty lazy comment.there's a reason you still at least annotate the top level in haskell, elm, and friends even though the compiler could've inferred it. it's because humans have to read it.", "i think it's because they weren't very clear on how they wanted to handle partial functions / error reporting, and historically functions like head are partial.making them total makes them a bit heavier for the best case, and furthermore can seem unnecessary (as you could just pattern-match the list itself).you can also see this oddity in haskell allowing non-exhaustive case, and allowing refutable patterns in bindings.", "this seems like such an obvious solution it makes me wonder why creators of haskell did not think of it? lists are a very basic type used all the time if you don't get that right lot of the value of the great type-system is lost i would think.", "> errors could presumably be provided as return values (similar to rust's option or haskell's either), though we know from languages like go that propagating these manually is a chore and an eyesore.mostly because go is terrible.> haskell's type system is extremely powerful, but it cannot catch this at compile time.the problem is not the type system, it's that haskell's error handling is inconsistent.elm, despite having a much simpler type system than haskell, handles this properly:code_removed this has nothing to do with the type system itself and everything to do with how the type system is used (or not used). the designers of haskell's `head` decided to make it a partial function, leading to type-checking inputs not generating any output.", "> this can be solved by dependent typingdependant typing isn't needed for some use cases you have mentioned:> list must not be empty you can use nonempty we are still encoding this special case and our intent in types. cons is that we need a special support for it (special library) where with dependant types we could reason about this use case without a special libraryedit: added newlines", "errors could presumably be provided as return values (similar to rust's option or haskell's either), though we know from languages like go that propagating these manually is a chore and an eyesore.a harder problem is errors that cannot be handled by a simpler type system. for example, consider haskell's head function, which is defined like this:code_removed in other words, it takes a list, and returns the first element. but if the list is empty, it throws an exception (technically called an \"error\" in haskell):code_removed haskell's type system is extremely powerful, but it cannot catch this at compile time.in order to express constraints such as \"list must not be empty\" or \"number must be higher than 1\" or \"file must be open, the type system needs to understand the semantics of the values expressed by a type system. this can be solved by dependent typing, but that's a complicated concept currently implemented by only a handful of languages (e.g. idris).", "type annotations can be helpful in writing maximally polymorphic code and in self documentation, independent of type inference. when i write haskell, i still annotate my code.", "if we're speaking of competition and javascript, then a much stronger competitor would be purescript. is a haskell dialect that was built specifically to run on top of javascript engines. specifically, compared with haskell, it is strictly evaluated (whereas haskell is non-strict / lazy, well almost). however it eliminates some of haskell's baggage, but retains haskell's functional purity.it's all around an awesome programming language for fp that targets javascript engines, far surpassing any other attempt.", ">there are many large and complex programs written in haskell by large teams of developers (open source or otherwise).how many of those projects regularly attract new contributors, vs..say.. something written in python or c++?", "from what i can tell, your best bet would be to build the generated parser (which will generate some c code) and then build a small interface in c. from there i would just use r/python's foreign function interface to call your c wrapper.alternatively for python you could use a parse combinator like parsec. depending on how complicated your file can get, using parsec could very likely be the better choice as it has first class support in python and seems powerful enough to handle your use case.there do seem to be a number of parse combinators in r but none of them seem as well established as parsec for python (which is based on the much more well known parsec for haskell).a quick look around seems to show that python will be your best bet for parsing as it has some decent tooling. here is an article on some of the different parse generators/parse combinators in the space.", "i have found that java enforces a higher floor of readability than most languages, simply because you have to type out so much \"boilerplate\" for everything. though even that does not come close to haskell. ironically, the introduction of lambdas made bad java code using them far less readable.", "> it sounds like you haven't experienced too many of those kinds of paradigm shifts. all you know is the math-y kind.you know that hn readers are about the 99th percentile of \"willingness to learn random new cs concepts\", right? most programmers know one language. in fact, most programmers have only ever worked for one company, on one product, for their whole productive careers so far. your idea of an \"average\" programmer is, in fact, a rare programmer.> if you delve into the smalltalk image and class library, it does teach you oop!that is the exact equivalent of reading a textbook on the subject, except it's not presented in prerequisite order, so it's slightly harder to digest.a system that teaches is a system that allows you to notice the micro-skills you're missing faster than a textbook. a textbook is the brute-force approach.smalltalk is not a system that teaches. it's just a system. you can get out what you put into delving through it, but you can do that just as well with any random system. to be pedagogical, a system has to accelerate that process.> we're awesome! we're the superior learners, which is why we're superior, but alas poor us, it also makes us suck at teaching.er, no: people that \"know haskell\" (category theory) generally suck at teaching haskell (category theory) because people suck at teaching by default, because they haven't learned the meta-skill of teaching. and even those that do, haven't yet put in the effort to factor their mental-model of a given skill to turn it into a teachable skill.the people that can teach you something about haskell (category theory), are, y'know, teachers, that have learned haskell (category theory) and then applied educational principles to their understanding of it in order to be able to teach it well.has nothing to do with haskell, other than haskell actually having a relatively-difficult skill in it for people coming from a sweng background to learn. other languages are easier or harder for such people to learn, because the skills they require are more or less natural given a sweng background; and, comparatively, people with a cs or physics or electrical engineering background have other backgrounds that make different languages have a different skill-gulf. haskell (category theory) is easy for mathematicians. assembly is easy for electrical engineers. prolog is easy for db systems programmers. etc. nothing special about any of them\u2014they're just different points in knowledge-space, that different people start out closer or further from because of their backgrounds.> try and produce stuff.i do! not in haskell, though. despite writing the above, i have literally never used haskell once in my life. i'm just talking about it as a specific application of the general principle of skill-gulfs.> try and reach people.why?in all of the above, nobody ever said why anyone is trying to teach anyone else monads. honestly, i think people just shouldn't bother. no \"amateur teacher\" is attempting to teach anyone else graph theory, or linear algebra, or the x86 isa. professional teachers, at universities, do that, because those are skills independent of any programming language. people generally understand that teaching these skills is the job of professional teachers, and that you have to apply yourself as a student, full-time, to learn them.well, category theory is such a skill.in short: stop trying to teach people monads. petition more schools to teach people monads (category theory), outside of the context of any particular language. then haskell is just a language, with no skill gulf.to say that you should \"reach people\" with an explanation of monads, is like expecting rdbms docs to \"reach people\" with an explanation of relational algebra. it's not their job. you're supposed to come in with that skill. their job is to provide you a thing that you know you want\u2014a solution for a problem you know you have\u2014given that the skills you already possess give you the ability to evaluate that solution.", "i think one thing one should ask is:if monads are the solution to x, and we add a different solution to x to the language, then what are monads for?let\u2019s say you have imperative io. then promises are a monad but then you could just add language support for async and promises are not really needed as a monad anymore.a more functional replacement for monads could be something like algebraic effects. these could replace monads completely or they could be like multi core ocaml and only give you one shot continuations (so not allowing for list or other multi-shot monads).in this context i like to think about the continuation monad. in haskell:code_removed this means \u201csome computation yielding a r which got paused part-done having just yielded an a. in some sense all monads are expressible in terms of cont. i feel like this is largely the essence of why it is useful to have monads: they express computations which happen with some context, able to switch back and forth between things in the context and things in the normal computation. i don\u2019t think sequencing evaluation is so important to the definition.", "> if you actually need to care about the evaluation strategy, then haskell may not be the language for your project.almost all projects end up needing to care about performance at some point or other, if only a little. (so yes, haskell is probably not a suitable language for most projects, sadly)> but do you use monads for all the things haskell programmers use them for? or only a subset of those things?all the things, as far as i'm aware. certainly the obvious ones like io.", "> describing monads in terms of their strict category-theoretical definition helps no one, especially those new to haskell.i am a counterexample: the description of a monad as a monoid in the category of endofunctors actually helped me, especially when i was new to haskell. i am a mathematician, and happen to know category theory enough to appreciate this description. also, i am a little tired of hearing \"you don't have to know category theory in order to learn haskell\". what if i already do know category theory? i wish someone wrote a tutorial or a book explaining haskell to mathematically inclined readers and not dismissing (in a kind of anti-intellectual way) simple algebra as \"useless abstractions\".", "light table is such a koan, created by a master of the path of living-memory-image reflective systemstwo answers. 1) so then someone should create a haskell koan which has just as much popular appeal and broad intuitive popular understanding. but then again, not really, because: 2) really, get off of this koan nonsense. it was really just a very well thought out and effective demo which chose exactly the right way to get across the benefits of such a system.whereas, in smalltalk itself, the seams aren't visible, because the system is coherent.oh, there are seams! and warts!indeed, it is the rare software engineer who actually experienced any paradigm shifts regarding computer sciencereally? it sounds like you haven't experienced too many of those kinds of paradigm shifts. all you know is the math-y kind.haskell's design and ecosystem \"reflects\" enlightenment on category theory, somewhat like smalltalk \"reflects\" enlightenment on living-memory-image oop. neither system teaches those skills, though.absolutely wrong. if you delve into the smalltalk image and class library, it does teach you oop!the long and short of the way to communicate all the haskell \"stuff\" efficiently, not just monads, is to:1. give the learner the meta-skill...2. throw a category theory textbook at the learner...either put up or shut up. anyone can have an esoteric uber language off in a corner somewhere and tell themselves the world misunderstands them while circle jerking with like minded folks. been there, done that. the whole world is chok full of little groups like that. stopping at just that is not that which makes a difference in the world.what you are saying seems to amount to: \"we're awesome! we're the superior learners, which is why we're superior, but alas poor us, it also makes us suck at teaching.\" i call bs. it doesn't matter if your tools are superior, if their qualities and the community's qualities make them inherently inferior at gaining mindshare. either they're so superior, everyone will take the time to adopt them, or they're not so superior that it really matters that much.try and produce stuff. try and reach people. the world will see who succeeds. simple as that.", "most programmers don't try very hard and anyone taking the time to even learn a rarely used language is demonstrating a positive quality that most don't.once known as the python paradox i suppose it would be the clojure conundrum or the haskell happenstance", "i wonder what you would get if you crossbred postgres and haskell, for example.basically adding indexed tables to the haskell data model, maybe? some hybrid of relational tables and algebraic data types?sometimes even when writing compilers i\u2019ve had a feeling that relational queries and update would be really nice.there seem to be four main data paradigms: (1) objects with pointers, (2) algebraic data types, (3) relational tables, and (4) prolog-style clauses.some haskell programs seem to partially reimplement 1, 3, or 4 using 2...", "i actually disagree. i write very little haskell but i do read it from time to time, simply because compared to any other language it's simply so readable it's almost fun.in no other language have i ever got distracted from my main goal by just reading the source code of the libraries i'm using.", "it depends. i had a sysadmin consulting co. in high school that serviced nuclear, mech and thermo engineering companies. ml/ai, scientific and other specialized software eng are rarely picky in anything but pedigree and experience. for general-purpose coding, i wouldn\u2019t bother unless you\u2019re hackathon-insanely productive... also such jobs are more standardized and therefore more readily outsourced.haskell (biceps emojis here)", "1. i perhaps forgot to mention a key thing about the enlightenment process. most of the people being asked the question are those further down the path, but not further-down by much. journeymen, not masters.a journeyman is someone who has acquired all the micro-skills they were missing, and has thus gone on to achieve some level of intuitive grasp of the enlightenment they sought. they \"grok\" the skill.a master is someone who has gone back and thoroughly weeded their mental garden of the micro-skills they started with and took for granted, and have begun (though perhaps not finished) replacing those with conscious learnings. the master desires to attain conscious handles onto each and every part of the mental schema or process they seek to understand, in order to understand the enlightenment-requiring mental skill as a system, rather than as a simple intuition.a journeyman has a sense that they know the answer\u2014that they \"are enlightened\"\u2014and this sense works well enough to guide them when they seek to use the mental skill they sought to acquire. but, because they do not understand the enlightenment-requiring mental skill as a system, only as an intuition, they can give an apprentice on the path no answer that will satisfy them. this is the \"gallows humour\" stage of the path.yes, masters of the path will be able to guide apprentices. zen koans are written by masters, and they are no gallows humour; they tilt the world enough to allow you to catch sight of the micro-skills the master was attempting to convey. (in the modern world of analytic philosophy, koans might even have a hope of being displaced by jargon-laden explanations that can be drudged through to bash the concept into one's head, like a maths textbook. that doesn't sound exciting, but it is!)light table is such a koan, created by a master of the path of living-memory-image reflective systems, seeking to \"tilt\" as many parts of the system that smalltalk is into the light as possible. (granger's trick was contrasting those parts to a backdrop of regular, ugly concepts like javascript and electron that aren't part of the enlightenment-inspiring system. the concept-handles come clear at the visible seams of the light table system. whereas, in smalltalk itself, the seams aren't visible, because the system is coherent. you can't see the muscles of the perfect average face; it's too coherent to dissect.)putting this another way: most people who might be asked about something aren't teachers with education degrees. they're just students who already learned something and want to share what they learned. they fail because the thing is hard to share, and they don't have the skills about teaching required to realize what's making the thing hard to share and to fix it. (those that do have such skills, but don't have the time to apply them to the concept\u2014dissecting it and re-building it in a teachable-to-others form\u2014usually just keep silent, rather than attempting to share their learning.)> haskell['s journeymen] are such failures [to teach the required micro-skills] even in the face of an audience who has previously undergone such a paradigm shift.ah, but have they? many people have a natural mind for software engineering. they take for granted the concepts inherent in procedural code execution on a cpu or virtual machine; in parsing and lexing; even in pseudo-paradigms like oop.indeed, it is the rare software engineer who actually experienced any paradigm shifts regarding computer science (for those of us that took a degree in it.) usually it's \"easy\"\u2014meaning natural\u2014for those of an analytical mindset.all, perhaps, except for that one class you have to take at the beginning of a cs curriculum, discrete maths. a lot of the sweng \"naturals\" struggle at that. because discrete maths is not the same thing as cs. discrete maths is, in fact, maths.mathematicians are used to paradigm shifts/\"englightenments\" (i.e. learning systematic skills requiring working knowledge of many micro-skills). each subfield of mathematics is essentially named for the systematic skill required to comprehend work done under its aegis. mathematicians who read work in various sub-fields, are used to quickly achieving a journeyman's competence in the relevant systematic skills. mathematicians who specialize, who enter a sub-field, must necessarily become masters, if they have any hope of building upon that work. they must understand the required skill fully. (they must, by cute analogy, be able to build their light-sabers from scratch.)most software engineers\u2014including haskellers\u2014are not mathematicians. they have, other than that one time in discrete maths, never experienced the feeling of climbing toward an enlightenment. even then, discrete maths is often the lowest grade for a lot of new cs students. they don't yet have this meta-skill of climbing toward enlightenments\u2014of throwing themselves hard at formalized jargon using textbooks and references in an attempt to build a new systematic schema in their brain in just a few days. and they are almost never told that this is the true skill that their discrete maths course is there to impart into them. it's not about learning graph theory or whatever; that, just as much as a class on operating systems or vlsi or whatever else, is a practical, concrete skill for a software engineer. the discrete maths class in a cs program is about learning how to quickly learn those kinds of concepts. it's about discovering that these mental gulfs exist, and learning the skills required to cross one.if only it was taught as such;)the reason haskell is uniquely bad, here, is that haskell was\u2014perhaps problematically\u2014constructed by mathematicians, people who had already crossed one such gulf. haskell's design and ecosystem \"reflects\" enlightenment on category theory, somewhat like smalltalk \"reflects\" enlightenment on living-memory-image oop. neither system teaches those skills, though. you don't need to cross the gulf of category-theory to intuit haskell as a journeyman; you only do if you want to have the appreciation for the \"coherent shape\" of haskell required to make coherence-preserving modifications to its feature-set.---the long and short of the way to communicate all the haskell \"stuff\" efficiently, not just monads, is to:1. give the learner the meta-skill of being a student of mathematics (i.e. becoming a journeyman in new systematic skills by poring over textbooks and doing problems);2. throw a category theory textbook at the learner, who is now equipped to digest it.anything less is laziness\u2014though not necessarily on the part of the teacher;)", "haskell does not constrain the order of evaluation when dealing with real world. it constrains order of effects.the code \"putstrln this >> putstrln that\" is allowed to evaluate this and that in any order, basically. \"that\" may depend on \"this\" and vice versa. the very expressions \"putstrln a\" is also not an action, but expression, being evaluated into actions.and the constrainment of effects is what makes haskell special.", "> then we choose to use `io` (i.e. a monad) to implement that solution.yes, we are in agreement, however i am arguing that haskell had to use monads here otherwise it would be very difficult to use.> as long as we teach monads as if they have anything to do with io we're confusing people.sure, but the introduction of monads in haskell came out of a real necessity is my point. category theory is powerful tool for abstraction and useful in any language.> but monads don't control order of evaluation. they've got nothing to do with order of evaluation.right, but they can hide the trick and make it all seem transparent, which imho is very important point to keep in mind.", "it seems that you have built the io type and it's monadic properties into the language? i am talking about the concrete type of io has and how using it, without the monads as abstraction would be so cumbersome that haskell \"needed\" monads.you can't change the semantics but you can emulate the desired semantics, which is what i argue io type does.", "> not only that but you can expect to get better performance from the jit than aot because the jit can perform optimisations which are impossible for the compiler.i can\u2019t help myself, but the jvm performs at par with managed aot languages (go, haskell, ocaml, etc) and strictly slower than the unmanaged aot languages (c, c++, rust). the jvm does outperform various aot java compilers, but that\u2019s probably an artifact of the decades of optimizations that went into the jvm; the same investment in an aot compiler would close the gap to within the margin of error. anyway, sorry for my compulsive nitpicking; hopefully it was interesting.", "but the point is the language doesn't need monads. you could express the same solution to the problem more verbosely without monads if the language couldn't express monads. consequently, monads are beside the point.haskell needs to constrain the order of evaluation when it's dealing with the real world. there's a solution to that problem (require and yield `world`). then we choose to use `io` (i.e. a monad) to implement that solution.but the abstraction that is a monad is independently justified and worthwhile in languages like typescript (i wish!) and ml which don't have the same io issue.as long as we teach monads as if they have anything to do with io we're confusing people. io uses monads because it's convenient and apt. but monads don't control order of evaluation. they've got nothing to do with order of evaluation.", "yes, it doesn't at all seem right.after i learnt haskell, i was forever wishing the languages i work in professionally had monads. but they're all strict languages. monads give us a nice consistent way of working with stuff inside generic wrapper types (e.g. nullable, arrays, classes and other partially applied functions, state machines, data paired with a world, partial functions converted into (more) total functions by tagging success and failed operations). my professional languages have different solutions for all of them and so it's harder to separate the rules and the mechanisms with heavy syntaxit's more that it's very convenient to think of side effecting functions operating on a world and returning a new one once you already have this powerful abstraction.i like the fact that the type system encodes that the function has a side effect. but i don't particularly care that the language is lazy when i enjoy this benefit. they're quite independent.", "akwardly, i agree on the facts but the sentence doesn't feel right. would you agree with this rephrasing: asm is simple in terms of number of abstract concepts needed to define its syntax and semantics (and as far as i know this is good since it's intended as a mother-of-all lingua franca), but of course every language out there is turing complete (and has some mechanism for syscalls); so in the end the only way to build haskell-like abstractions in asm is actually to code up ghc and then code in haskell. which i wouldn't call at all programming in asm (just like i'm not commuting circuits by typing on this keyboard). nor do i think this is actually what asm is used for (when written by humans). my guess is that asm is used for programming close to the metal--crucial parts of firmwares, drivers--in situations with simple logic and in which abstraction would actually get in your way (who care about types or functions when you just need to write some values into some memory location).", "> there's no wrapper, and \"interface\" is misleadingtrue. i used a convenient lie to make a point. if you're interested in learning monads you should definitely learn it from a proper source like haskell from first principles [0], an online course, or someone who really knows what they're talking about.as i only alluded to and others have pointed out: there's nothing about monads that's inherently sequential or having to do with ordering operations. that's just how the language defined the interpretation of the io monad. and it also happens that this is the primary topic of concern of tfa.you might even come to realize that much of what a monad isn't contradicts the entire premise of tfa... haskell doesn't even need the io monad and could implement io other ways just fine [1].[0] [1]", "> to discuss this properly, you need to consider the evaluation strategy, which is part of the semantics of the language.yes, you are certainly right. i misread and thought incorrectly that the discussion was about whether certain constructs forced data dependencies in any theoretical language, not in the particular language haskell.> these details of evaluation order are important to know, and they are not something to be argued about: they are well-specified \u2026.while i take your meaning, i think that you don't mean literally what you said: they got to be well specified precisely by being argued about, and will hopefully get to be even better specified by continuing argument. they are certainly not for me to argue about, though.", "> programming in asm isn't really \"harder\" than programming in haskell, it's just slower - it requires discipline, but not the ability to grasp abstraction that some more modern languages need.reminds me of this comment:", "i'm not that sold on this. programming in asm isn't really \"harder\" than programming in haskell, it's just slower - it requires discipline, but not the ability to grasp abstraction that some more modern languages need.i think that issues like knowing \"how do compilers actually work\" or \"this thing is actually the halting problem, let's stop\" are more relevant than how removed from latches and memory controllers one is.", "in haskell? i'd construct an api that could be used like the following. this looks like the code we write at the place i work at:code_removed the signatures of socket, bind, etc, would look like (for example):code_removed then, at top levelcode_removed the key here is that error handling is factored out. the 'runservice' function expresses concisely all the steps taken, and the entire concern of error handling is factored out into the 'handleerror' function, whose behavior i can actually change based on what i may want. in a c implementation, changing error handling strategies, would mean passing some kind of flag in (you could rebuild exceptions using setjmp/longjmp, but meh).", "to discuss this properly, you need to consider the evaluation strategy, which is part of the semantics of the language. strict, lazy, call-by-need: things do get evaluated in a prescribed order, and sequencing using monads (predictably) involves strictness, meaning that a function argument is evaluated before the function.these details of evaluation order are important to know, and they are not something to be argued about: they are well-specified and the compiler doesn't just casually make lazy code into strict code or vice versa. that would cause chaos. and what instruction set haskell is being compiled to is totally irrelevant to this level of the language's semantics.", "i'd say the problem with all these monad explanations is the people reading them are in general object oriented programmers (like me) and the problem that exists in functional programming just isn't an issue in c++ / swift etc. its never explicitly stated because functional programmers are just so used to it, its like air.so in a very naive way - here's the problem, when you apply a function and get a result you have no state - the function doesn't remember what happened. in object oriented programming you always have the state - its in the object, or other objects floating around, and methods can always reach out into surrounding objects to get bits of state it needs, pure functional programs can't do this - they have no state except the things that are passed as parameters. the haskellian way around this is to pass around the context of what just happened - vaguely the context is the surrounding bits of data you need to keep track of.monads, functors and so on are the ways that haskell keeps and manipulates the context and the value. the rules also have a very nice mathematical theory which they fit into. most haskell intros start from maths and shoe horn the code into this - its not really necessary. this clarified it for me", ">because of the way the rules of the monad interface are structured you're guaranteed that the functions you use to compose your monads together will be executed in sequence with respect to their definition in your function body.no! monads don't guarantee sequencing. some particular monad instances do (e.g. io). but there's nothing inherently sequential about monads. see e.g. point 10 of the following:", "if you actually need to care about the evaluation strategy, then haskell may not be the language for your project.> meanwhile i find monads very useful in scala, even without any laziness in sight.but do you use monads for all the things haskell programmers use them for? or only a subset of those things?", "i find that kind of comment incredibly misleading. the concepts that most people attach to lists and optionals don't touch functor semantics and thus are miles away from monads.saying that lists are an instance of monad in haskell says much more about novel ways you can use a list in haskell than about properties of a monad.", "children aren't born knowing c, and people who learn functional first don't tend to find it any harder. (if anything it's easier, since the meaning of \"=\" in haskell is much closer to its usual meaning than the meaning in c).", "ordering of operations is done by the non-associativity and non-commutativity of the bind operation. data dependency is not sufficient for ordering io\u00b9\u00b2.well, that's in theory at least. in ghc haskell the ordering is not denoted by neither data dependency ot the operator semantics, but by a complex set of rules that change from one version of the compiler to the other.1 - although it is sufficient for any monad that lacks real-world effects.2 - well, technically nothing is enough for really ordering io operations, but those two properties give single-threaded semantics to io.", "> where do i do that?\"i assume 'diversity of thought' refers to expressed thoughts...\"> first, i am struggling over how to identify 'diversity of thought' during the interview process.i think we've covered this pretty well, so your struggle isn't over the \"how\" - but the \"why\".> is it something different than \"can come up with innovative solutions\" or \"out of the box thinking\" or \"creative problem solver\"?it is no different, with one exception: it is measured in relation to your existing organization. if all your programmers are proponents of the functional programming paradigm, hiring another haskell programmer, while relatively novel to the rest of the industry - likely does little to increase your organizations diversity in thinking (without additional screening parameters).> these seem like two different interpretations of that phrase...they are: one is selecting for proxies, presumably as a shortcut. the other is directly addressing what is desired. i'm always amazed at how proponents for such selection mechanisms are totally oblivious to how ridiculously prejudice it is.>...i lean towards ubernostrum's down-voted comment that \"diversity of thought\" seems often used as a euphemism for \"put up with assholes\" (my interpretation).clearly.> which means you end up biased towards rules lawyers. which may be what you want, but bear in mind that you are presenting one performance goal while you have withheld a secret goal that you are actually looking for.boom, point proven. you have at that point learned something about that candidate's way of thinking, select on it or don't. if that was a hidden goal then it worked, if it wasn't then disregard.> here's a less secret goal: the test is meant to see if you know what modern c++ is like...not a diversity of thought test.>...and if you have a good idea of what the posix mindset is like (so you don't end up asking pointless rules-lawyer questions).that is a diversity of thought test. is the candidate willing to, in the face of ambiguity, insert his own opinion instead of speaking up?> which of these possible secret goals should the interviewee try to optimize?as i said earlier: the one that, in your experience, indicates an ability to do the task that the candidate is hired for. should there be a tie, the one that arrived at a solution that you did not anticipate. and no, that doesn't mean you should hire a guy who insists on sorting files using node.js, just because he was the only one... you can't determine rationale based only on language selection. if he does it in shell script, ask why. you may learn that binary compatibility concerns are higher on his priority list due to some past experience that you wouldn't have considered.>...the essential problem remains - does \"diversity of thought\" differ from \"highly competent and creative problem solver\"?yes, but first i'll point out that \"highly competent\" is an unrelated concept. because effectively nobody has unbounded useful creativity over an entire problem domain, you want to select individuals who's constraints overlap as little as possible - thereby covering more of the problem domain. personal example: i took over a database from the engineering department because the guy maintaining it retired. i was horrified when i looked inside, the architect was obviously a plc programmer - using triggers and views to form a hellish logic ladder. i was trying to figure out how i'd be able to untangle everything into a more tradition normalized database when i got a request from one of the engineers to insert a new trigger to account for some upcoming process change, i told him how much i didn't want to do that and asked if i could spend a day with him in order to get a better grasp on their problem domain - he was annoyed, but agreed. well it turns out the old engineer wasn't totally insane, the problem domain was pretty much unbounded and constantly changing: new metrics, new datatypes, new requirements - totally normal for their department. whereas i would have used a domain-key normal form in that situation, he just created a new table and added a trigger. both styles work, each has different weaknesses and strengths. neither of us would have arrived at the other's solution. diversity of thought.> in my description, the first argument is a filename. the contents of the file are a set of lines, terminated by a n.lol, even your attempt at clarification adds confusion. the ambiguity this time: is the set of lines terminated by n, or is each line in the set terminated by n, or is the file terminated by n? yes, i'm pretty confident that i know what you mean - but i have seen 0x1f used for stuff like this in production, bad things would have happened had i just made an assumption.> otherwise the desire to sort the contents makes no sense.sure it does: if instead of interpreting the explicit mention of ' n' to mean line termination within the file, one interpreted it as the termination of the first parameter. again, one can guess the intent due to convention - but it is ambiguously phrased and immediately led to two competing possibilities of intent in my mind. maybe that is because i think differently from you...", "as far as i can see, explaining io in haskell in terms of monads is unhelpful. it would be like using monads to explain how list concatenation works. the fact that e.g ( x -> [x]) and concatmap form a monad is not really very helpful in understanding what concatmap does.", ">the monad bind operator introduces a data dependency which is responsible for the sequencing itself, not the actual implementation of the bind (i.e. it is a result of the type of the bind)no, there is nothing in the type of >>= which guarantees sequencing of side effects. so for example:a >>= ( b -> c)there is nothing in the type of >>= that guarantees that a will be completely evaluated before c is evaluated.i suspect this misconception is what makes many people think that haskell's way of handling io has something crucially to do with monads.", "does haskell support bofa monads?", "the operational perspective is valid but it doesn't help to answer the question, imo. if your answer to \"what is the problem?\" is \"the problem is our hard-to-predict evaluation strategy\", then the beginner's natural follow-up question is \"why not just use a normal evaluation strategy?\", and there's no good answer to that one (indeed many regard haskell's laziness as the wrong choice; in recent times we've seen post-haskell languages e.g. idris moving away from it, and the best-known industrial deployment of haskell uses a strict variant).meanwhile i find monads very useful in scala, even without any laziness in sight.", "i hate to be \"that guy\" but take a look at rust if you haven't. it's pretty close to c but incorporates a lot of functional-style type magic. your particular example is very explicitly supported by the `result` type (which is an error-specific version of haskell's `either` type). it also has some syntax sugar and macro usage to make working with error types pretty simple.", "you might like to look at clean (terrible name) which is roughly as old as haskell and in a similar style, but instead of monads it uses linear types to enforce the order of io -", "in haskell, the 'if (err) {... }' parts could be factored out into a new bind operator for a new monad stack. then, you don't have to write these checks every single time. the do notation is automatically converted into the corresponding monadic code, and the algebraic monad laws guarantee that the meaning of the code is preserved.for example, for the `if (err) {...}` cases, this is just the `exceptt` monad transformer.with regard to understandability, using error throwing code in haskell is really easy. implementing it is slightly more difficult, but so is implementing a c compiler. i mean, we shouldn't judge the utility of a thing based on whether the implementation of the thing could be understood by a child. by that measure, children would be incapable of using facebook, because they could not build it.", "an enlightenment is a realization that culminates only from all of a set of micro-skills being attainedthere are lots of disciplines/areas of human knowledge and culture where most of the micro-skills have inherent rewards for learning them.when faced with someone starting on the path to an enlightenment, who asks you to simply summarize the path for them, there's no way to actually usefully tell them.i think that has to do more with not being motivated enough to try hard enough combined with the difficulty of summarizing. it's one thing to try to explain a paradigm-shifting insight or system to someone who has never paradigm shifted to learn something. the thing about haskell outreach, are such failures even in the face of an audience who has previously undergone such a paradigm shift.you don't make the joke to be snarky. you make the joke because you wish that, this time, it would work, and the learner would skip the path and achieve the enlightenmenthow is this different from laziness? smalltalkers similarly gave up trying to convey how their environment was different, many of them with such snarky jokes. then years later, chris granger comes along with light table, and transmits what it is quite clearly and succinctly.", "i want to be careful about doing internet psych diagnosis, but you sound (from your previous comments) like you may be somewhere on the spectrum of depression/anxiety. have you thought about talking to a professional?i have no idea what my iq is. i definitely know what my present limitations are, and i think about them a lot (i'm a little obsessed by the limits on my willpower that keep me from e.g. spending 8 consecutive hours studying abstract algebra, or learning haskell). but i'm not alarmed by them. i am naturally \"good at\" some things (i'm coming to believe that \"good at\" is almost a synonym for \"enjoys/gets a charge from\") and other things are uphill climbs for me. i try to arrange my work so that my uphill climbs are always for a reason. i think this is a healthier attitude than trying to gauge some very-probably-fictitious intrinsic \"iq\" attribute to find my place in the world.if you can write in complete sentences and in a conversational tone, you're doing fine on charisma. having organized and been involved in hn meetups in the past: you are almost certainly not anomalously inept in social situations. we are not the funnest cocktail party in the world.i came across this post because i have a saved search for \"iq\" (historically, \"iq\" has been a reliably marker for seriously gross threads) and not because i clicked through on an \"ask hn\" about \"coming to grips with your own mediocrity\". i'd gingerly suggest that the whole notion of \"coming to grips with mediocrity\" is a bit toxic and crazymaking.", "could you elaborate? as a c guy, i'm interested what you think would be simpler than that simple code you posted. structurally, what you just posted (minus the details about what \"socket\" and \"listen\" mean) could be understood by a child. i'm skeptical the corresponding haskell >>= construction would be so understandable.", "i'm not really talking about haskell. certainly not ghc.", "> these bigger, more useful programs you can write with haskell are pretty much unreadable though.this seems somewhat baseless. unreadable according to whom? there are many large and complex programs written in haskell by large teams of developers (open source or otherwise). it\u2019s the nature of software in any language to become difficult to manage as the code base becomes large; i don\u2019t think haskell is an exceptional offender in this category.> there is a reason everyone is not jumping into the functional programming bandwagon, despite mature languages being available for 30+ years.there certainly are reasons for that, but not the ones you laid out.", "everyone thinks their own code is readable. it's when you jump into a project with code written by 10 other people that you get an idea for a language's innate readability. in my experience i tend to agree that haskell does not score high on this dimension, its syntax is too terse and too flexible and there are few conventions about how to organize large codebases.", "while programming, i end up reading the source of most badly documented packages on hackage that have some interface that looks like what i'm doing. nearly all that mostly low quality (correlates pretty well with lack of documentation) code is perfectly legible (although some have other problems).i have never seen any language get near haskell on the legibility of random code on the internet.", "'so it's a wrapper that implements a particular interface? then why, oh why, do we have so many people who spout, \"a monad is just a monoid in the category of endofunctors, what's the problem?\"'\"monad\" seems to be just beyond the complexity event horizon where it is difficult for people to get a really clean idea of what it is, so instead we've got dozens of ideas of what they are floating around, probably a good two-thirds of them with fundamental errors in them, which then contributes to the general haze surrounding the ideas.i've got a mostly-written blog post on deck with the tentative title \"functors and monads for people who have read too many tutorials\", for which around 80% of it isn't explaining what they are, but systematically walking through all the errors i've seen (some of which are in the type notation for haskell itself; the \"[a]\" abbreviation for what should be \"[] a\", if not \"list a\", alone has done untold damage to comprehension) before finally getting down to what the things are.(functor in particular is so trivial it's hard to believe it's that trivial when you finally really get it. monad legitimately has a bit of a twist in it, and some of the specific uses of that interface take that twist and hammer it home to produce some very funky code, so the fact that it's a bit foggy isn't that big a surprise. the fog that functor has picked up by association with monad is much, much larger than the concept itself, though.)\"so it's a way of imperatively declaring execution sequence dependencies that lets you reason as if there's only pure functions most of the time.\"it turns out no, that's just one use of them. a very big one, a very natural one, and the one that drove their prominence in the current debate... but it's not actually what the interface is \"about\" per se. for a good counterexample, consider the parsing monad implementations that \"declaratively\" [1] create a parser. it's not really about declaring execution sequences.(there's also a non-trivial amount of confusion that arises from the fact that monad and laziness have a lot of interaction. the monad interface in a strict language would be used differently than it can be in haskell.)", "> then why, oh why, do we have so many people who spout, \"a monad is just a monoid in the category of endofunctors, what's the problem?\"it's a joke/dank maymay that haskells still find funny long after it's pissed everyone else off.the idea is that since category theory is described as \"generalized abstract nonsense\" by its practitioners, describing monads in terms of their strict category-theoretical definition helps no one, especially those new to haskell. the problem is that unless your audience is steeped in category theory, they can't appreciate the irony of the situation and you just come off sounding like a dick.", "i don't think this is accurate. haskell \"cheats\" by making io special and magical [1]. ghc has this definition:code_removed the haskell standard, last i heard, specifies the implementation of io as being compiler-specific. i may be wrong, but i believe you can't reimplement io yourself in pure haskell, at least not the way ghc needs it to be defined.as the article points out, this has little to do with monads. you can force ordering using unique types [2] (e.g. used in clean) by having i/o functions take a file handle and return a new file handle in every call. but io fits nicely into the monadic pattern.[1]", "i think the commenter is referring to the process of declaring an order for executing a compute graph. with csp languages this is established by the order in which the statements appear and reference each other, and computation is explicit: all previous statements in a given process have finished executing at any given point.this is in contrast to haskell that uses monads to declare the computation graph (well, functions, but monads are under discussion here). in this world, data is computed lazily as needed. the questions you ask about the code center around functions and their dependencies, not necessarily computation order.a task that is trivial to express with on paradigm might be non-trivial to express on the other: haskell is excellent about expressing lazy computation and side effects, whereas a csp language will offer easy reasoning about the specific and correct order of execution.note i am not a pl expert, just an enthusiast. my diction may be off for the domain.", "to my limited non-haskellian understanding, you can give a block of expressions to a monad. it then decides which expressions to evaluate, in which order, optionally depending on the value they might return to the monad. so you could have a monad which does \"evaluate all these in order unless something goes null\" (which is a nuisance to type in c-style languages), or one that expands on the if-then-else concept. none of these carry forward internal/hidden state like an io monad does, but are there to expand user control for how to flow from 1 expression to another in your custom scopes.it's somewhat conceptually related to command or visitor pattern programming, but haskell has syntactic sugar to have them basically work similarly to normal statements. alternatively, this is a runtime-only version of one specific thing that lisp macros can do to &body scopes, in constructing custom control flow.this also is only 1 way to use monads, as they're a technically pretty simple tool (an interface with 2 functions) that can be used in a bunch of scenarios.[if i'm wrong, and i'm probably wrong, i'd love clarifications for myself, too!]", ">not only do you get to use it's wonderful type system but you can compose together small imperative programs into bigger, more useful ones.these bigger, more useful programs you can write with haskell are pretty much unreadable though. there is a reason everyone is not jumping into the functional programming bandwagon, despite mature languages being available for 30+ years.", "haskell doesn't \"need\" an io type\u2014it wants one. the io type gives us a language-level way to separate code that has side-effects from code that doesn't. it's a powerful tool to help manage complexity in our programs.one of the advantages of keeping io in an explicit io type is that code that isn't in io becomes easier to refactor. this is what people mean by referential transparency: since i know that a `char` cannot implicitly depend on the state of the rest of the program, i am always free to move it around, put it in a variable or replace it with an equivalent expression without changing the meaning of the program. you would not get this with getchar:: char because two getchars could give you different results, so moving them around or reordering them would change the semantics of your program.", "a side point since the author pointed to agda as being more pure than haskell:in many practical situations, computations have deadlines, which may either be a timeout or the user giving up and cancelling. languages that guarantee that functions terminate aren't as useful as you might guess, because they don't say anything about how long it will take. (it could be millions of years.)a guarantee that a function will terminate is useful when you can avoid evaluating the function at all, while relying on a function call's existence (without compile errors) as a proof that the result exists.it's not too often that you want to know that an answer exists without knowing the answer. this mostly comes up in mathematics when proving things.", "if you're looking to understand what monads are or why they're interesting this isn't the place to figure that out.monad: if you have a data structure that wraps some value of any type, then you also have to implement the interface that provides `return` and `bind` (there's talk about requiring another method, `join` but i digress). the data structure is the \"context\" and the interface is how you compose values from other monads together using functions. if you can prove your implementation of the interface methods follow certain rules then you have a monad.why is this pattern/abstraction/interface useful in haskell?i think there are several reasons. the article touches one of the most talked about: sequencing. because of the way the rules of the monad interface are structured you're guaranteed that the functions you use to compose your monads together will be executed in sequence with respect to their definition in your function body.(how it all ties together is straight-forward but requires a certain pedagogy and exposition to follow that i won't get into.)this is, consequently, what makes haskell the best imperative language in the world. not only do you get to use it's wonderful type system but you can compose together small imperative programs into bigger, more useful ones.", "this is a somewhat misleading way to think about haskell and monads\u2014it puts the cart in front of the horse and obscures both how haskell deals with effects and how monads are more general and useful than just io. this blog post ends up mystifying more rather than demystifying.then again, this shouldn't be a surprise from an article that describes the haskell ideas as \"the haskell monadic dogma\"! you wouldn't expect a particularly charitable or educational account to start like that.a much better way to think about it is to think about io without considering monads at all. one of haskell's core characteristics is that it explicitly separates code with side effects from code without side effects using the io type. this is a powerful design in and of itself\u2014it's a tool for helping programmers manage effects and not a hack around laziness.personally, more tools to manage effects is exactly what i want. after all, even in languages, code i write is carefully organized to separate most side-effects (api calls, database accesses... etc) from the domain logic, but this happens solely through convention and code organization. having tools in the language to express the same separation is powerful.note how i never needed to talk about monads here\u2014io is the important concept. with this in mind the real question is not \"why does haskell need monads?\" but \"why are monads a useful abstraction?\". this gets a bit long for an hn comment, but i wrote a blog post with my thoughts a few years back. it started like this:> i believe the notion that haskell uses \u201cmonads\u201d to enforce purity is rather misleading. it has certainly caused quite a bit of confusion! it\u2019s very much like saying we use \u201crings to do arithmetic\u201d. we don\u2019t! we use numbers, which just happen to form a ring with arithmetic operations. the important idea is the number, not the ring. you can\u2014and most people do\u2014do arithmetic without understanding or even knowing about rings. moreover, plenty of rings don\u2019t have anything to do with arithmetic.> similarly, in haskell, we use types to deal with effects. in particular, we use io and state and st, all of which happen to form monads. but it is still better to say we use \u201cthe io type\u201d to do io or that we use state for state than to say we use \u201cmonads\u201d to do io or state.you can read the rest here: is by no means a definitive discussion of monads or anything like that; it's just a perspective i found useful for understand what haskell gets by having a monad abstraction and why it's interesting.", "actually, that is not entirely true. the monad bind operator introduces a data dependency which is responsible for the sequencing itself, not the actual implementation of the bind (i.e. it is a result of the type of the bind).but i do agree with the general idea that haskell as a language is still a leaky abstraction, you still need to understand a lot of behind-the-scenes stuff, like how the rts interacts with the os abi, how concurrency is implemented, the consequences of laziness and so on. just knowing the denotational semantics of the language is not enough.", "data dependencies don't viably smuggle operation sequencing into haskell. consider e.g.:code_removed the sum depends on the product but this doesn't sequence anything: it may be compiled into a single fma machine instruction. more generally inlining, cse, etc. can break apparent data dependencies.it's simpler and cleaner to merely state that the haskell runtime is written to execute io actions in sequence.", "it\u2019s faster to write typescript than javascript. because a) you get properties and type definitions popping up in your text editor as you write code and b) you eliminate a tonne of run time bugsthere\u2019s basically no extra effort to using typescript if you already have a build pipeline running. it\u2019s not like using java or haskell where you\u2019re drowning in type definitions.", "well, then you came pretty far already. this post is not a tutorial on monads. it\u2019s really his thoughts on why he sees monads are needed in haskell. (and not needed in, for example, ml.)", "it is a completely wrong-headed perspective. monads are just an abstraction, they do not \"turn the language\" into anything; code that uses monads is normal haskell code evaluated with the same lazy strategy as all haskell code.haskell also does not need monads to do io as the author suggests. if you made monads impossible to express (as first class concepts) in haskell, say by blasting hkts out of the language, you would still do io the same way, just with concrete functions instead one's parameterized over an arbitrary monad. if you made haskell strict, you would still do io the same way (as an unrelated note though, i believe you would need to add an unbounded looping combinator uloop: (a -> io (a, bool)) -> a -> io a)", "unfortunately, the haskell wiki is not a great place to point beginners. the wiki's growth was rather... organic.", "i dunno, to me the whole 'abc coders are xyz' is a heuristic. i value curiosity and i find that devs that are solid at a wide variety of paradigms often get there through curiosity. so if someone tells me they are learning clojure/haskell/scheme/racket/ocaml/brnfuck/scala/smalltalk/etc i'll think that's interesting and wonder what made them decide to learn the language. without further information it's a safe guess that they are curious and enjoy learning new things/challenging themselves, things that i think are cool to do. and people who do cool things are often times cool people.but daiyi's main point isn't that abc coders aren't xyz, but rather that other people are also xyz, and that if an efg coder becomes an abc coder and are found to be xyz then they were probably xyz back when they were efg before becoming abc coders.and this point should be well taken. there is a common trend that analytic subjects contribute more value than artistic subjects. this, in part, is due to the phenomenon that analytic subjects have values that are easier to calculate (...analytically, whence this is somewhat circular) while artistic subjects have effects that must be evaluated more subjectively. a coder works for a week and adds a new feature which increases marketability. a painter works for a week and produces a painting that may eventually sell for $500 in a couple years. but this undervalues the painter---the effect of arts on a society is more than their retail value.i think this in part describes why web devs/front end engineers are socially valued less than coders in the development community. their contributions are harder to quantify and the problems that they solve are more diffuse and subjective. this leads to \"it's hard to quantify an efg coder's contribution\" being conflated with \"efg coders contribute less\".but this is bs---i have yet to come across anything that isn't both an art and a science if done correctly. in fact, this thought lead me to my own answer to one of the great philosophical questions of the ages: \"what is art?\": i contend that art is anything done well.and as a computer scientist with a prior life as a musician i can assure you that there is plenty of 'calculation' that goes into the arts. sometimes this is explicit. for instance, say that i have a closed voicing cfa (closed voicing means everything is close together) and they are moving to b?g that will then move to ceg. what do i want to replace `?` with? well we don't want f to move down (we try to avoid parallel motion, this can be thought of as a sort of axiom) so f must either remain fixed (oblique motion) or go up (contrary motion). we also don't want voices to cross (while voice crossing is less taboo than parallel motion it is still often avoided, and our adherence to this restriction makes our problem much easier). since we are working with a closed voice we have two (diatonic) choices: we can double the g or stay fixed on f. doubling the g is boring but staying on f creates dissonance (b to f is a b5 and f to g is a m2). luckily this dissonance is nicely resolved by the subsequent voicing and we win music! yay!notice something? this is just a constraint system! but rather than solving a sat formula we are adding in some subjective data to consider as well. i like to phrase this as \"in math, `1 + 2 + 3 = 6` while in music, `c + e + g = happy`\".these calculations can also be done implicitly: say i'm taking a break over some jazz tune and i'm hitting a turn around, a ii-v7-i. i have a vague notion that i want to hit the \"billie holiday special\" ( at the end of my break (a melodic 5-2-1 with a slight scoop up to the 2 which falls back to the 1). i'm in the key of bb and i want to play this around the tonic at the 8th fret of my d string. right now i'm in the upper area of the neck and about to change to the ii chord which holds for two beats. i want to leave a pause over the v chord to make the tag more interesting, so i have exactly two beats to get from where i am to where i want to go, and i have to quickly 'calculate' this transition in real time. this is, of course, very natural since i've been playing for most of my life, and the 'calculation' is more of a feeling than an explicit mental exercise. but underneath the hood there is a shitload of precomputation that i did, practicing similar harmonic and melodic situations, honing my instincts, expanding my ear, studying theory, etc. i have just, in real time, solved a complicated constraint problem in front of a room full of people. and they are all cheering for me! see? people love math!i'm sure i don't have to argue the reverse direction on this site (namely that coding/engineering/mathematics/etc are all forms of art) so i'll omit this.all this is to say that the distinction between the artists and scientists is very blurry. i won't go so far as to argue that it doesn't exist since it clearly does. but when i try to figure out what that distinction is i find a number of qualitative differences but nothing quantitative.", "it's worth noting that the io monad implementation is very much compiler magic and can't be done in library level haskell. evaluation order without io/st is undefined in haskell. this is similar to write barriers, you need a magic primop to specify external data dependencies.without that magic the compiler may inline everything, drop the 'uselss' state token and happily move your buffer freeing before the allocation - or drop it entirely.alternatively you could mark every function as noinline and end up with fantastically slow code.", "> monads in haskell are used as a mechanism for scheduling evaluation, thus turning a language with a hard-to-predict evaluation strategy into a language with predictable, sequential, interactions. this makes it possible to add interactive computations such as state and input-output to the language, noting that benign (non-interactive) computations are already a part of the language, transparent to the type system.that's a very operational/imperative perspective, and to my mind is putting the cart before the horse. to me the whole value of monads is that they let you talk about things like state and input-output in a declarative way, using plain old functions and values, rather than having to use these awkward/confusing concepts of \"evaluation\" and \"scheduling\".", "reading this: did not make me come to that conclusion.the io monad is noncommutative, and thus controls sequencing of operations, because of data dependencies, more or less hidden.a \"haskell wizard\" tried to tell me the ordering of operations was implemented through low-level magic a few weeks ago. the fact is that whatever ultimate form ghc might compile your code to, the sequencing is expressible in the semantics of haskell code. getting sequencing into the semantics is one of the problems which monads solve.", "the more i've learned about haskell, the more i've come to realize that haskell's approach to io really has very little to do with monads. fundamentally, haskell implementations sequence io actions using hidden magic. (ghc uses dummy world variables.) as it happens, the operations for constructing io actions from pure values and for sequencing io actions form a monad. but that's not really any more interesting than the fact that e.g. ( x -> [x]) and concatmap form a monad.", "right, here's my implementation in haskell:code_removed each `case` represents a couple of hypothetical contexts, applying case analysis to the either (the or). you're going to have to duplicate some work, since the `left a` branch appears twice and you're getting the `a` from different places.", "> doesn't work as well in languages where indentation is significant.store the bytecode, indents and dedents are present as <indent> and <dedent> token which are no different than e.g. <brace, open> and <brace, closed>.well technically those are in the tokeniser, the ast or bytecode would reify the structures they delimit, and if you stored the ast or bytecode the separator would be reified from there.but the point is that for the machine indentation is no different than any other token (in fact haskell is defined using braces and semi-colons, the common indentation-based version is an augmentation of the base language which semantically just inserts braces and semicolons)", "here's a great talk by simon peyton jones on integrating linear types into haskell:", "stevebmark's comment got me thinking about ui technology in general and computer science.the thing about ui... it's just, plain, _hard_.there's not much more to it then that. \"ui is hard\". user interfaces, no matter if they're text based or graphical, are perhaps the most frustrating field of computer science. they look simple. \"oh, this is just a bunch of boxes and text. i can bang that out in an hour!\" three weeks later. sound familiar? it's that illusion of simplicity that drives programmers crazy. ui has, as far as i can tell, the highest ratio of perceived simplicity to actual difficulty of any other computer science field.so here we are. we have several decades worth of computer science under our collective belts. over the plethora of decades that our field has existed we've: invented the transistor, made it the size of a handful of atoms, flew to the moon and back, beat humans at chess and go, can make video calls half way around the planet, and have crammed unthinkable amounts of technology into our pockets in the form of smart phones. my house bends to my very _voice_ thanks to modern computer science.but in all that time... ui is still hard.i don't think a lot of programmers stop to think about that. maybe, just maybe, all this thrashing about with ui libraries has more to do with the fact that ui, as a computer science problem, is perhaps one of the most complicated, impenetrable problems we've come across. the perceived simplicity of the problem so often blinds us to that fact.i believe it stems from a shared \"ancestor\" with multi-threading: concurrency. every programmer knows and fears the problem of multi-threading, but they don't fear ui in the same way. yet, these two problems are more alike than not. a ui is a system that is filled with concurrent, unpredictable, events and threads that could happen in any order. that's a multi-threaded system.so it's no surprise when viewed like this that ui is hard. it's very difficult for us to reason about a multi-threaded system. even the best engineers in the world make \"obvious\" (in hindsight) mistakes when they build concurrent systems. look at all the bugs that pop up when researchers attempt to do formal verification of concurrent primitives implementations.so if it's impossible for us to reason about ui, as a concurrent system, then what do we do?my time spent with rust, the programming language, has given me some theories. rust is most popularly known for its memory safety, but its true power lies in its type system. rust is the first language i've encountered to expose to the user an advanced type system in a practical way. languages like haskell et al have of course had these advanced type systems for _decades_. but rust offers them in a way that is digestible and ergonomic. for us common folk at least. it's perhaps the first chance that we as an industry will have at a widely used programming language with advanced typing and static analysis.that advanced typing system is what gives rust its true power. most salient to this discussion is its usage of the traits send and sync. these two traits allow us to communicate to other engineers and the compiler that \"this type is safe in these concurrent scenarios.\" suddenly the frightening world of concurrency blows apart. instead of being afraid, you can be fearless. write whatever code you want and then the compiler will check it and prove (in a limited sense) that your program is correct and safe.it's an incredible shift for programmers to have this power. send and sync are a small step in a new direction: being able to leverage static analysis by the compiler to assist programmers in designing their systems. before, in e.g. c, it was up to the programmer to think about all the state of their program in their head. at best we suck at that, especially in complex scenarios like concurrent systems (and ui!).now we have tools that can augment our mental facilities. in the same way you don't have to think as hard about memory in rust as you do in its ancestors, you don't have to think as hard about concurrent systems because the compiler and the libraries and types we build alleviate the number of problems we need to think about.i believe that it's possible this road that is leading to a brighter story for concurrent programming is also leading to a brighter story for ui. rather then having to think about _all_ the states that a ui and its backing state machines can be in, we instead build type systems that allow us to describe how we believe the system should look in our heads. and then the compiler will do the dirty work of proving our assumptions correct. our compilers will be 1000x better then us at considering an exponential number of states that a ui could be in given its concurrent and unpredictable nature.so just imagine a ui framework built on top of an advanced typing system. we could do insane things like using the typing system to say that certain view elements should only be visible given certain states in our model. for example, the logout view should never be visible when the user isn't in the loggedin state. and the advanced typing system, combined with the compiler's static analysis, checks all of our state machines to prove that logout will never be visible unless the loggedin state is active.it's crazy, right? but i think it's possible. just like rust's lifetime analysis can prove when certain objects will be alive so that the borrow checker can check all your references are alive and safe. i don't think it's so crazy to imagine a future where the compiler can determine the lifetimes of a view and make sure they aren't referenced in certain states.anyway, the most important thing i wanted to communicate is that ui is hard. really hard. and we shouldn't forget that. we should approach ui with the same caution and respect that we do multi-threaded programming. perhaps with that mindset less programmers will fall into the trap of frustration. that trap that has led so many to believe that it is our libraries and frameworks that are broken, and to go off and build yet-another-framework in the vain attempt to \"solve\" ui without making any real attempts to innovate on the core computer science problem that is ui.p.s. i'm not terribly good at communicating the strength of rust's type system and underlying compiler. there's just something magical about rust that makes it easy to write an api where a) it's obvious to users how to use it, and b) it's a compiler error to use it wrong. it's not any one thing and it's easy to compare rust to other languages. so i'm not people will reply with \"but language x has feature y just like rust; how dare you argue that rust is some kind of revolution!\" oh well.i'm also sure some will come along and take issue with my assertion that rust makes memory management easier. rust makes memory management easier only if you take the time to consider the full story. that is to say, it's quite easy to manage memory efficiently in, say, c. but to do it _without_ bugs? it takes _decades_ to write a c program with no memory bugs. yet i can write the same program in rust and the compiler will _ensure_ memory is managed correctly. (within certain limits, it's possible to leak memory, etc, etc.)", "it is entirely possible to write absolute garbage code in an fp language as well.i can attest to that as i in college had a course on functional programming with haskell and the way i did my assignment was awful to say the least.", "this type of signaling is very real and present in functional programming languages specifically. java programmers feel insecure because they're not writing scala, the scala people wish they were as functional as the haskell people, the haskell people wish they were as advanced as the academic idris people.it's a never ending comparison contest. and despite functional programming having an objectively higher barrier to entry, it is entirely possible to write absolute garbage code in an fp language as well.", "s-expressions are already (a trivially deserialised encoding of) an ast representation. if the haskell language used s-expressions, or if the \"frontend\" language was designed to desugar into s-expressions via a standalone pre-processor, then this representation would be available to any code that wanted to use it. different programs, or different parts of the same program, might decide to convert it to their own specialised datatypes (like those of ghc's frontend and template haskell), but those would essentially be details specific to that program (either as an implementation detail or an api). it would have no real influence on how others choose to process the language.if we think of the current ghc implementation in this way, we find that the only de facto representations of haskell code is `bytestring` (or `lazy.bytestring` or `string` or `text` or `lazy.text`, of course;) ). since these are generally unparseable (e.g. via haskell-src-exts and friends), it's hard to do much with them (hence the tendency to delve into ghc's own representations).note that for my own work i ended up abandoning haskell syntax altogether in favour of ghc core. i use cabal and ghc to do the parsing (since that seems to be the only way to handle real world code), and a ghc plugin to dump out core as s-expressions", "i'm curious to see how languages with support for rational types would handle this problem. (e.g. scheme, clojure, haskell) seems to me that they would eliminate the round-off problem entirely for a great number of commonly-faced applications in the finance world. (so easy to use `x/100`.)", "> note that even ghc can't re-use its own asts: the template haskell extension provides its own ast representation, entirely separate to that used by the compiler's frontend!isn't that about the expression problem, though? how would changing the syntax help?", "some features i just can't live without:* tmux integration. whether i'm in a remote server or my own machine, just use -cc and i can now use tmux with the same keybindings i would use without tmux.* watch for the completion of a command. especially useful if you happen to be using a language with a slow compiler like haskell or rust. plays a nice ding when the command is done. (this may require shell integration).* even if you forgot to run your command with time, iterm can still tell you the wall clock time of your command. (shell integration too).and then just small things that the builtin terminal doesn't have:* focus follows mouse * smart selection (for example it could detect a url and you can select the whole url, then command-click to open) * copy on select", "> it's genius and i wish all other languages gave you the ability to optionally choose between braces or whitespace. it could settle the whole python vs c syntax war once and for all!i really like haskell as a language, but the fact it isn't based on s-expression is the biggest issue i have with it. whitespace, braces, etc. are very minor quibbles: they're basically debates about language as a ui. the problem is, that same language is also the api we must adhere to when manipulating code programatically, e.g. writing interpreters/compilers/documentation generators/code formatters/linters/renderers to html or latex or whatever/static analysers/verifiers/model checkers/ides/refactoring tools/etc.i think it's telling that a language so heavily focused on language implementation (dsls, etc.) effectively has a single usable implementation (ghc), and a mountain of dead/niche implementations ( ).imagine we're given the path to a file containing haskell code, and we want to transform it in some way (e.g. replacing calls to one function with another function). the most basic thing we need to do is parse it, but my work on code analysis tools over the past few years has taught me that we can't even manage that reliably.we might naively reach for the ghc api, but that requires that we set a whole bunch of configuration options that we may not know (language extensions, package databases, commandline flags, etc. collectively referred to as \"dynflags\"); if we get those wrong, our program crashes saying `the impossible happened!`. we can't, in general, figure out what these should be; the only real solution is to invoke our program via cabal, and read in the needed values by emulating the commandline flags of ghc. this solution is useless if we have a string of code, without any associated cabal project.we might instead opt for a standalone library, like haskell-src-exts. the problem is, those libraries typically can't parse haskell code found \"in the wild\". language extensions are one problem, but another major blocker is widespread use of the c preprocessor (an unhygenic, unsafe macro system based on string substition; which would be largely unnecessary if haskell used an easily manipulated format like s-expressions instead).note that even ghc can't re-use its own asts: the template haskell extension provides its own ast representation, entirely separate to that used by the compiler's frontend!whilst there are layers on top of haskell like \"liskell\", which accept s-expressions and produce haskell code, they're solving the opposite problem: it's easy to convert from s-expressions, since they're so trivial to manipulate. the hard problem is being able to do anything useful with the mountain of existing code which isn't in a nice s-expression format, other than compile it with (some versions of) ghc, if invoked with the right options from (some version of) cabal; or maybe stack; maybe after running hpack; or who knows what else!i wrote up some of this at", "@pjmlp thanks for clarifying. i had no idea there was such a thing.@darpa_escapee - thanks for guiding me into that rabbit hole. csound looked the most promising to me. pure data needs more screenshot and samples, the site was very hard for me to dive through and overtone clojure it's cool. wanted to learn that at one point, but i'm sticking first with learning haskell.", "that's exactly the conclusion the haskell community came to, and how they ended up with optional meaningful-whitespace. it's genius and i wish all other languages gave you the ability to optionally choose between braces or whitespace. it could settle the whole python vs c syntax war once and for all!", "as a german who worked as a software dev in the netherlands for 2 years, i could't disagree more. the dutch speak a great english, even the homeless. i've never heard a better american style english anywhere else in europe and i found the dutch english often more clean than even received pronounciation.same goes for the code bases, they had the usual mess that codebases have but variable names weren't an issue.i find your example of childs vs children to be bike shedding, the hard part about coding isn't the variable names. if you read haskell you would probably find \"c\" for child and \"cs\" for children, simply to keep the code terse.while i strongly condone the form of backlash you received, i am still happy that there is pushback.(sorry)we as software devs battle complexity on a daily basis, and we achieve many of the things we achieve only because of collaboration. introducing an additional translation step into the process of coding sounds like a complexity nightmare, a debugging nightmare and a communications nightmare.when working in an international team you still have to talk about the stuff, and as long as something like this doesn't ship with a perfect star trek like universal natlang translator people still have to settle on one language, except that the code they are looking at is now code they've never seen before.kudos for the effort, go do it as a hobby but don't be suprised that people get mad just by the very thought of being forced by management to work with something that puts even more complexity onto their shoulders.and i'm happy that people want collaboration so bad that they are willing to speak and work in a language that they don't understand well in order to connect with peers from all over the world.and don't take it personal that others don't digg the idea of having to work with something like this. it's a cool idea, it didn't work. move on and try the next cool idea, one day one of them will stick. you're not the only one to have worked on something and then figured out a year into the project that there is no demand/ its technically unfeasible / there is some obscure paper from the 70s that had the same idea but discovered a fundamental flaw and dropped it.to quote allan key:if you don't fail at least 90 percent of the time, you're not aiming high enough.", "learn a new language make sense if such language teaching you a new way of thinking.if you come from a \"normal\" background i guess you can already program in python or ruby or java or cfrom this kind of background i would love towards functional programming (haskell or closure) or the actor model (beam languages or maybe pony) or rust.the reality is that go forgot the last 10/20 years of progress in programming languages theory. it is true that this makes a really simple programming language but it is also true that the complexity of any task does not disappear if you use a simple programming language but it will be simply shuffle around in the code itself.on the other side rust is pushing the state of the art in programming languages. this means that the language itself is more complex to learn, but once you master it the language itself will take care of part of the complexity in your code.as always it is a trade-off.", "you can write git hooks in any language, not just bash. they can be compiled haskell binaries, even.", "i think in theory you are correct: as soon as you have 2 different \"versions\" of a language, you can, with sufficient creativity, construct a program that will break with the newer version.how likely this is going to bite you in practice, though, is a different question, and one where the specifics of the language are important.c++ is a language without a module system; instead, the preprocessor resolves #include directives by textual substitution, which is of course extremely fragile wrt. compatibility, particularly considering idiomatic \"header-only libraries\" of the boost variety.haskell doesn't use #include but has a module system, which avoids a lot of the c++ standard incompatibility issues, because you can compile each module independently with its required language standard.also note that there is a pragma you can put into modules to specify the version directly inline, e.g., \"{-# language haskell2010 #-}\" or \"{-# language haskell98 #-}\".", "my fuzzy mind when from ai and legal to google for stuart sierra (just to see how is clojure evolving nowadays), the link \"is clojure dying\" was irresistible, then appcanary from clojure to ruby transition and happiness for programmers, then stuart \"do not\" about combining lazy evaluation with side effects and the comments there seems to justify that clojure \"simplicity over easyness\" is a problem. when the ai hype expand from deep learning to other techniques i think we'll see a better scenario to apply ai to real world. yesterday the \"how is haskell in 2017 and 70-100 full time programmers in haskell in the us\" give us an idea of how is the tech world evolving. the velocity of the expanding radius of technology and ia is decreasing.", "you don't need infinite loops, all you need are simple inductive types and reduction rules, it has not to be a turing complete language. you can have simple typelevel functions in haskell, whilst its typechecker is not turing-complete.", "> i think it's less that go has significantly different needs, but it's more that people overestimate what their actual needs are.i think you are right. and i doubt it hurts that sat solving is a fun problem!my main package management experience has been with haskell, which has used the cabal tool for many years. cabal was a traditional solver-based tool (with the added pain of a global mutable package database, although that is going away), and it frequently broke down in confusing ways. cabal hell was a widely used term. a few years ago, another tool arrived on the scene, stack, which used the same package format and such as cabal, but snapshotted the central package list (hackage) by gathering subsets of packages and versions that were guaranteed to work together (or at least do not have conflicting bounds). it works well[0], and although it does in principle result in a major loss in flexibility, it's rarely something i miss. importantly, the improvement in reliability was nothing short of astounding. that certainly helped convince me that flexibility may not be a needed feature for a (language) package manager.[0]: there are all sorts of socio-political stack/cabal conflicts in the haskell community now, but i'm not sure they are founded in technical issues.", "yes, thank you! atc is \"associated type constructors\". i believe haskell calls them \"type families\"? it's sort of a similar idea; a form of higher-kindness. we are likely to get atc in the medium term, but full hkt is farther out.", "i can also recommend: (js, py) (go) (haskell)", "hardly worth replying, but i don't see the similarity. a 6-year-old understands perfectly well what a prime number is, and you can write a program to test for primality in half a line of haskell (though the performance will not be good). now what's a \"free will\"?", "people are talking about secure alternative matrix/riot, mattermost, zullip... not that i have anything to do with them but wire is pretty impressive (you can geek out on haskell backend).in small org we have been using riot/matrix and it is great. works well but it is more like modern irc. it doesnt have too much ui sugar. mattermost on the other hand looks cool but had slow clients and there was some bullshit with push notifications requireing some enterprise server license. hope its no longer the case - i mean why would you want chat without notifications?", "hey, thanks! i wasn't aware of that.that said, i suppose a haskell designer and me have rather different expectations from a type system. i want great typescript/java level tooling, catching stupid type-style bugs, and easier to understand code. going for a fully covered, sound, type system sounds like quite a challenge indeed and i can imagine why it didn't work out.i disagree that \"the type system can't guarantee the types of what gets sent between processes\" implies \"a type system would be useless\". most of my code is not busy sending and receiving messages. it's just, well, regular boring single-threaded code that manipulates data, performs some side effects maybe, etc. i'd be perfectly happy with a type system that just makes me specify, at compile time, what message types a process is expecting to receive. somebody sends something else? my problem, runtime error. that way, each process can be decently typechecked individually, the process type can just be \"pid\", and you can skip the entire \"how do we type the actor model\" problem. i'm sure i'm wrong here in some subtly detailed way, but i'm convinced that elixir would fit a typescript-like type system like a glove if you just forget about typed messaging.does this guarantee \"if it compiles, it works\"? nop. does it allow for readable code, extremely powerful tooling and catching stupid errors? sure thing.", "i don't think it's surprising if you consider elixir's nature.languages like go, rust, and haskell have to start from scratch. getting to the point where they work at all is a huge achievement (though of course they do more than that).languages like clojure run on an existing virtual machine, but want a very different programming model, so they have to invent a lot.by contrast, elixir runs on the beam and gets 99% of its features from erlang: you still use processes, supervisors, pattern matching, etc.so in a sense, the only reason for elixir to exist is to provide a great developer experience for the beam. if it doesn't do that, you might as well use erlang.", "oh lovely, will have to give this a read at some stage!i'd also be really interested in versioning, and upgrading a cluster over time, without bringing the whole thing down (like with cloud haskell). would be super handy to be able to verify that your migration works first, before actually going ahead with it. i'd also love it if the types could be used in some way to make this kind of thing easier to reason about.are you also aware of the work advancing in akka typed? after a number of iterations they made some modifications that made things simpler - not sure how it compares with your work though:", "dialyzer works on success typing, which only tells you when it's certain there's a bug, but will stay silent if it's unsure. even at the highest settings i couldn't get the same lovely iteration loop that you get in an ml-style language (like haskell, elm, rust, etc) that i've come to expect, where you feel like you are having a conversation with the tool.at the time i was attempting to use it, it was also super slow, and libraries were not keeping their typespecs up-to-date. also a big one: no parametric polymorphism results in `any`s galore.:/", "there's a bigger reason than that: recap, one of the main haskell designers tried to come up with a type system for erlang but couldn't cover the inter-process communication, probably because a process which has another process' pid is allowed to send it literally any type of message.in elixir, you notice the dynamic typing mostly when you're defining callbacks that take mfa-style function specs, e.g. def handle_click(m, f, a)...last point, you are right about dialyzer error messages, but people are working on it right now. look for messages in this discussion from _asummers.", "i like elixir and the community is amazing, especially for such a young language. particularly the quality of the standard library as well as the more popular open source libraries is really high.that said, there's one design choice that i simply never understood: the dynamic typing. bear with me, i'm not trying to start another holy war here, i have an argument. thing is, elixir very seldomly uses its dynamic typing. ruby has method_missing and monkey patching, javascript (finally) has proxies, but elixir has none of these. in fact, most elixir code is particularly undynamic in nature.all elixir code that i've seen looks more like a non-oo version of typical java or c# code. notably, variables and seldomly change type. function arguments are seldomly \"a string or an array\" like is common in javascript. structured arguments are typically either used as a dictionary, or as a struct (the elixir word for object, record, whatever), but not really ever \"a little bit of both\". modules always have the same set of functions, the functions always have the same signatures.elixir replaces ruby's monkey patching with macros. they feel a bit similar, but notably macros are entirely compile time. there's nothing dynamic about them.i feel like if elixir had unambitious static typing, more akin to c# or typescript than to haskell, it'd have significantly better tool support, code would be much much easier to read and follow, and virtually all code that works now would still, well, just work except that you'd need to specify types on function arguments of course.of course, there's typespecs, but anyone who's ever tried to use them knows how abysmal the development experience is. dialyzer error messages are impossible to figure out, often showing errors multiple functions down the stack from where the typing or programming error actually is. the syntax is weird, minimally documented and not integrated with the rest of the language. i'm impressed by how well most bigger libraries are typespec'ed, given how hard it is to get that right.all that said, i'm well aware that even an \"unambitious\" type system would be hard to accomplish. making a dynamically typed language surely must be easier than an ergonomic statically typed one - especially if the underlying vm does not depend on static types. maybe the simple reason elixir lacks a good static type system is that it's a lot of work.", "it's really asking from an abstraction layer with opaque capabilities... something like the mobile frameworks or haskell's mtl-style io.", "also, elixir is a relatively small and simple language.yes, it's functional, but it doesn't have a lot of complex concepts and is much easier to learn than, eg, ocaml or haskell. (at least in my opinion).a good dev should probably be productive within a week.", "author here. i answered this and other questions in discussions on reddit:", "thanks. i have been part-time trying to figure out how to install the beast on osx for months.", "i did the same but with a purescript frontend and a haskell backend", "i've always thought that hiring i.e. haskell developers would be easier than for more widely used languages like java and python as i've assumed that the talent-to-jobs ratio would be a lot higher. i actually have no idea though.", "intel has ghc (haskell) running on these in-house if i recall correctly.", "> considering the only response you got points you to a subredditfunnily enough, a job posting was made on r/haskell since that comment was posted. it's not a bad space to watch for jobs.", "minimalism helps. ruby has one kind of minimalism, but fails at minimalism in some other ways. the same with go. people who like haskell like the kind of reasoning it facilitates. people who like java want a managed version of c++'s \"good parts.\"a lot of it has to do with expectations. going beyond the principle of least surprise, there's also a principle of \"no dismay.\" go is like the dependable old corolla. it sets modest expectations, and it delivers a high degree of utility very consistently, and if you're ever let down, it's very rare. c++ can cause you utter dismay due to rather subtle slip-ups. i've only seen this level of dismay in golang around subtle resource release issues around prepared statements.", "meh, everyone has a preferred type of language they find least surprising. to many ruby is the least surprising, and matz used \"principle of [his] least surprise\" as a guiding principle when designing it, but many other people find it enigmatic and confusing. some people find haskell the least surprising and most consistent, others say java is. every language has caveats and inconsistencies, even go. like how go has generics, but only for two or three built-in types. it seems to be more about the person trying out the language than the language itself.", "> \"haskell has excellent libraries for integrating with databases and web services, and for building api services.\"i tried using haskell for my side project(group chat type). its libraries are nowhere near matured ones like phoenix.", "check out miso [1] a frontend framework built in haskell.[1] -", "we're active users of purescript at lumi (w15). we started experimenting with haskell on the backend about two years ago and it was a huge success for many of the same reasons stated by the op. we've now completely moved from node to haskell for our api. since then we've continued to double down on type-driven development and bringing it to the frontend with purescript made sense. it helps that phil freeman, its creator, is on our team:)we've been dipping our toes into open-sourcing more purescript libraries, such as our react bindings:", "from the article: \"both the haskell and elm code-bases are worked upon by multiple developers simultaneously.\"", "there are two sides to the coin. it is a lot easier to hire for a haskell developer, because the pool of jobs is so small compared to the amount of people that would like to work with haskell in their daily life.that of course also means that the opposite is true for someone looking for a job\u2014it's a lot harder to find something, so most trudge on, writing code in some language and then use haskell in their spare time.the last part usually also mean that the developers you find, as a company looking for someone, usually have a higher lower bar, by the very nature of having invested time into learning a niche language. of course, that goes for most such cases as above, not that haskellers are magically better programmers.", "> they mention plentiful motivated job applicationsi'd take anything from an advocacy article with a grain of salt.> how is the market from the perspective of a developer looking to focus on haskell?considering the only response you got points you to a subreddit, i'm guessing it isn't so great. at best, it is a niche market ( though that could be lucrative ).i wouldn't put all my eggs in one basket. i'd make sure you have some expertise in java, c#, c++, python, etc ( don't forget sql ) where there is a large established market that isn't going anywhere soon. but even more important, get experience in specific technologies ( databases, web servers, ides, version control, etc ).", "if you want something that's (really) easy to get started with, and yet won't artificially constrain you from using your functional programming tricks as you evolve, i recommend trying out concur [haskell version]( or [purescript version]( i wrote an initial introduction which also compares it with elm -", "learning elm really helped me learn haskell which is something i'm continuing to do, but elm helped a lot. so i can see why a haskell shop would want to use elm for their frontend work. this makes total sense.that said, my initial enthusiasm for using elm, aside from a gateway-drug to haskell, has waned. i just do not have enough confidence in adopting elm for our internal project nor to recommend it to other companies.the last release of elm was 1 year and 8 months ago. the new release is purported to break many things. however, this new release is unknown, it's really unknown when it's going to be released and aside from a few insiders and contributors no one else seem to know what to expect.elm applies some interesting principles (type safety, purity, etc.) that helps to reason about your code. but, it's direction is driven by one person. that in itself is not bad, however, there is very little communication coming out of him (the last blog update by him was 1.5 years ago). because of that, i started looking at reason and what fb and others are doing.i think it makes no sense to invest months or years into something like elm at this point and any advantages elm might have had initially, is coming to parity with other solutions.i still think if you want to get your hands dirty with functional programming, play around with elm. the pragmatic studio elm lesson is great starting point. but look elsewhere for any serious projects.", "just as some anecdata, i know of a single developer who works with haskell; they do fluid dynamics programming for exxonmobil in houston.", "there are more and more jobs coming up, some remote and some not.a lot of them get posted on which is fairly active, worth keeping an eye on it.", "they mention plentiful motivated job applications, how is the market from the perspective of a developer looking to focus on haskell?", "you certainly cannot determine that two programs do or do not have the same behaviour in the general case.in specific cases, the proofs can be pretty trivial: - proof your two programs are different - proof 'y + x' is the same as version 1.these proofs weren't automatically discovered, though for such simple programs i'd expect an smt solver to be able to find the proof or a counterexample easily enough.but even proving they're the same value for all inputs isn't all that helpful, because of lazy haskell code like:code_removed they're (provably) the same for all (positive) input values, but if you call version 1 with n greater than, say, 35, you'll be waiting quite a while for an answer, while version 2 will be very snappy for the first few hundred thousand values of n, at least, after which the size of the answer will be a bottleneck.if a library switched from the latter to the former, it'd have a good chance of breaking code.while obviously exponential code is obviously exponential, this sort of behavioural change can show up in less obvious ways - a change in memory usage might blow your heap after a supposedly minor version change, eg.in the end i don't think the value judgement of 'breaking' or even 'significant' is computable, and you'd need to rely on a human doing something that approximates to 'right' for your world view with their version numbering.", "in one of your comments you say you have improved a lot in two months or so, so perhaps you need a little more practice and i think you could improve a lot more (less time for solving puzzles and writing better code). anyway, i have tried to solve some of the puzzles. perhaps other people in this thread can give more valuable information about your coding style. i wish you the best.sum of cubes:code_removed findmediansortedarrays using haskell:code_removed", "> 1. type classes in haskell are supposedly coherent, i.e. the compiler is supposed to force a single type class instance in the whole project, however ghc does in fact not do that so you can end up with multiple instances of the same type in the same projectcan you give an example?", "to my understanding, string theory/m-theory is quite coherent mathematically, the issue that prevents a good lay description, other than the theory being a somewhat moving target as more of the math gets solved, is a \"naming an abstraction\" problem just as one has all the time in programming. the mathematicians have a good idea of the abstractions in terms of the math itself and its own internally consistent/coherent jargon, but haven't made a solid, coherent leap together to what those systems mean in a way they can sell to lay people.for example, the difference between working in haskell and knowing the monad abstraction, versus using the descendants of that work such as async/await in a language like js, c#, or python and no longer needing to know/worry about the monad abstraction because that's now a compiler/interpreter concern. (an interesting edge to that analogy too is that reminder that haskell's use of the abstraction provides more opportunity, as do-notation works with all monads, but for now async/await is specialized to just one monad. this is useful to the string theory/m-theory question as well, as some users of string theory/m-theory seems interested in mathematically exploring all possible worlds under the theory, not just necessarily the practical ones that align with the world we live in, in case the overall abstraction or do-notation equivalent is useful in other situations.)", "> \"that seems like too limiting a definition of \"magic\" to me\"what is your definition of \"magic\" then? things that are unfamiliar?please don't mention \"explicit vs implicit\", because scala's implicits are in fact explicit, plus we can always talk of assembly language and how it lacks any magic.> \"well, not exactly, as far as i can tell. type classes (in haskell at least) are significantly more ergonomic.\"ergonomics has nothing to do with whether a concept is a generalization of another.> \"since they semantically describe the user's types, they allow you to perform their operations directly with the user's values. implicit parameters have to be pulled out of the implicit environment and used explicitly themselves, as far as i can tell.\"nope, both type clases and implicit parameters allow for describing functions that turn type names into values. that's all there is to it. or in other words, both type classes and scala's implicits are about return type polymorphism.the only actual differences are that:1. type classes in haskell are supposedly coherent, i.e. the compiler is supposed to force a single type class instance in the whole project, however ghc does in fact not do that so you can end up with multiple instances of the same type in the same project2. scala's implicits are more flexible in what they allow, for example it has priority rules in case of conflicts, which allow say those implicits to work in the presence of oop subtyping, or to work with multiple type params for describing things that are difficult to describe via type classes (but not necessarily desirable, e.g. the canbuildfrom pattern)3. working with haskell's type classes is nicer, because for hierarchies in scala you end up dealing with oop issues (i.e. in modelling haskell's type class hierarchies, we ended up debating on inheritance vs composition), plus we do a lot of manual plumbing in libraries like typelevel catsbut trust me when i say this, fundamentally they are the same;-)you can also read martin odersky's paper about it:", "> solved at compile time and lexically scoped so do not qualify for \"magic\".that seems like too limiting a definition of \"magic\" to me.> implicit parameters are in fact a generalization of type classes.well, not exactly, as far as i can tell. type classes (in haskell at least) are significantly more ergonomic. since they semantically describe the user's types, they allow you to perform their operations directly with the user's values. implicit parameters have to be pulled out of the implicit environment and used explicitly themselves, as far as i can tell.it's true that the underlying mechanism is (roughly) the same, but the surface-level behavior is what really matters, and there they are very different.", "in haskell, typeclasses are language-level construct, not needing any implicits, and monadic code is easy to write using do-notation which is syntax sugar over binding (\"comprehensions\").in scala, typeclasses are a pattern, something achievable using a bunch of language features strung together, and implicits are likely an inevitable part of that mix. for-comprehensions is what \"sequential computation\" really is if you want to represent it as a function, and not forget to check intermediate results. it has numerous advantages, but again, on the language level it's a pattern, a contraption that makes monadic style possible, but not necessarily easy on the eyes.", "in your example, not really, but in general, assuming the implicit is in scope most of the time, `x.method` is much more discoverable through autocomplete than `method(x)`.incidentally, the fact that haskell's function calls look like `f x` instead of `x.f` probably makes building a pleasant haskell ide quite difficult.", "implicit parameters in scala are solved at compile time and lexically scoped so do not qualify for \"magic\".> why botherbecause software development is hard, we're solving hard problems and it's good to have better and better tools to do that.in particular scala's implicit parameters, along with its support for higher kinded types and functional programming in general allow for modeling your problem domain via tools imported from haskell and other fp languages, because implicit parameters are in fact a generalization of type classes. and type classes are many times a superior alternative to oop for building polymorphic code.plus the landscape is very competitive and the market is global. i remember in 2000 when the bubble burst the jobs of thousands of developers disappeared over night. to stay competitive, a \"why bother\" attitude is not going to cut it when the current bubble bursts, just saying.", "there's not a module-level safe/trustworthy/unsafe division, but as steveklabnik1 says, any potentially-dangerous code has to be placed into an `unsafe` block.one can also forbid the use of any `unsafe` blocks for a crate/module (with the #[forbid(unsafe_code)] attribute), but this is slightly different to the {-# language safe #-} pragma in that it does consider imports at all. however, since \"unsafety\" is modeled in the language in rust, and is granular, people are encouraged to have every module be \"trustworthy\" (in safe haskell terms): if an individual function could cause undefined behaviour if misused, it should be marked \"unsafe\", and a \"safe\" module (i.e. one using the forbid above) won't be able to use it.", "the title of this post (on hn, not the original article title) leaves out the rest of author's sentiment on the data.\"given the relatively small numbers here, there is more noise in the rankings. i'm also not convinced that the apparent decline of things like clojure and haskell is anything more than a result of github growing more mainstream over time.\"", "the problem is the phrase \"the current standard\". is haskell going to become the new c++? c++11, c++14, c++17, etc? is it going to live up to the phrase \"i love standards. there are so many to choose from.\"? is it going to become a python 2.7 vs python 3 vs python 4 game?i understand the benefit of using the same name as you can trade on the prior mindset. but if old code won't compile then it isn't the same language.if you're going to change a language with a standard (e.g. haskell98), change the name. call it peyton or something. otherwise there will be a haskell20 that is refactored for dependent types that won't compile under haskell10. then when people claim to \"know haskell\" the question becomes... which language?the \"current standard\" game leads into \"library hell\".", "not that this \"makes the point\", necessarily, but ghc haskell does have the whole safe/unsafe haskell module inference/guarantee, so it may be a bit easier to avoid unexpectedly unsafe behavior entirely.i have no idea whether any equivalent exists for rust.", "any python function may use ctypes, any haskell function may use unsafeperformio,..., so all bets are off all the time.i don't think that's a particularly useful point, as is.", "i agree that this is very annoying (and time consuming!) time for debugging, as it has implicit assumption about data (e.g. that some column has more than one value).i was tempted a few time to write pipelines in python which make such sanity-checks.in any case - thanks for sharing your example. by any chance, can you show an example for such haskell pipeline? (especially if there is some non-trivial statistics, or ml training.)", "oh definitely, while i don\u2019t think it will ever evolve into everyone using haskell, we\u2019re definitely going to keep seeing more and more functional concepts creep into all programming languages. hell, even king oop, java, is even breaking down and adding some functional things last i heard, finally getting lambdas (i think), right? and i imagine that was much to the outcry of thousands of \u201centerprise\u201d developers, what\u2019s going to happen when big bad functional programming comes to down and shuts down all their abstract factories?! think of their child classes!but, i digress, and honestly think a nice balance between concepts, and using what works best for the task at hand. however, i\u2019m super excited for the future of functional languages. i love elixir/erlang, once you get the hang of otp/actor model/functional programming, it\u2019s absolutely mind blowing how easy it is to write highly concurrent programs that are super reliable, easy to restart from failures (just let it die is what they say right?). nothing like the headache\u2019s i experienced when i first learned concurrency with pthreads in c++. and what\u2019s exciting is the erlang vm is legendary for being able to build up highly reliable and super concurrent, complex software, however one of it\u2019s biggest dings was it\u2019s far slower than something like c when it comes to raw computations. this is largely because of it\u2019s functional nature, since it\u2019s data structures are immutable, any modifications will result in having to make new copies of data, while c could just do it right in place. however, now that raw computing power is becoming cheaper and faster, they is becoming much less of an issue. and the erlang vm can handle things like clustering servers to run processes across several computers built right in. i don\u2019t want to imagine what it\u2019d be like to have to set that up with our old friend c out of the box (but c also doesn\u2019t have the overhead of things like a vm or a garbage collector, so it\u2019s not like it doesn\u2019t have a ton of advantages over erlang i just wouldn\u2019t want to use it to build concurrent software across multiple servers).", "i fail to see the humour in this, how are those http responses? when would a server respond to a request with \"haskell\"? makes no sense to me, while \" i'm a teapot\" made perfect sense", "> what's wrong with a pipeline operator?honestly, for the use case, the same thing that's wrong with a (mandatory) visible function application operator in haskell.> chaining calls in js means that a function returns the original object, piping is actually passing over the result as an argument, so it's semantically different.the syntax flux uses for creating the result is the same as js would use for mutating an inbound object, so it actually would be consistent if pushing the result used the same syntax as passing the (mutated) original object would in js.though i\u2019d prefer whitespace for piping just like haskell does for application. if your are going to specialize a language for a domain, don't be timid about it.", "there seems to be a lot of not understanding sql in the sql criticism, and the design of the new language seems to have a lot of excess noise.1. if arity-1 functions are as dominant in use as the examples suggest, mandatory named args are excessive noise.2. from the examples, the |> operator also looks like needless noise; code would be cleaner and more readable if this operator was whitespace without any other character (like function application in haskell, but newlines should also be acceptable) and there was a different punctuation for when that isn't intended.3. this seems really noisy:code_removed map is a transform applied to an input, so is square, so why can't it be:code_removed or, better:code_removed", "functional-ness is completely orthogonal to the type system. clojure is probably the second most-functional prominent language after haskell. immutability is very strongly encouraged, with mutation used only in controlled ways.", "for the backend i start with node, then get tired of the runtime errors and switch to go. go is cool but soon i get tired of writing \u201cif err == nil\u201d so i switch to haskell. haskell is nice but soon i get tired of not finding decent libraries for some not very popular things that i use, so i say fuck it and go to rails. ruby is nice and rails feels well thought out and solid, but then i can\u2019t help be annoyed that it\u2019s not fast, so fuck it, i switch to rust. i get tired of lifetimes and wrapping everything in refcells so i switch to erlang. erlang is cool and all, but no fucking meta programming. sucks, let\u2019s try lisp...i am not making fast progress, i think the problem is my keyboard, i should try buying that ducky one i have been eyeing for quite a while.", "thanks. that's a really excellent way to describe things, probably the best comment on this thread.there's always a tradeoff between how much intelligence you put into a runtime vs how much you have to ship with the app. in the limit wasm would turn into \"download and run an entire language runtime with every web page\", which is clearly suboptimal. most likely compilation to js will continue for the forseeable future when possible for that reason.one idea that could probably work very well is to write a wasm interpreter for graalvm. graalvm has very high level constructs but can also support low level manually memory managed code. they have one for llvm bitcode already, but wasm would probably be simpler to implement and with a more stable bytecode format. then c/rust/exceptionless c++ could ship artifacts as wasm files, scripting languages can ship source code, static managed languages like java or haskell (eta) can ship jars, and they can all interoperate and be compiled together.i don't see a route to getting there with current wasm runtimes or just the existing featureset of wasm though. as a portable isa for distribution of limited, os neutral c-ish libraries it seems reasonable enough. as a future vm for everything i can't see them beating graalvm anytime soon. graalvm has the shared high level constructs, but it is able to also (eventually) compile low level wasm/llvm style code down to what a typical gcc like compiler would create.", "i agree in principle, but this is exactly why we've moved our data pipeline from python to haskell.the python ecosystem has this concept of what is \"pythonic\", which, while it results in more code around the internet looking familiar, it largely resolves to \"write it out yourself by hand\". the result is that there are often no library functions for these things, even in libraries where you'd expect them to be. need to coalesce an optional, or need a switch statement? write out the conditional. need zipwith, flatmap, or mapmaybe? write out the list comprehension. need a combinator, or something curried? write it out.we spent an obnoxious amount of time fighting with bugs from this, or weird edge cases in pandas and numpy, that would show up halfway through training, or not at all until we measured results. heisenbugs from generators were also a huge issue. we ultimately decided the situation wasn't tenable for the quick iteration cycles we needed, and moved all the data munging to haskell. almost everything we need for data munging is in base, usually in prelude. if it isn't, it's in lens. changes and refactors are quick, and no more surprises halfway through training.", "the most distinguishing factor of haskell is not it's functional programming features, but rather it's very flexible and powerful type system. you won't see that pulled in by the mentioned languages any time soon.", "i've been using r for 20 years, and i think the history does matter.r is an open source clone of s, which had some traction with rigorous statisticians via bell labs. so it had stats at its core. r was just a version of s that had less overhead and was easier to access.the explosive growth of r really is more about the explosive growth of stats and data analysis than anything else. r and s were sort of growing within the stats community anyway, and then when stats took off, so did r. i think it's open source quality and the fact that it is more similar to other programming platforms than sas or stata helped too as stats branched out into computer science.lisp is an interesting comparison with lessons for haskell. xlispstat was a competitor to r very early on but died out relatively quickly. i always was sad about that, because i loved lisp, and it was great having stats embedded in a broader language, but the reaction was uniformly the same: that lisp was just too weird, too hard to read, and too hard to program in. lisp has diminished in importance in computer science more broadly, but didn't die out in the same way xlispstat did in stats.haskell is suffering similar issues. the lack of ecosystem is partly because it's coming from the outside in, rather from the inside out, but part of it is because it is just perceived as odd. i love functional programming but am increasingly becoming convinced that any language that pushes too hard on one paradigm is going to lose out to one that is less pure. as great as functional approaches are, sometimes it's just easier to think and organize procedurally, and this is increasingly true as you get closer to the metal.the real elephant in the room is the poor performance of the languages currently dominating data science, whether that be r or python. the llvm basically made it possible to right a conceptually clean language that also exhibits good performance, so we don't have to choose between expressive and performant languages so much, unless you're talking about embedded systems or low-level systems programming. although many people don't want to program a glm (and maybe shouldn't be for integrity's sake) there are many times when going down to the likelihood function and optimization level for an unusual case shouldn't result in a huge performance hit. you shouldn't have to change to c or even rust for something that conceptually isn't that much lower level. things like julia and nim really make this possible, and is where things will probably eventually head (even if i'm not sure it will be either of those). i also wonder if we'll see things like rust taking off via higher-level extensions such as lia or gluon.my guess is that if \"functional\" languages will take off with stats, it will be through something like ocaml (especially if that gets its distributed/parallelism worked out quickly enough).", "if i understand correctly, a bunch of python's libraries (numpy, specifically) came from fortran. the fortran libraries are very well debugged and tested, and they cover an insane number of special cases. (you want a linear equation solver for sparse complex hermitian matrices that is both efficient and numerically stable? sure, we got that.)i don't know whether haskell could wrap such libraries in the same way. i mean, i assume that technically it's possible, but you'd like to keep haskell's type safety. encoding that a matrix has to be hermitian in a type is possible, i suppose, but it might be messy...", "the poor ecosystem is very real, i agree. i'm a huge fan of haskell in particular, but i don't use it as my everyday language precisely because of lack of support in so many ways. which is a shame, because the language really has so much to offer.if you're frustrated by the lack of ide support in particular, i'd suggest checking out racket. one of the language developers' primary accomplishments is a dedicated ide called drracket which is designed to make using racket easy. the books \"how to design programs\" [0] and \"programming languages: application and interpretation\" [1] use racket and are available online for free, and you can find matthew flatt's course notes for his functional class here: [2] (he's one of the language's primary implementers).[0]", "i think the problem isn't haskell but rather the way programming is usually taught.imperative programming is the most widespread paradigm, by far. when people find an introduction to programming, it's going to be in a language like c, c++, java, python, c#, javascript, etc. many of these languages support functional style in some way or another, but none of them truly embrace it \u2014 and anyway, you wouldn't find any mention of it in introductory material.in an imperative language, you write down a list of instructions for the computer. you can think of it as a step-by-step recipe, and the computer will dumbly follow your instructions to the t. this is easy to explain, and since it's what most people use it's also what most people teach.haskell (and pure functional languages in general) are fundamentally different. in a functional language, you're writing data transformations. that's literally all it is. instead of writing a procedure, you write what essentially amounts to a mathematical function describing how to transform the input data into the desired output. it's not a list of steps, but rather a single modification. you compose multiple functions together to get the desired result. this definitely seems more aligned with the goals of data science, for the most part. (though i'm not a data scientist, so i could be wrong!)i don't think functional programming is significantly more difficult to learn. it's just hard to learn after you've already learned the imperative style. it's hard to go back and figure out a different way to explain things to the computer once you're used to doing it the one way. i think this is the part that those quotes you have are really talking about. i don't think haskell is inherently more difficult to learn than java for somebody whose programming knowledge is a blank slate; it's just hard to learn after you've started down the path of imperative thinking.", "would haskell's type system really prevent statistical biases like data snooping, etc?", "r is for people who lean maths and stats from mathematicians and statisticians. its scripting is quite well aligned to the way its taught in those disciplines. computer scientists dislike its huge inefficiency, but for its problem space its a good fit.python/numpy/pandas is where i think r should be, but i get there are two models here. i use both. python+plotly gets you to print ready svg output really quickly. i like jupyter. i also like shiny/r.i tend to think haskell is a quant thing in data science. you think a lot about the model. you type the royal french bejesus out of the inputs. you adopt strong formalisms about moments of exchange between types, and compositions over types because when you stand up and say \"this $32b dollar play has about a 15% upside, if the model holds\" you really want to know the model holds, not a pile of bugs i didn't consider holds.", "if i had to do a project, probably vue or just vanila-js.if i wanted to learn more, i really liked the purescript book [1]. it made many concepts i wanted to learn in haskell click. i am not sure i would be confident enough to try to deliver a project in it, but i know some people do, i really liked the presentation of claudia doppioslash contrasting elm and purescript [2][1]", "> julia may be more interesting (and it offers types!) plus much more focus om performance for iterative operations (which haskell is lacking). though, each time i tried it, i had to go back to python - again, due to maturity of its data science ecosystem.i definitely agree that the julia ecosystem is still maturing and not everything is as developed, however i've often found that the lack of maturity is less of an issue in julia because the flexability of the language through generics, parametric types and macros makes a lot of the infrastructure needed in python unessessary in julia. obviously your milage may vary in this regard though.", "students usually learn r in a statistics class - while also trying to learn statistics! they usually don't have any prior programming experience so the forgiving nature of the language makes sense. trying to learn haskell and statistics at the same time might be asking too much, esp. if the libraries aren't there.", "i think a wrinkle on what you're saying, though, is that many \"mainstream\" languages are adapting (or have adapted) functional programming features.swift and rust pull in a lot of functional programming features.programming java 8 feels surprisingly functional, in a lot of ways.clojure allows you to experience even more of the functional programming experience (albeit with dynamic typing) on the jvm.\"javascript the good parts\" showed that javascript best practices generally follow a functional programming mindset.having said that, if you want the full functional programming experience (first class functions, immutable data structures, isolated side effects, sum|union types, etc.) then yes, what you say is true. the amount of libraries and size of the community for haskell and the ml family just don't compare to the more mainstream languages.", "the author seems to argue that haskell's mental fit of the language is a better fit for the domain of data science, and so, really it's the lack of libraries that are holding haskell back. so, obvious question, why did the libraries get created in r and python..?many blog post about haskell seem to include something like...\"this is not a language for beginners...\"\"this language will make you smarter but there is a steep learning curve...\"\"i don't feel smart enough to want to learn haskell...\"and i haven't seen many other posts attempting to dispel that notion. libraries are written by people. how big is haskell's userbase? what is the haskell community doing to increase it? it's at a natural disadvantage when you've got schools (like mit and harvard school) using python as the learning language of choice now and python has a reputation for being easy to pickup and just being really pleasant to write it.", "imho f# is another contender in this space. it's a functional language with a lot of nice features, tools and support for the whole.net ecosystem (though compared to haskell it does lack certain 'advanced' features like higher kinded types). some packages are listed at find fsharp.data especially to be amazing for productivity.", "tl;dr never.jokes aside. tl;dr the author finds haskell better suited to expressing mathematical abstractions (no examples), however, they believe that the lack of libraries holds haskell back. they end by talking about how rhaskell lets you integrate r and haskell to get the best of both worlds.", "i recently spent a small amount of time diving down the functional programming rabbit hole (following sicp, poking at haskell, and such). my general impression is that the coolness of the languages is overshadowed by the poor ecosystem for a lot of use cases, exactly as the article suggests for data science.it all seems possible to overcome, but you\u2019d end up needing to deal with c/c++ bindings for many situations. cryptography libraries, for example, appear to be mostly hobby projects, which would be clearly not trustworthy for serious uses, so now you\u2019re writing/finding bindings.is that a fair assertion? i\u2019m not at all an expert; i got kind of excited about the area and then a little disappointed when i considered doing some of my pet projects in a functional language and saw the immature ecosystem."]